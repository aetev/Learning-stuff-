{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24a80f3e-976e-4464-b561-68a3d9692512",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.8/site-packages (2.13.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.65.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (4.21.7)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from tensorflow) (65.4.1)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (4.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (0.34.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (2.13.1)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.23.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.32.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (4.11.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d491617-afea-4020-ac0a-36d19e1c70af",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.1/41.1 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.1 scipy-1.14.0 threadpoolctl-3.5.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eabe3f39-6ba5-4165-9519-8c64882a1172",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-03 23:16:51.439658: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-03 23:16:51.497173: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-03 23:16:51.515529: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-03 23:16:51.585326: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Lambda, Layer, Input, Dense, Concatenate\n",
    "from tensorflow.keras.layers import Flatten, Conv1D, Reshape, GlobalAveragePooling2D,LSTM, BatchNormalization\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc4b4813-ac14-4b5b-a41a-8c14bf3ce7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722727014.894542  166958 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1722727014.963671  166958 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1722727014.963742  166958 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "# Set TensorFlow to use only the CPU\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9af48050-f477-4338-ac0b-f2e2792a808b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs detected:\n",
      "- PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"GPUs detected:\")\n",
    "    for gpu in gpus:\n",
    "        print(f\"- {gpu}\")\n",
    "else:\n",
    "    print(\"No GPUs detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28d61721-a19b-4a5c-8779-bb4fd674d04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csrf_token(session):\n",
    "    \"\"\"Fetches the CSRF token from the login page.\"\"\"\n",
    "    login_url = \"https://www.heartharena.com/login\"\n",
    "    response = session.get(login_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    csrf_token = soup.find(\"input\", {\"name\": \"_csrf_token\"})[\"value\"]\n",
    "    return csrf_token\n",
    "    \n",
    "def login(username, password):\n",
    "    \"\"\"Logs in to the HearthArena website.\"\"\"\n",
    "    url = \"https://www.heartharena.com/login_check\"\n",
    "    session = requests.Session()\n",
    "\n",
    "    # Get CSRF token\n",
    "    csrf_token = get_csrf_token(session)\n",
    "\n",
    "    # Prepare payload\n",
    "    payload = {\n",
    "        \"_username\": username,\n",
    "        \"_password\": password,\n",
    "        \"_csrf_token\": csrf_token,\n",
    "        \"_remember_me\": \"on\"  # Optional, based on whether you want to stay logged in\n",
    "    }\n",
    "\n",
    "    # Submit the login form\n",
    "    response = session.post(url, data=payload)\n",
    "\n",
    "    # Check if login was successful\n",
    "    if response.status_code == 200:\n",
    "        print(\"Login successful!\")\n",
    "    else:\n",
    "        print(\"Login failed.\")\n",
    "\n",
    "    return session\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "764ade49-5152-4383-bf42-ce4ee47d88eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRuns(arenaURL,session):\n",
    "    # Initialize an empty list to store the links\n",
    "    response = session.get(arenaURL)\n",
    "    links = []\n",
    "    end = BeautifulSoup(response.text, 'html')\n",
    "    runs = end.find('tbody')\n",
    "    # Find all 'a' tags within 'tr' elements and filter for those with 'href' attribute starting with '/arena-run/'\n",
    "    for link in runs.find_all('tr'):\n",
    "        anchor_tags = link.find_all('a')\n",
    "        for tag in anchor_tags:\n",
    "            href = tag.get('href')\n",
    "            if href and href.startswith('/arena-run/'):\n",
    "                links.append('https://www.heartharena.com'+href)\n",
    "    links = list(set(links))\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d44502dc-fc7f-4434-89b5-f5938582a6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStatsFromRun(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, 'html')\n",
    "    nameExtract = soup.select('h1.class')[0].text.strip()\n",
    "    parts = nameExtract.split('/')\n",
    "       \n",
    "    wins = 0\n",
    "    deckList = 0\n",
    "    champ = \"\"\n",
    "    hasData = len(soup.find_all('span', class_='wins'))\n",
    "    print(hasData)\n",
    "    if hasData == 1:\n",
    "        champ = parts[0].strip() \n",
    "        wins = int(soup.find_all('span', class_='wins')[0].text)\n",
    "        arenaDeck = soup.find_all('ul', class_=\"deckList\")[0]\n",
    "        cardNames = arenaDeck.find_all('span', class_='name')\n",
    "        cardAmount = arenaDeck.find_all('span', class_='quantity')\n",
    "        # Extract and convert numeric values and names\n",
    "        namesList = [(name.text.strip()) for name in cardNames]\n",
    "        amountList = [int(amount.text.strip()) for amount in cardAmount]\n",
    "\n",
    "        # Initialize an empty list to hold the repeated names\n",
    "        deckList = []\n",
    "\n",
    "        # Iterate through the names and amounts simultaneously\n",
    "        for name, amount in zip(namesList, amountList):\n",
    "            # Repeat the name 'amount' times and extend the repeated_names list\n",
    "            deckList.extend([name] * amount)\n",
    "\n",
    "    return champ, wins/12, deckList, hasData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a704ecb-12ea-4f1a-b1ba-6a23b7f6cc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc0d79aa-007a-4932-86cb-d21ba245395a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to the JSON file\n",
    "file_path = 'my_dict.json'\n",
    "\n",
    "# Load JSON file and convert it to a dictionary\n",
    "with open(file_path, 'r') as file:\n",
    "    encodedDeck = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2f2e938-1376-4d49-bbc5-b5e63bb00414",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "def encodeDeck(deck):\n",
    "    stats_list = []\n",
    "    desc_list = []\n",
    "    for name in deck:\n",
    "        if name in encodedDeck:\n",
    "            data = encodedDeck[name]\n",
    "            stats = data[0]\n",
    "            desc = data[1]\n",
    "            stats_list.append(stats)\n",
    "            desc_list.append(desc)\n",
    "    \n",
    "    \n",
    "    return [stats_list, desc_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4121a502-e035-4789-aa4d-b3c4bb391072",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Death Knight','Demon Hunter','Druid','Hunter','Mage','Paladin','Preist','Rogue','Shaman','Warlock','Warrior']\n",
    "\n",
    "# Initialize an empty dictionary to hold the encoding\n",
    "encoded_classes = {}\n",
    "\n",
    "# Iterate over each class name\n",
    "for name in classes:\n",
    "    # Check if the name is already in the dictionary\n",
    "    if name not in encoded_classes:\n",
    "        # If not, add it with a unique integer\n",
    "        encoded_classes[name] = len(encoded_classes) + 1\n",
    "\n",
    "\n",
    "\n",
    "def encodeClass(classData):\n",
    "    empty_list1 = [0] * len(encoded_classes)\n",
    "    empty_list2 = [0] * len(encoded_classes)\n",
    "    separated_names = classData.split(' + ')\n",
    "    empty_list1[encoded_classes.get(separated_names[0])-1]+=1\n",
    "    empty_list2[encoded_classes.get(separated_names[1])-1]+=1\n",
    "    return empty_list1+empty_list2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66192f17-7844-40c5-9625-f7980b3317ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def scrapeArenaData(linksList):\n",
    "    # Initialize an empty list to store the outputs\n",
    "    outputs = []\n",
    "\n",
    "        # Iterate through linksList\n",
    "    for link in linksList:\n",
    "        # Call getStatsFromRun for each link and append the result to outputs\n",
    "        \n",
    "        output = getStatsFromRun(link)    \n",
    "        outputs.append(output)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17a6bcda-5c4b-4afb-8cbe-94c9ba2c0ece",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getTrainingData(arenaData):\n",
    "    winRateList = []\n",
    "    DeckList = []\n",
    "    classList = []\n",
    "    descList = []\n",
    "    \n",
    "    for run in arenaData:\n",
    "        print(run[3])\n",
    "        if run[3] == 1:\n",
    "            classEncoded = encodeClass(run[0])\n",
    "            \n",
    "            winRate = run[1]\n",
    "            deckEncoded = encodeDeck(run[2])\n",
    "            \n",
    "            classList.append(classEncoded)\n",
    "            DeckList.append(deckEncoded[0])\n",
    "            descList.append(deckEncoded[1])\n",
    "            winRateList.append(winRate)\n",
    "    \n",
    "    \n",
    "    return [classList,DeckList,descList], winRateList\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "20062441-624e-4a53-950c-68d54dcc254d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login successful!\n"
     ]
    }
   ],
   "source": [
    "session = login(\"mcbrideslade@gmail.com\", \"U$!*3YFvJS2@Dvd4\")\n",
    "arenaUrl = 'https://www.heartharena.com/my-arenas'\n",
    "linksList = getRuns(arenaUrl,session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "14df24d6-99ca-4c15-b00a-43a5eaeaf4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "arenaData = scrapeArenaData(linksList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "84a0bee8-4e87-4b20-b319-e4b06f0d2d1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "trainingdata, winratedata = getTrainingData(arenaData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "981faa78-e55d-4e4a-b34d-886ecf3a0857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 22)\n",
      "(25, 30, 5)\n",
      "(25, 30, 30, 300)\n"
     ]
    }
   ],
   "source": [
    "inputdata1 = trainingdata[0]\n",
    "inputdata2 = trainingdata[1]\n",
    "inputdata3 = trainingdata[2]\n",
    "\n",
    "inputdatanp1 = np.array(inputdata1, dtype=np.float32)\n",
    "inputdatanp2 = np.array(inputdata2, dtype=np.float32)\n",
    "inputdatanp3 = np.array(inputdata3, dtype=np.float32)\n",
    "\n",
    "winratedatanp = np.array(winratedata, dtype=np.float32)\n",
    "print(inputdatanp1.shape)\n",
    "print(inputdatanp2.shape)\n",
    "print(inputdatanp3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4a535215-4221-45e2-9865-390fabfc6eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom DeepSetLayer with Dropout\n",
    "class DeepSetLayer(layers.Layer):\n",
    "    def __init__(self, output_dim, phi_units=[12, 12], rho_units=[12, 12], dropout_rate=0.2):\n",
    "        super(DeepSetLayer, self).__init__()\n",
    "        self.phi_layers = []\n",
    "        for units in phi_units:\n",
    "            self.phi_layers.append(layers.Dense(units, activation='gelu'))\n",
    "            self.phi_layers.append(layers.Dropout(dropout_rate))\n",
    "        \n",
    "        self.rho_layers = []\n",
    "        for units in rho_units:\n",
    "            self.rho_layers.append(layers.Dense(units, activation='gelu'))\n",
    "            self.rho_layers.append(layers.Dropout(dropout_rate))\n",
    "        \n",
    "        self.output_layer = layers.Dense(output_dim)\n",
    "    \n",
    "    def call(self, inputs, training=False):\n",
    "        # Apply the transformation function Φ to each element\n",
    "        x = inputs\n",
    "        for layer in self.phi_layers:\n",
    "            if isinstance(layer, layers.Dropout):\n",
    "                x = layer(x, training=training)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        \n",
    "        # Aggregate the transformed elements (averaging)\n",
    "        #x = tf.reduce_mean(x, axis=1)\n",
    "        x = tf.reduce_max(x, axis=1)\n",
    "        \n",
    "        # Apply the aggregation function ρ\n",
    "        for layer in self.rho_layers:\n",
    "            if isinstance(layer, layers.Dropout):\n",
    "                x = layer(x, training=training)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        \n",
    "        # Output layer\n",
    "        output = self.output_layer(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a6b3cc29-53bc-4857-88ca-57ec035b1413",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskingLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MaskingLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(MaskingLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        stats_input, words_input = inputs\n",
    "        \n",
    "        # Generate a binary mask\n",
    "        batch_size = tf.shape(stats_input)[0]\n",
    "        num_cards = tf.shape(stats_input)[1]\n",
    "        \n",
    "        # Randomly choose cards to mask\n",
    "        mask = tf.random.uniform(shape=(batch_size, num_cards), minval=0, maxval=2, dtype=tf.int32)\n",
    "        \n",
    "        # Ensure the same mask is used for both inputs\n",
    "        mask = tf.cast(mask, dtype=tf.float32)\n",
    "        \n",
    "        # Apply mask to both inputs\n",
    "        masked_stats = stats_input * mask[:, :, tf.newaxis]\n",
    "        masked_words = words_input * mask[:, :, tf.newaxis, tf.newaxis]\n",
    "        \n",
    "        return masked_stats, masked_words\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "d740f0eb-2e2b-413e-9669-000028f3bf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomCardRemovalLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, removal_prob=0.5, **kwargs):\n",
    "        super(RandomCardRemovalLayer, self).__init__(**kwargs)\n",
    "        self.removal_prob = removal_prob\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        stats, word_vectors = inputs\n",
    "        \n",
    "        if training:\n",
    "            # Create a random mask for removal\n",
    "            random_mask = tf.random.uniform((tf.shape(stats)[0],), 0, 1) > self.removal_prob\n",
    "            random_mask = tf.cast(random_mask, tf.bool)\n",
    "            \n",
    "            # Apply mask to stats\n",
    "            stats = tf.boolean_mask(stats, random_mask, axis=0)\n",
    "            \n",
    "            # Apply mask to word_vectors\n",
    "            word_vectors = tf.boolean_mask(word_vectors, random_mask, axis=0)\n",
    "        \n",
    "        return stats, word_vectors\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(RandomCardRemovalLayer, self).get_config()\n",
    "        config.update({\"removal_prob\": self.removal_prob})\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "2391022a-9051-4aea-b2bf-4b8beddd3fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CardProcessingLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(CardProcessingLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.lstm_1 = tf.keras.layers.LSTM(20,return_sequences=False)\n",
    "           \n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        \n",
    "        lstm_1 = tf.map_fn(lambda x: self.lstm_1(x), inputs, dtype=tf.float32)     \n",
    "\n",
    "        return lstm_1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "df4463af-d241-4d4f-b753-19227bdc143c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_15\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_15\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Deck_stats          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Card_desc           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ random_card_remova… │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>), │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Deck_stats[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandomCardRemoval…</span> │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,  │            │ Card_desc[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ card_processing_la… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">25,680</span> │ random_card_remo… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CardProcessingLay…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Class (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ deep_set_layer_30   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span> │ random_card_remo… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DeepSetLayer</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ deep_set_layer_31   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">980</span> │ card_processing_… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DeepSetLayer</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_151         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Class[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │ deep_set_layer_3… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │ deep_set_layer_3… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_15      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_151[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ batch_normalizat… │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_190 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,150</span> │ concatenate_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_160         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_190[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_191 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │ dropout_160[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Deck_stats          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Card_desc           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;45mNone\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m300\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ random_card_remova… │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m), │          \u001b[38;5;34m0\u001b[0m │ Deck_stats[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│ (\u001b[38;5;33mRandomCardRemoval…\u001b[0m │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;45mNone\u001b[0m,  │            │ Card_desc[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m300\u001b[0m)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ card_processing_la… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m20\u001b[0m)    │     \u001b[38;5;34m25,680\u001b[0m │ random_card_remo… │\n",
       "│ (\u001b[38;5;33mCardProcessingLay…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Class (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ deep_set_layer_30   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │        \u001b[38;5;34m800\u001b[0m │ random_card_remo… │\n",
       "│ (\u001b[38;5;33mDeepSetLayer\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ deep_set_layer_31   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │        \u001b[38;5;34m980\u001b[0m │ card_processing_… │\n",
       "│ (\u001b[38;5;33mDeepSetLayer\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_151         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ Class[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │         \u001b[38;5;34m80\u001b[0m │ deep_set_layer_3… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │         \u001b[38;5;34m80\u001b[0m │ deep_set_layer_3… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_15      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dropout_151[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ batch_normalizat… │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_190 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │      \u001b[38;5;34m3,150\u001b[0m │ concatenate_15[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_160         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_190[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_191 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m51\u001b[0m │ dropout_160[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,821</span> (120.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m30,821\u001b[0m (120.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,741</span> (120.08 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m30,741\u001b[0m (120.08 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> (320.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m80\u001b[0m (320.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the inputs\n",
    "Class = tf.keras.Input(shape=(22,), name='Class')\n",
    "Deck_stats = tf.keras.Input(shape=(None, 5), name='Deck_stats')\n",
    "Card_desc = tf.keras.Input(shape=(30, None, 300), name='Card_desc')\n",
    "\n",
    "Deck_stats_rem, Card_desc_rem = RandomCardRemovalLayer()([Deck_stats, Card_desc])\n",
    "\n",
    "\n",
    "\n",
    "# Apply 1D Convolution\n",
    "conv1d = CardProcessingLayer()(Card_desc_rem)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create the network for input_1\n",
    "x1 = Dropout(.5)(Class)\n",
    "\n",
    "x2 = DeepSetLayer(output_dim=20)(Deck_stats_rem)\n",
    "\n",
    "x2 = BatchNormalization()(x2)\n",
    "\n",
    "x3 = DeepSetLayer(output_dim=20)(conv1d)\n",
    "\n",
    "x3 = BatchNormalization()(x3)\n",
    "\n",
    "# Concatenate the outputs of the two networks\n",
    "concatenated = layers.concatenate([x1, x2, x3])\n",
    "\n",
    "x4 = layers.Dense(50, activation='gelu')(concatenated)\n",
    "\n",
    "x4 = Dropout(.2)(x4)\n",
    "\n",
    "# Add an output layer\n",
    "output = layers.Dense(1)(x4)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=[Class, Deck_stats, Card_desc], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mae', metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5935b2f-02fc-4839-9b0f-82ad1a8090f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8s/step - loss: 0.5865 - mae: 0.5865\n",
      "Epoch 2/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.5288 - mae: 0.5288\n",
      "Epoch 3/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.9299 - mae: 0.9299\n",
      "Epoch 4/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.6651 - mae: 0.6651\n",
      "Epoch 5/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.4636 - mae: 0.4636\n",
      "Epoch 6/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.7036 - mae: 0.7036\n",
      "Epoch 7/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.3962 - mae: 0.3962\n",
      "Epoch 8/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.7815 - mae: 0.7815\n",
      "Epoch 9/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.6060 - mae: 0.6060\n",
      "Epoch 10/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4538 - mae: 0.4538\n",
      "Epoch 11/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3966 - mae: 0.3966\n",
      "Epoch 12/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2593 - mae: 0.2593\n",
      "Epoch 13/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.2746 - mae: 0.2746\n",
      "Epoch 14/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4561 - mae: 0.4561\n",
      "Epoch 15/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4974 - mae: 0.4974\n",
      "Epoch 16/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.2789 - mae: 0.2789\n",
      "Epoch 17/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.4585 - mae: 0.4585\n",
      "Epoch 18/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.3843 - mae: 0.3843\n",
      "Epoch 19/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.4254 - mae: 0.4254\n",
      "Epoch 20/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.3107 - mae: 0.3107\n",
      "Epoch 21/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.3539 - mae: 0.3539\n",
      "Epoch 22/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.2770 - mae: 0.2770\n",
      "Epoch 23/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4303 - mae: 0.4303\n",
      "Epoch 24/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.3633 - mae: 0.3633\n",
      "Epoch 25/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.2173 - mae: 0.2173\n",
      "Epoch 26/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.2667 - mae: 0.2667\n",
      "Epoch 27/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.3683 - mae: 0.3683\n",
      "Epoch 28/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.1800 - mae: 0.1800\n",
      "Epoch 29/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.2622 - mae: 0.2622\n",
      "Epoch 30/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.3579 - mae: 0.3579\n",
      "Epoch 31/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.3176 - mae: 0.3176\n",
      "Epoch 32/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.1978 - mae: 0.1978\n",
      "Epoch 33/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.3105 - mae: 0.3105\n",
      "Epoch 34/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.1986 - mae: 0.1986\n",
      "Epoch 35/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.2290 - mae: 0.2290\n",
      "Epoch 36/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.3407 - mae: 0.3407\n",
      "Epoch 37/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3114 - mae: 0.3114\n",
      "Epoch 38/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.2959 - mae: 0.2959\n",
      "Epoch 39/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3446 - mae: 0.3446\n",
      "Epoch 40/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.2878 - mae: 0.2878\n",
      "Epoch 41/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.2021 - mae: 0.2021\n",
      "Epoch 42/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.2357 - mae: 0.2357\n",
      "Epoch 43/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.1551 - mae: 0.1551\n",
      "Epoch 44/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.2207 - mae: 0.2207\n",
      "Epoch 45/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.2331 - mae: 0.2331\n",
      "Epoch 46/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.2234 - mae: 0.2234\n",
      "Epoch 47/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.2936 - mae: 0.2936\n",
      "Epoch 48/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.2791 - mae: 0.2791\n",
      "Epoch 49/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.2673 - mae: 0.2673\n",
      "Epoch 50/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.3290 - mae: 0.3290\n",
      "Epoch 51/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.3614 - mae: 0.3614\n",
      "Epoch 52/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.2364 - mae: 0.2364\n",
      "Epoch 53/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.2115 - mae: 0.2115\n",
      "Epoch 54/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.2860 - mae: 0.2860\n",
      "Epoch 55/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.2938 - mae: 0.2938\n",
      "Epoch 56/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.1494 - mae: 0.1494\n",
      "Epoch 57/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.3240 - mae: 0.3240\n",
      "Epoch 58/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.2948 - mae: 0.2948\n",
      "Epoch 59/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3454 - mae: 0.3454\n",
      "Epoch 60/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.2560 - mae: 0.2560\n",
      "Epoch 61/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.2389 - mae: 0.2389\n",
      "Epoch 62/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.2815 - mae: 0.2815\n",
      "Epoch 63/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1892 - mae: 0.1892\n",
      "Epoch 64/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3242 - mae: 0.3242\n",
      "Epoch 65/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.2573 - mae: 0.2573\n",
      "Epoch 66/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.2139 - mae: 0.2139\n",
      "Epoch 67/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.2395 - mae: 0.2395\n",
      "Epoch 68/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.2047 - mae: 0.2047\n",
      "Epoch 69/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4213 - mae: 0.4213\n",
      "Epoch 70/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.2955 - mae: 0.2955\n",
      "Epoch 71/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.2863 - mae: 0.2863\n",
      "Epoch 72/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.2402 - mae: 0.2402\n",
      "Epoch 73/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.3629 - mae: 0.3629\n",
      "Epoch 74/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3292 - mae: 0.3292\n",
      "Epoch 75/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.2354 - mae: 0.2354\n",
      "Epoch 76/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.2925 - mae: 0.2925\n",
      "Epoch 77/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.2664 - mae: 0.2664\n",
      "Epoch 78/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.1750 - mae: 0.1750\n",
      "Epoch 79/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4422 - mae: 0.4422\n",
      "Epoch 80/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.2170 - mae: 0.2170\n",
      "Epoch 81/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.3189 - mae: 0.3189\n",
      "Epoch 82/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.3564 - mae: 0.3564\n",
      "Epoch 83/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.4008 - mae: 0.4008\n",
      "Epoch 84/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.2404 - mae: 0.2404\n",
      "Epoch 85/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.2678 - mae: 0.2678\n",
      "Epoch 86/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.2473 - mae: 0.2473\n",
      "Epoch 87/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.2544 - mae: 0.2544\n",
      "Epoch 88/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.2426 - mae: 0.2426\n",
      "Epoch 89/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.3215 - mae: 0.3215\n",
      "Epoch 90/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.2187 - mae: 0.2187\n",
      "Epoch 91/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.1506 - mae: 0.1506\n",
      "Epoch 92/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.2521 - mae: 0.2521\n",
      "Epoch 93/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.1796 - mae: 0.1796\n",
      "Epoch 94/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2157 - mae: 0.2157\n",
      "Epoch 95/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.2540 - mae: 0.2540\n",
      "Epoch 96/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.2051 - mae: 0.2051\n",
      "Epoch 97/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.2555 - mae: 0.2555\n",
      "Epoch 98/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3144 - mae: 0.3144\n",
      "Epoch 99/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4095 - mae: 0.4095\n",
      "Epoch 100/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.1963 - mae: 0.1963\n",
      "Epoch 101/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.2473 - mae: 0.2473\n",
      "Epoch 102/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.2091 - mae: 0.2091\n",
      "Epoch 103/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2576 - mae: 0.2576\n",
      "Epoch 104/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.2582 - mae: 0.2582\n",
      "Epoch 105/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.2677 - mae: 0.2677\n",
      "Epoch 106/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.3518 - mae: 0.3518\n",
      "Epoch 107/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.2146 - mae: 0.2146\n",
      "Epoch 108/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3388 - mae: 0.3388\n",
      "Epoch 109/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.2730 - mae: 0.2730\n",
      "Epoch 110/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.2211 - mae: 0.2211\n",
      "Epoch 111/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.1391 - mae: 0.1391\n",
      "Epoch 112/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.2203 - mae: 0.2203\n",
      "Epoch 113/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.2793 - mae: 0.2793\n",
      "Epoch 114/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3125 - mae: 0.3125\n",
      "Epoch 115/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.2877 - mae: 0.2877\n",
      "Epoch 116/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.1782 - mae: 0.1782\n",
      "Epoch 117/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.2787 - mae: 0.2787\n",
      "Epoch 118/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.2124 - mae: 0.2124\n",
      "Epoch 119/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.2182 - mae: 0.2182\n",
      "Epoch 120/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1780 - mae: 0.1780\n",
      "Epoch 121/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.2525 - mae: 0.2525\n",
      "Epoch 122/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3068 - mae: 0.3068\n",
      "Epoch 123/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.1966 - mae: 0.1966\n",
      "Epoch 124/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.1739 - mae: 0.1739\n",
      "Epoch 125/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.1840 - mae: 0.1840\n",
      "Epoch 126/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2400 - mae: 0.2400\n",
      "Epoch 127/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.2684 - mae: 0.2684\n",
      "Epoch 128/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.1868 - mae: 0.1868\n",
      "Epoch 129/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1843 - mae: 0.1843\n",
      "Epoch 130/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.2138 - mae: 0.2138\n",
      "Epoch 131/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.3298 - mae: 0.3298\n",
      "Epoch 132/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.1558 - mae: 0.1558\n",
      "Epoch 133/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.2683 - mae: 0.2683\n",
      "Epoch 134/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3185 - mae: 0.3185\n",
      "Epoch 135/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.2358 - mae: 0.2358\n",
      "Epoch 136/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.1426 - mae: 0.1426\n",
      "Epoch 137/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.1938 - mae: 0.1938\n",
      "Epoch 138/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.1790 - mae: 0.1790\n",
      "Epoch 139/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.2209 - mae: 0.2209\n",
      "Epoch 140/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.1386 - mae: 0.1386\n",
      "Epoch 141/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3177 - mae: 0.3177\n",
      "Epoch 142/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1680 - mae: 0.1680\n",
      "Epoch 143/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.2656 - mae: 0.2656\n",
      "Epoch 144/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.3086 - mae: 0.3086\n",
      "Epoch 145/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.1783 - mae: 0.1783\n",
      "Epoch 146/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.1033 - mae: 0.1033\n",
      "Epoch 147/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.2459 - mae: 0.2459\n",
      "Epoch 148/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.1988 - mae: 0.1988\n",
      "Epoch 149/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1212 - mae: 0.1212\n",
      "Epoch 150/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.1650 - mae: 0.1650\n",
      "Epoch 151/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1914 - mae: 0.1914\n",
      "Epoch 152/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1104 - mae: 0.1104\n",
      "Epoch 153/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.2813 - mae: 0.2813\n",
      "Epoch 154/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.2703 - mae: 0.2703\n",
      "Epoch 155/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1673 - mae: 0.1673\n",
      "Epoch 156/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.2428 - mae: 0.2428\n",
      "Epoch 157/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.1782 - mae: 0.1782\n",
      "Epoch 158/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1325 - mae: 0.1325\n",
      "Epoch 159/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.2363 - mae: 0.2363\n",
      "Epoch 160/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.2541 - mae: 0.2541\n",
      "Epoch 161/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.2276 - mae: 0.2276\n",
      "Epoch 162/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1677 - mae: 0.1677\n",
      "Epoch 163/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.2045 - mae: 0.2045\n",
      "Epoch 164/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1244 - mae: 0.1244\n",
      "Epoch 165/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.3094 - mae: 0.3094\n",
      "Epoch 166/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.1793 - mae: 0.1793\n",
      "Epoch 167/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.2234 - mae: 0.2234\n",
      "Epoch 168/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.2545 - mae: 0.2545\n",
      "Epoch 169/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1493 - mae: 0.1493\n",
      "Epoch 170/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.2373 - mae: 0.2373\n",
      "Epoch 171/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.1494 - mae: 0.1494\n",
      "Epoch 172/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.2249 - mae: 0.2249\n",
      "Epoch 173/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.2267 - mae: 0.2267\n",
      "Epoch 174/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.2631 - mae: 0.2631\n",
      "Epoch 175/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2218 - mae: 0.2218\n",
      "Epoch 176/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.2152 - mae: 0.2152\n",
      "Epoch 177/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.1088 - mae: 0.1088\n",
      "Epoch 178/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1746 - mae: 0.1746\n",
      "Epoch 179/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.2428 - mae: 0.2428\n",
      "Epoch 180/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.2190 - mae: 0.2190\n",
      "Epoch 181/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.1261 - mae: 0.1261\n",
      "Epoch 182/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0899 - mae: 0.0899\n",
      "Epoch 183/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1339 - mae: 0.1339\n",
      "Epoch 184/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.1854 - mae: 0.1854\n",
      "Epoch 185/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.2207 - mae: 0.2207\n",
      "Epoch 186/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.1842 - mae: 0.1842\n",
      "Epoch 187/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.3362 - mae: 0.3362\n",
      "Epoch 188/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.2360 - mae: 0.2360\n",
      "Epoch 189/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.1613 - mae: 0.1613\n",
      "Epoch 190/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.1427 - mae: 0.1427\n",
      "Epoch 191/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1661 - mae: 0.1661\n",
      "Epoch 192/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.1645 - mae: 0.1645\n",
      "Epoch 193/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1223 - mae: 0.1223\n",
      "Epoch 194/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1701 - mae: 0.1701\n",
      "Epoch 195/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.2237 - mae: 0.2237\n",
      "Epoch 196/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.1817 - mae: 0.1817\n",
      "Epoch 197/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.1431 - mae: 0.1431\n",
      "Epoch 198/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.1059 - mae: 0.1059\n",
      "Epoch 199/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.2396 - mae: 0.2396\n",
      "Epoch 200/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.2599 - mae: 0.2599\n",
      "Epoch 201/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1072 - mae: 0.1072\n",
      "Epoch 202/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.1941 - mae: 0.1941\n",
      "Epoch 203/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1489 - mae: 0.1489\n",
      "Epoch 204/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.2533 - mae: 0.2533\n",
      "Epoch 205/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1651 - mae: 0.1651\n",
      "Epoch 206/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.1151 - mae: 0.1151\n",
      "Epoch 207/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1975 - mae: 0.1975\n",
      "Epoch 208/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1823 - mae: 0.1823\n",
      "Epoch 209/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1912 - mae: 0.1912\n",
      "Epoch 210/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.2204 - mae: 0.2204\n",
      "Epoch 211/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1884 - mae: 0.1884\n",
      "Epoch 212/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1293 - mae: 0.1293\n",
      "Epoch 213/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1507 - mae: 0.1507\n",
      "Epoch 214/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1695 - mae: 0.1695\n",
      "Epoch 215/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.1583 - mae: 0.1583\n",
      "Epoch 216/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1582 - mae: 0.1582\n",
      "Epoch 217/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.1655 - mae: 0.1655\n",
      "Epoch 218/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.2184 - mae: 0.2184\n",
      "Epoch 219/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.2093 - mae: 0.2093\n",
      "Epoch 220/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.2115 - mae: 0.2115\n",
      "Epoch 221/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.1326 - mae: 0.1326\n",
      "Epoch 222/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.1693 - mae: 0.1693\n",
      "Epoch 223/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.1484 - mae: 0.1484\n",
      "Epoch 224/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.2925 - mae: 0.2925\n",
      "Epoch 225/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.2048 - mae: 0.2048\n",
      "Epoch 226/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.1668 - mae: 0.1668\n",
      "Epoch 227/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3197 - mae: 0.3197\n",
      "Epoch 228/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.2075 - mae: 0.2075\n",
      "Epoch 229/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.2756 - mae: 0.2756\n",
      "Epoch 230/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0902 - mae: 0.0902\n",
      "Epoch 231/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.1929 - mae: 0.1929\n",
      "Epoch 232/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.2205 - mae: 0.2205\n",
      "Epoch 233/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.1832 - mae: 0.1832\n",
      "Epoch 234/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.2019 - mae: 0.2019\n",
      "Epoch 235/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.1491 - mae: 0.1491\n",
      "Epoch 236/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.1306 - mae: 0.1306\n",
      "Epoch 237/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.1805 - mae: 0.1805\n",
      "Epoch 238/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.1093 - mae: 0.1093\n",
      "Epoch 239/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.1705 - mae: 0.1705\n",
      "Epoch 240/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.1805 - mae: 0.1805\n",
      "Epoch 241/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.1713 - mae: 0.1713\n",
      "Epoch 242/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.2338 - mae: 0.2338\n",
      "Epoch 243/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.1476 - mae: 0.1476\n",
      "Epoch 244/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.1515 - mae: 0.1515\n",
      "Epoch 245/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.1264 - mae: 0.1264\n",
      "Epoch 246/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.2419 - mae: 0.2419\n",
      "Epoch 247/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.1916 - mae: 0.1916\n",
      "Epoch 248/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.1281 - mae: 0.1281\n",
      "Epoch 249/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.1144 - mae: 0.1144\n",
      "Epoch 250/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.1214 - mae: 0.1214\n",
      "Epoch 251/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1292 - mae: 0.1292\n",
      "Epoch 252/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.1819 - mae: 0.1819\n",
      "Epoch 253/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.1542 - mae: 0.1542\n",
      "Epoch 254/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.1020 - mae: 0.1020\n",
      "Epoch 255/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.2379 - mae: 0.2379\n",
      "Epoch 256/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1880 - mae: 0.1880\n",
      "Epoch 257/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.2068 - mae: 0.2068\n",
      "Epoch 258/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.1563 - mae: 0.1563\n",
      "Epoch 259/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1922 - mae: 0.1922\n",
      "Epoch 260/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.1613 - mae: 0.1613\n",
      "Epoch 261/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1909 - mae: 0.1909\n",
      "Epoch 262/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.2313 - mae: 0.2313\n",
      "Epoch 263/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.1431 - mae: 0.1431\n",
      "Epoch 264/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.1972 - mae: 0.1972\n",
      "Epoch 265/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.1245 - mae: 0.1245\n",
      "Epoch 266/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.1646 - mae: 0.1646\n",
      "Epoch 267/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1563 - mae: 0.1563\n",
      "Epoch 268/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.1834 - mae: 0.1834\n",
      "Epoch 269/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.1432 - mae: 0.1432\n",
      "Epoch 270/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1441 - mae: 0.1441\n",
      "Epoch 271/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.1700 - mae: 0.1700\n",
      "Epoch 272/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0865 - mae: 0.0865\n",
      "Epoch 273/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.1239 - mae: 0.1239\n",
      "Epoch 274/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.2138 - mae: 0.2138\n",
      "Epoch 275/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.2094 - mae: 0.2094\n",
      "Epoch 276/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1927 - mae: 0.1927\n",
      "Epoch 277/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.1889 - mae: 0.1889\n",
      "Epoch 278/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.1936 - mae: 0.1936\n",
      "Epoch 279/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.1984 - mae: 0.1984\n",
      "Epoch 280/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2451 - mae: 0.2451\n",
      "Epoch 281/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1199 - mae: 0.1199\n",
      "Epoch 282/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.1482 - mae: 0.1482\n",
      "Epoch 283/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.2417 - mae: 0.2417\n",
      "Epoch 284/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.1663 - mae: 0.1663\n",
      "Epoch 285/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.1881 - mae: 0.1881\n",
      "Epoch 286/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.1861 - mae: 0.1861\n",
      "Epoch 287/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1284 - mae: 0.1284\n",
      "Epoch 288/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1924 - mae: 0.1924\n",
      "Epoch 289/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.2032 - mae: 0.2032\n",
      "Epoch 290/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.1739 - mae: 0.1739\n",
      "Epoch 291/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1233 - mae: 0.1233\n",
      "Epoch 292/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1407 - mae: 0.1407\n",
      "Epoch 293/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.1463 - mae: 0.1463\n",
      "Epoch 294/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - loss: 0.2219 - mae: 0.2219\n",
      "Epoch 295/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.2253 - mae: 0.2253\n",
      "Epoch 296/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.1348 - mae: 0.1348\n",
      "Epoch 297/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.1353 - mae: 0.1353\n",
      "Epoch 298/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1782 - mae: 0.1782\n",
      "Epoch 299/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1859 - mae: 0.1859\n",
      "Epoch 300/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2026 - mae: 0.2026\n",
      "Epoch 301/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.1144 - mae: 0.1144\n",
      "Epoch 302/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1460 - mae: 0.1460\n",
      "Epoch 303/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.2235 - mae: 0.2235\n",
      "Epoch 304/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.1616 - mae: 0.1616\n",
      "Epoch 305/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1050 - mae: 0.1050\n",
      "Epoch 306/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1697 - mae: 0.1697\n",
      "Epoch 307/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1549 - mae: 0.1549\n",
      "Epoch 308/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.1337 - mae: 0.1337\n",
      "Epoch 309/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.1896 - mae: 0.1896\n",
      "Epoch 310/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.2024 - mae: 0.2024\n",
      "Epoch 311/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.1398 - mae: 0.1398\n",
      "Epoch 312/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.1585 - mae: 0.1585\n",
      "Epoch 313/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1299 - mae: 0.1299\n",
      "Epoch 314/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.1523 - mae: 0.1523\n",
      "Epoch 315/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1263 - mae: 0.1263\n",
      "Epoch 316/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.1481 - mae: 0.1481\n",
      "Epoch 317/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.2272 - mae: 0.2272\n",
      "Epoch 318/500\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit([inputdatanp1,inputdatanp2, inputdatanp3], winratedatanp, epochs=500, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "8d316ae4-7231-4d65-a2a3-72270c2a23f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 14 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7fd7e065d300> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 809ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict([inputdatanp1,inputdatanp2, inputdatanp3])\n",
    "flattened_list = [item for sublist in prediction for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "656a8ebb-bbd8-4c15-bd58-95aa4dffc1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = winratedatanp\n",
    "list2 = flattened_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "0612ac49-1b25-46c3-b4f0-c6b3478aeee8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 25 and the array at index 1 has size 11",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[196], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Step 4: Combine arrays\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m combined_array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlist1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlist2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Extract the first row (keys)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m first_row \u001b[38;5;241m=\u001b[39m combined_array[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/core/shape_base.py:289\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(tup, dtype, casting)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    288\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m [arrs]\n\u001b[0;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 25 and the array at index 1 has size 11"
     ]
    }
   ],
   "source": [
    "# Step 4: Combine arrays\n",
    "combined_array = np.vstack([list1, list2])\n",
    "# Extract the first row (keys)\n",
    "first_row = combined_array[0]\n",
    "\n",
    "# Sort the combined_array based on the first row\n",
    "sorted_combined_array = np.array(sorted(zip(first_row, *combined_array[1:]), key=lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "7944bfcd-32f4-48fe-bcd2-13b5938537ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the two columns into lists\n",
    "column_1 = sorted_combined_array[:, 0].tolist()\n",
    "column_2 = sorted_combined_array[:, 1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "84b05316-e7f7-4c1e-a77d-c0fe31733322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting\n",
    "plt.plot(list1, label='List 1', color='blue')\n",
    "plt.plot(list2, label='List 2', color='red')\n",
    "\n",
    "# Customization\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Two Lists Overlay')\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcc0aaa-00f5-4443-b6a2-b3fa7958b84f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
