{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPs/K0XGjAJksyILMzOHa90",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aetev/Learning-stuff-/blob/main/wganworkking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xI7rEeMMgDQI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgyl_WtbgO5k",
        "outputId": "19df2a04-ec78-4f6b-db2e-dfe85702b7ac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(7*7, input_shape=(100,)))\n",
        "    model.add(layers.Dense(14*14,activation='relu'))\n",
        "    model.add(layers.Dense(28*28,activation='sigmoid'))\n",
        "    model.add(layers.Reshape((28,28,1)))\n",
        "\n",
        "    return model\n",
        "\n",
        "def make_discriminator_model():\n",
        "    input_img = layers.Input(shape=(28,28,1))\n",
        "\n",
        "    x = layers.Conv2D(64,3,2,padding='same',activation='relu')(input_img)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "\n",
        "    dense_output = layers.Dense(128, activation='relu')(x)\n",
        "\n",
        "    dense_output = layers.Dense(64, activation='relu')(x)\n",
        "\n",
        "    dense_output = layers.Dense(1, activation='linear')(dense_output)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=input_img, outputs=dense_output)\n",
        "    return model"
      ],
      "metadata": {
        "id": "kik7wQ1qgOV-"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = make_generator_model()\n",
        "discriminator = make_discriminator_model()\n",
        "generator_optimizer = tf.keras.optimizers.Adam(0.0004)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(0.0004)"
      ],
      "metadata": {
        "id": "lS0DF8rjhHdY"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "#@tf.function\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = tf.reduce_mean(real_output)\n",
        "    fake_loss = tf.reduce_mean(fake_output)\n",
        "    total_loss = fake_loss - real_loss\n",
        "    return total_loss\n",
        "\n",
        "#@tf.function\n",
        "def generator_loss(fake_output):\n",
        "    return -tf.reduce_mean(fake_output)\n",
        "\n",
        "#@tf.function\n",
        "def gradient_penalty(real_images, fake_images):\n",
        "    alpha = tf.random.uniform([BATCH_SIZE, 1, 1, 1], 0., 1.)\n",
        "    real_images, fake_images = tf.cast(real_images, tf.float32), tf.cast(fake_images, tf.float32)\n",
        "    interpolated_images = alpha * real_images + ((1 - alpha) * fake_images)\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(interpolated_images)\n",
        "        pred = discriminator(interpolated_images, training=True)\n",
        "    gradients = tape.gradient(pred, [interpolated_images])[0]\n",
        "    norm = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis=[1, 2, 3]))\n",
        "    gp = tf.reduce_mean((norm - 1.)**2)\n",
        "    return gp"
      ],
      "metadata": {
        "id": "DYQpIZyEgSlN"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NOISE_DIM = 100\n",
        "GP_WEIGHT = 10\n",
        "\n",
        "\n",
        "#@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "    for i in range(2):\n",
        "      with tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(noise, training=True)\n",
        "\n",
        "        real_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "        gp = gradient_penalty(images, generated_images)\n",
        "        disc_loss += gp * GP_WEIGHT\n",
        "      if i ==0:\n",
        "         weights = discriminator.get_weights()\n",
        "\n",
        "      gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "      discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    with tf.GradientTape() as gen_tape:\n",
        "      generated_images = generator(noise, training=True)\n",
        "      real_output = discriminator(images, training=True)\n",
        "      fake_output = discriminator(generated_images, training=True)\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    discriminator.set_weights(weights)\n",
        "    tf.print(\"disc_loss\",disc_loss,'gen_loss',gen_loss)"
      ],
      "metadata": {
        "id": "oyW06YaegVMB"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NOISE_DIM = 100\n",
        "GP_WEIGHT = 10\n",
        "\n",
        "\n",
        "#@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(noise, training=True)\n",
        "        real_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        gp = gradient_penalty(images, generated_images)\n",
        "        disc_loss += gp * GP_WEIGHT\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    tf.print(\"disc_loss\",disc_loss,'gen_loss',gen_loss)"
      ],
      "metadata": {
        "id": "cP3-wZztEeaE"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    for batch in range(len(dataset) // BATCH_SIZE):\n",
        "\n",
        "            target_images = dataset[batch * BATCH_SIZE: (batch+1) * BATCH_SIZE]\n",
        "\n",
        "\n",
        "            train_step(target_images)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      print(epoch)\n",
        "\n"
      ],
      "metadata": {
        "id": "Sx_KbIfjiogE"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "x_train2 = np.expand_dims(x_train, axis=-1)\n",
        "x_train2 = (x_train2 - np.min(x_train2)) / (np.max(x_train2) - np.min(x_train2))\n",
        "train(x_train2, EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWp_3RkPg248",
        "outputId": "4f0a4600-e107-44a4-f9cf-d6e92bad5414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "disc_loss 7.45939302 gen_loss 0.0741928369\n",
            "disc_loss 6.09642744 gen_loss 0.39651531\n",
            "disc_loss 5.03104 gen_loss 0.69573307\n",
            "disc_loss 3.81365204 gen_loss 0.993869185\n",
            "disc_loss 2.75862145 gen_loss 1.28385377\n",
            "disc_loss 1.23007929 gen_loss 1.58079624\n",
            "disc_loss -0.138076305 gen_loss 1.88613403\n",
            "disc_loss -1.23080385 gen_loss 2.2074151\n",
            "disc_loss -2.44772243 gen_loss 2.52807856\n",
            "disc_loss -3.08477664 gen_loss 2.84871292\n",
            "disc_loss -3.63338423 gen_loss 3.22844172\n",
            "disc_loss -3.95519876 gen_loss 3.6256454\n",
            "disc_loss -4.11445856 gen_loss 4.00669098\n",
            "disc_loss -4.45369864 gen_loss 4.40807581\n",
            "disc_loss -4.75398922 gen_loss 4.78131962\n",
            "disc_loss -4.98658466 gen_loss 5.21142578\n",
            "disc_loss -5.19492626 gen_loss 5.6412096\n",
            "disc_loss -5.07019424 gen_loss 6.02349472\n",
            "disc_loss -5.9686718 gen_loss 6.37185097\n",
            "disc_loss -6.60843039 gen_loss 6.89286709\n",
            "disc_loss -6.56405544 gen_loss 7.08277178\n",
            "disc_loss -7.35877466 gen_loss 7.53929424\n",
            "disc_loss -7.88484526 gen_loss 7.90807915\n",
            "disc_loss -7.80204153 gen_loss 8.13135529\n",
            "disc_loss -8.30720806 gen_loss 8.345438\n",
            "disc_loss -8.97502422 gen_loss 8.80431843\n",
            "disc_loss -9.35404396 gen_loss 9.12686729\n",
            "disc_loss -9.70765877 gen_loss 9.45943737\n",
            "disc_loss -9.90197945 gen_loss 9.79013634\n",
            "disc_loss -9.95999336 gen_loss 9.99380112\n",
            "disc_loss -10.295846 gen_loss 10.1631269\n",
            "disc_loss -10.4597931 gen_loss 10.3620138\n",
            "disc_loss -10.2713223 gen_loss 10.4749346\n",
            "disc_loss -10.2410975 gen_loss 10.6897411\n",
            "disc_loss -10.2818289 gen_loss 10.6853123\n",
            "disc_loss -9.89391518 gen_loss 10.7588863\n",
            "disc_loss -9.87448406 gen_loss 11.0254364\n",
            "disc_loss -9.8008852 gen_loss 10.9544668\n",
            "disc_loss -9.86772346 gen_loss 10.8954926\n",
            "disc_loss -9.37368202 gen_loss 10.7314129\n",
            "disc_loss -9.42992401 gen_loss 10.7567177\n",
            "disc_loss -9.32227 gen_loss 10.5953035\n",
            "disc_loss -9.18857861 gen_loss 10.316267\n",
            "disc_loss -8.94307327 gen_loss 10.1699896\n",
            "disc_loss -8.93425941 gen_loss 10.0326786\n",
            "disc_loss -8.7120409 gen_loss 9.59441376\n",
            "disc_loss -9.00599289 gen_loss 9.43461418\n",
            "disc_loss -8.72985 gen_loss 9.15504169\n",
            "disc_loss -8.66352558 gen_loss 9.04253578\n",
            "disc_loss -8.56943703 gen_loss 8.7358284\n",
            "disc_loss -8.44434261 gen_loss 8.60711288\n",
            "disc_loss -8.37755203 gen_loss 8.54129219\n",
            "disc_loss -7.90257 gen_loss 8.35438061\n",
            "disc_loss -7.94241381 gen_loss 8.22042274\n",
            "disc_loss -7.84632874 gen_loss 8.08575249\n",
            "disc_loss -7.35382271 gen_loss 7.90618229\n",
            "disc_loss -7.04271507 gen_loss 7.75638866\n",
            "disc_loss -7.05511427 gen_loss 7.72265196\n",
            "disc_loss -7.07636213 gen_loss 7.31369877\n",
            "disc_loss -6.84328365 gen_loss 6.96897078\n",
            "disc_loss -6.84523487 gen_loss 6.87863445\n",
            "disc_loss -6.72972965 gen_loss 6.59544039\n",
            "disc_loss -6.53550053 gen_loss 6.23436832\n",
            "disc_loss -6.29122877 gen_loss 6.18444347\n",
            "disc_loss -6.13665962 gen_loss 5.83929157\n",
            "disc_loss -5.984478 gen_loss 5.36921883\n",
            "disc_loss -5.96916771 gen_loss 5.39132404\n",
            "disc_loss -5.87945604 gen_loss 5.11820126\n",
            "disc_loss -5.90751219 gen_loss 4.87072706\n",
            "disc_loss -5.4390893 gen_loss 4.51674557\n",
            "disc_loss -5.20059967 gen_loss 4.39621496\n",
            "disc_loss -5.25731754 gen_loss 4.14225578\n",
            "disc_loss -4.95107031 gen_loss 3.89733624\n",
            "disc_loss -4.67258406 gen_loss 3.60976887\n",
            "disc_loss -4.90122747 gen_loss 3.26971221\n",
            "disc_loss -4.84153748 gen_loss 3.10780549\n",
            "disc_loss -4.90038633 gen_loss 2.85769892\n",
            "disc_loss -4.69993067 gen_loss 2.54166555\n",
            "disc_loss -4.54743767 gen_loss 2.22900772\n",
            "disc_loss -4.49172592 gen_loss 1.98541451\n",
            "disc_loss -4.42684507 gen_loss 1.59926236\n",
            "disc_loss -4.23665524 gen_loss 1.35275543\n",
            "disc_loss -4.11991215 gen_loss 0.942811847\n",
            "disc_loss -4.32777739 gen_loss 0.7865538\n",
            "disc_loss -4.10288 gen_loss 0.540545464\n",
            "disc_loss -3.95457935 gen_loss 0.159215569\n",
            "disc_loss -4.22483253 gen_loss 0.00426076\n",
            "disc_loss -4.07697725 gen_loss -0.501813412\n",
            "disc_loss -4.27231264 gen_loss -0.668616474\n",
            "disc_loss -4.03032351 gen_loss -0.918848872\n",
            "disc_loss -3.88088465 gen_loss -1.22966027\n",
            "disc_loss -3.81868219 gen_loss -1.60651898\n",
            "disc_loss -4.01925039 gen_loss -1.60485768\n",
            "disc_loss -3.87192416 gen_loss -1.90129304\n",
            "disc_loss -4.15466595 gen_loss -2.02693772\n",
            "disc_loss -4.16597795 gen_loss -2.31667948\n",
            "disc_loss -4.13174629 gen_loss -2.55886292\n",
            "disc_loss -4.02625 gen_loss -2.76060867\n",
            "disc_loss -4.26703739 gen_loss -2.95989919\n",
            "disc_loss -4.04865742 gen_loss -3.17522979\n",
            "disc_loss -4.28066397 gen_loss -3.38849163\n",
            "disc_loss -3.99202228 gen_loss -3.53800797\n",
            "disc_loss -4.00191689 gen_loss -3.63501978\n",
            "disc_loss -4.13463402 gen_loss -3.6513052\n",
            "disc_loss -3.95299077 gen_loss -3.63047075\n",
            "disc_loss -3.75171041 gen_loss -3.48703\n",
            "disc_loss -3.76541519 gen_loss -3.2515142\n",
            "disc_loss -4.35006475 gen_loss -3.003263\n",
            "disc_loss -4.57955599 gen_loss -2.87920713\n",
            "disc_loss -4.35043859 gen_loss -2.67308044\n",
            "disc_loss -4.13971376 gen_loss -2.52267241\n",
            "disc_loss -3.95248747 gen_loss -2.40953302\n",
            "disc_loss -3.95296645 gen_loss -2.22312832\n",
            "disc_loss -4.23006105 gen_loss -2.09652972\n",
            "disc_loss -3.96053934 gen_loss -1.95902789\n",
            "disc_loss -4.02713823 gen_loss -1.86856592\n",
            "disc_loss -4.20348454 gen_loss -1.66062093\n",
            "disc_loss -4.21499777 gen_loss -1.61883605\n",
            "disc_loss -4.34275436 gen_loss -1.50118756\n",
            "disc_loss -4.31478214 gen_loss -1.3249619\n",
            "disc_loss -4.6340456 gen_loss -1.24326122\n",
            "disc_loss -4.59996557 gen_loss -1.18028891\n",
            "disc_loss -4.36615801 gen_loss -1.09225714\n",
            "disc_loss -4.72866344 gen_loss -1.03473735\n",
            "disc_loss -4.52123785 gen_loss -1.08146095\n",
            "disc_loss -4.68435192 gen_loss -1.109846\n",
            "disc_loss -4.61749649 gen_loss -1.19259453\n",
            "disc_loss -4.39882612 gen_loss -1.28145337\n",
            "disc_loss -4.71530676 gen_loss -1.29176152\n",
            "disc_loss -4.63108 gen_loss -1.36842084\n",
            "disc_loss -4.86151123 gen_loss -1.4067874\n",
            "disc_loss -4.75266218 gen_loss -1.47414148\n",
            "disc_loss -5.10104179 gen_loss -1.54379213\n",
            "disc_loss -4.80285215 gen_loss -1.67526078\n",
            "disc_loss -4.7330451 gen_loss -1.82124865\n",
            "disc_loss -4.9234333 gen_loss -2.03981829\n",
            "disc_loss -4.81625032 gen_loss -2.23324585\n",
            "disc_loss -4.74043608 gen_loss -2.40331841\n",
            "disc_loss -4.58302 gen_loss -2.56526661\n",
            "disc_loss -4.84774256 gen_loss -2.73607922\n",
            "disc_loss -4.69980335 gen_loss -2.83815265\n",
            "disc_loss -4.49181128 gen_loss -2.9072969\n",
            "disc_loss -4.40912485 gen_loss -2.95548749\n",
            "disc_loss -4.57566166 gen_loss -2.99060917\n",
            "disc_loss -4.5397191 gen_loss -2.91202664\n",
            "disc_loss -4.77302933 gen_loss -2.79339361\n",
            "disc_loss -4.83118248 gen_loss -2.75539351\n",
            "disc_loss -5.08612204 gen_loss -2.62633777\n",
            "disc_loss -4.84976816 gen_loss -2.61631536\n",
            "disc_loss -4.54239464 gen_loss -2.57805777\n",
            "disc_loss -4.57954407 gen_loss -2.57551527\n",
            "disc_loss -4.54125595 gen_loss -2.56492233\n",
            "disc_loss -4.78635454 gen_loss -2.54141474\n",
            "disc_loss -4.62324905 gen_loss -2.64319754\n",
            "disc_loss -4.80016756 gen_loss -2.68244052\n",
            "disc_loss -4.46148682 gen_loss -2.84872651\n",
            "disc_loss -4.75363398 gen_loss -2.8350811\n",
            "disc_loss -4.32151222 gen_loss -2.96980929\n",
            "disc_loss -4.44607353 gen_loss -3.05390167\n",
            "disc_loss -4.41266489 gen_loss -3.16202974\n",
            "disc_loss -4.29706478 gen_loss -3.32133722\n",
            "disc_loss -4.61241245 gen_loss -3.51480174\n",
            "disc_loss -4.53683567 gen_loss -3.78802943\n",
            "disc_loss -4.54331303 gen_loss -3.98934412\n",
            "disc_loss -4.34214211 gen_loss -4.24440384\n",
            "disc_loss -4.15088511 gen_loss -4.45849037\n",
            "disc_loss -4.36626482 gen_loss -4.60737705\n",
            "disc_loss -4.49652672 gen_loss -4.73593473\n",
            "disc_loss -4.2915926 gen_loss -4.80301952\n",
            "disc_loss -4.12257 gen_loss -4.88385963\n",
            "disc_loss -4.1829567 gen_loss -4.99298048\n",
            "disc_loss -4.42263842 gen_loss -5.06545258\n",
            "disc_loss -4.60396481 gen_loss -5.12474489\n",
            "disc_loss -4.223104 gen_loss -5.20439053\n",
            "disc_loss -4.07858181 gen_loss -5.25311661\n",
            "disc_loss -4.51334095 gen_loss -5.24189472\n",
            "disc_loss -4.45670223 gen_loss -5.31020069\n",
            "disc_loss -4.26883698 gen_loss -5.32143736\n",
            "disc_loss -4.42059183 gen_loss -5.32048607\n",
            "disc_loss -4.45000696 gen_loss -5.34057188\n",
            "disc_loss -4.43363905 gen_loss -5.39216185\n",
            "disc_loss -4.32134295 gen_loss -5.34976339\n",
            "disc_loss -4.28511286 gen_loss -5.37256241\n",
            "disc_loss -4.39614868 gen_loss -5.32228947\n",
            "disc_loss -4.43361378 gen_loss -5.38720703\n",
            "disc_loss -4.46423578 gen_loss -5.35618687\n",
            "disc_loss -4.31917953 gen_loss -5.35779715\n",
            "disc_loss -4.82141495 gen_loss -5.46317577\n",
            "disc_loss -4.495049 gen_loss -5.4699626\n",
            "disc_loss -4.73738241 gen_loss -5.49293041\n",
            "disc_loss -4.85349464 gen_loss -5.49667788\n",
            "disc_loss -4.98162079 gen_loss -5.6312089\n",
            "disc_loss -4.98289633 gen_loss -5.65097618\n",
            "disc_loss -4.85895634 gen_loss -5.75294447\n",
            "disc_loss -4.9345336 gen_loss -5.82495642\n",
            "disc_loss -5.0360465 gen_loss -5.75906658\n",
            "disc_loss -5.25623274 gen_loss -5.88935184\n",
            "disc_loss -4.91909552 gen_loss -5.9446907\n",
            "disc_loss -5.00020075 gen_loss -5.90845728\n",
            "disc_loss -4.94928169 gen_loss -5.91270161\n",
            "disc_loss -4.5417304 gen_loss -5.93323135\n",
            "disc_loss -5.00824261 gen_loss -5.96462822\n",
            "disc_loss -5.11581087 gen_loss -5.86626148\n",
            "disc_loss -5.15788126 gen_loss -5.93258\n",
            "disc_loss -5.21986866 gen_loss -5.94923735\n",
            "disc_loss -5.3242116 gen_loss -6.06228399\n",
            "disc_loss -5.38015175 gen_loss -6.16689968\n",
            "disc_loss -5.41324139 gen_loss -6.30790615\n",
            "disc_loss -5.1167655 gen_loss -6.43976402\n",
            "disc_loss -4.86457443 gen_loss -6.55046749\n",
            "disc_loss -5.10311794 gen_loss -6.6303854\n",
            "disc_loss -5.03310537 gen_loss -6.75974464\n",
            "disc_loss -4.92821789 gen_loss -6.92866898\n",
            "disc_loss -4.67572832 gen_loss -7.06428051\n",
            "disc_loss -4.34112215 gen_loss -7.14750862\n",
            "disc_loss -4.66556597 gen_loss -7.23986244\n",
            "disc_loss -5.00211477 gen_loss -7.27742529\n",
            "disc_loss -5.06593657 gen_loss -7.22447681\n",
            "disc_loss -4.89095926 gen_loss -7.25862789\n",
            "disc_loss -5.06321526 gen_loss -7.30157232\n",
            "disc_loss -5.30421162 gen_loss -7.29638863\n",
            "disc_loss -5.23652458 gen_loss -7.28358603\n",
            "disc_loss -4.79486 gen_loss -7.41854334\n",
            "disc_loss -5.17483139 gen_loss -7.3994441\n",
            "disc_loss -5.14134455 gen_loss -7.44634962\n",
            "disc_loss -5.0576582 gen_loss -7.50326872\n",
            "disc_loss -4.65158796 gen_loss -7.55185795\n",
            "disc_loss -5.03272057 gen_loss -7.61686087\n",
            "disc_loss -5.03462553 gen_loss -7.5992775\n",
            "disc_loss -5.10457945 gen_loss -7.67706394\n",
            "disc_loss -5.05961514 gen_loss -7.73461199\n",
            "disc_loss -5.09127426 gen_loss -7.7691021\n",
            "disc_loss -5.14593554 gen_loss -7.82165051\n",
            "disc_loss -4.66937351 gen_loss -7.82284069\n",
            "disc_loss -4.81974125 gen_loss -7.90150833\n",
            "disc_loss -4.83893394 gen_loss -7.89751816\n",
            "disc_loss -4.96387911 gen_loss -7.89636946\n",
            "disc_loss -4.92890882 gen_loss -7.97999239\n",
            "disc_loss -4.77924681 gen_loss -7.940557\n",
            "disc_loss -4.57657957 gen_loss -7.93960428\n",
            "disc_loss -4.74277401 gen_loss -7.8886013\n",
            "disc_loss -4.78264809 gen_loss -7.82393742\n",
            "disc_loss -5.23842049 gen_loss -7.75232744\n",
            "disc_loss -5.1067605 gen_loss -7.80091\n",
            "disc_loss -4.8332448 gen_loss -7.65266\n",
            "disc_loss -4.85633183 gen_loss -7.6287961\n",
            "disc_loss -4.96976471 gen_loss -7.6431036\n",
            "disc_loss -4.92496872 gen_loss -7.8084116\n",
            "disc_loss -5.03659201 gen_loss -7.8125\n",
            "disc_loss -4.76648855 gen_loss -7.91338205\n",
            "disc_loss -4.67281246 gen_loss -7.97572613\n",
            "disc_loss -4.82461739 gen_loss -8.00917053\n",
            "disc_loss -4.90573311 gen_loss -8.1258831\n",
            "disc_loss -4.65617561 gen_loss -8.33634567\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noise = tf.random.normal(shape=(10,100))\n",
        "test = generator.predict(noise)\n",
        "plt.imshow(test[1].squeeze(), cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "9vPp5AiDkrAF",
        "outputId": "9d8b9508-6f7c-4b9b-edee-59e12525114d"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAjoUlEQVR4nO3dfWyV9f3/8VdvD4jtwVJ6JwUL3uAE6sawYyjD0RRq4kCYwZtlYIgGVojAvBkGQdyWfscSJU6mMzMwE/EuE4gmI1GwbXQFA0oI03W01rWMtkhnzymF3l+/P/hZd+T287Hn+pyW5yM5Ce05L67Puc51zqun55x34zzP8wQAgM/iXS8AAHBpooAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOJHoegHf1Nvbq6NHjyolJUVxcXGulwMAMOR5nlpbW5WTk6P4+HM/z4m5Ajp69Khyc3NdLwMA8C3V19dr1KhR5zw/5gooJSXF9RJihs0zwFifrGRznc73E9S59PT0GGcweNkcQ9Lp38jEqoFwnS70eB6114A2bdqkq666SkOGDFFBQYE+/PDDi8r5+Wu3uLg4q5Of2/JjbX6K9f3g1/oG23EX68ce18nd/el8olJAr732mlatWqV169bpo48+Un5+vmbNmqVjx45FY3MAgAEoLhrTsAsKCjRlyhQ9++yzkk4/5cvNzdXy5cv1q1/96rzZcDisYDDY30s6K9tmt9llNtuyycTyrwwku18b2GS6u7uNM5K/z8BN+XXc2YrlX/8mJCRY5WL5V7m218nmMcL2tg2FQkpNTT3n+f3+DKizs1P79+9XYWHh1xuJj1dhYaEqKyvPuHxHR4fC4XDECQAw+PV7AR0/flw9PT3KzMyM+H5mZqYaGxvPuHxpaamCwWDfiXfAAcClwfkHUVevXq1QKNR3qq+vd70kAIAP+v1t2Onp6UpISFBTU1PE95uampSVlXXG5QOBgAKBQH8vAwAQ4/r9GVBycrImT56sXbt29X2vt7dXu3bt0tSpU/t7cwCAASoqH0RdtWqVFi5cqO9///u66aabtHHjRrW1tem+++6LxuYAAANQVApowYIF+uKLL7R27Vo1Njbqxhtv1M6dO894YwIA4NIVlc8BfRv/+zkgk88w2HzewXaUhV+fDbC5aWw+G2B7fWz2eYwdbmewOSZsPleRnJxsnOns7DTO+PlZN5t959d2YvnzPJKUlJTk27a6urp825bvnwMCAOBiUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMCJqEzD7i8mgwpthhraDsa0HWJqymaAos1gzMRE/w4Dm/XF+gBTGzYDIW0Gi9oOI/VrKGus37a2+8+UnwNCbZgeD57nXdRtyzMgAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOBGz07Dj4uKMJtHaTOK1nXRrM6Xar0nGNtOFu7u7jTODlc0+T0hIiMJKzmRz3NlObrc5jvyaHG2zv232nWR3nWwei/y8TjbHRLQei3gGBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOxOww0vj4eKMBeDbDE22GBkr+DQm12U5ycrJxpquryzgjSZdffrlx5sSJE8YZPwdj2hwTiYnmd6MrrrjCOPPll18aZ4YOHWqckfwdfGrK9ni1YXOdbI4hm2PcdgiuzfpsHysvhGdAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOBEzA4jNeXnMD+bQY0227K5Tn4Oajx58qRxxq+Blbbbsdl/zc3Nxhm/Bphu3brVOCNJc+bMMc7YDKe1uS/ZsB1O69f91ibj176LJp4BAQCcoIAAAE70ewE98cQTiouLiziNHz++vzcDABjgovIa0A033KB33333641Y/L4bADC4RaUZEhMTlZWVFY3/GgAwSETlNaDDhw8rJydHY8eO1b333qu6urpzXrajo0PhcDjiBAAY/Pq9gAoKCrRlyxbt3LlTzz33nGpra3XLLbeotbX1rJcvLS1VMBjsO+Xm5vb3kgAAMSjOs3kDuoGWlhaNGTNGTz31lBYvXnzG+R0dHero6Oj7OhwOKzc3VwkJCUbv3e/u7jZe22D8HFCUb84Ifn2mx4afnwMKhULGGb8+B/TXv/7VOCPF9ueAbO7rnZ2dxhlJSk5ONs7YrM/mftvb22uc8VsoFFJqauo5z4/6uwOGDx+ua6+9VtXV1Wc9PxAIKBAIRHsZAIAYE/UfYU+cOKGamhplZ2dHe1MAgAGk3wvooYceUnl5uT7//HP9/e9/1x133KGEhATdfffd/b0pAMAA1u+/gjty5IjuvvtuNTc3a+TIkbr55pu1Z88ejRw5sr83BQAYwKL+JgRT4XBYwWCwb4rCxYr1F+RshyH6wfYFe7+GIX7nO98xznz66adW2zpy5IhxxuaHq/994000MykpKcYZSbrtttuMM+Xl5caZoUOHGmeefPJJ48zKlSuNM5Ld/davN+fY3v9srpNtTVzoTQix+zYmAMCgRgEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnov4H6WyZ/kVUmwF7sT7A1GYA4JAhQ4wzNkMuJSkpKck4Y7O+iooK48zBgweNM5KUmZlpnKmsrDTO5OfnG2ds/iKqzV/nlKSMjAyrnKkPPvjAOFNTU2OcGTZsmHHGls2QUJu/xOsn08fXi33s4hkQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnIjZadimU3zj4/3rUpsp1QkJCcYZm+tkM9nadt+NHTvWOLNv3z7jzNChQ40zd955p3FGkoYPH26cueqqq4wz5eXlxpkxY8YYZ7Zu3WqckaR//etfxhmbKdBZWVnGmfr6euPMP/7xD+OMJE2ZMsU4c/z4ceOMzX3Q5i8ASFJiovnDfrSmdfMMCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCciNlhpJLZsL3e3t4oriSSzRBAmwGmpgNZJSkpKck409nZaZyRpM8//9w4Y7O+vXv3GmdaW1uNM5K0Zs0a48zy5cuNM3/605+MM6NHjzbO5OfnG2cku9vWRjAYNM7YDJq99tprjTOS9MUXXxhnbAYP22RsHlMku8GipsNSPc+7qPXxDAgA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnIjZYaRxcXFGQz9tBvPZDACU/Bt8ajP0NDU11TgTCoWMM5LdUMO0tDTjzIMPPmicGT9+vHFGkioqKowzd911l3FmxYoVxpnjx48bZxoaGowzknTq1CnjTEpKinGmo6PDODNixAjjzPXXX2+ckez2X3Nzs3HGZvCw7eNQcnKyccZ2YPGF8AwIAOAEBQQAcMK4gCoqKnT77bcrJydHcXFx2r59e8T5nudp7dq1ys7O1tChQ1VYWKjDhw/313oBAIOEcQG1tbUpPz9fmzZtOuv5GzZs0DPPPKPnn39ee/fu1bBhwzRr1iy1t7d/68UCAAYP4zchFBcXq7i4+KzneZ6njRs3as2aNZozZ44k6aWXXlJmZqa2b99u9WItAGBw6tfXgGpra9XY2KjCwsK+7wWDQRUUFKiysvKsmY6ODoXD4YgTAGDw69cCamxslCRlZmZGfD8zM7PvvG8qLS1VMBjsO+Xm5vbnkgAAMcr5u+BWr16tUCjUd6qvr3e9JACAD/q1gLKysiRJTU1NEd9vamrqO++bAoGAUlNTI04AgMGvXwsoLy9PWVlZ2rVrV9/3wuGw9u7dq6lTp/bnpgAAA5zxu+BOnDih6urqvq9ra2t14MABpaWlafTo0VqxYoV+85vf6JprrlFeXp4ef/xx5eTkaO7cuf25bgDAAGdcQPv27dOtt97a9/WqVaskSQsXLtSWLVv0yCOPqK2tTQ888IBaWlp08803a+fOnRoyZEj/rRoAMODFeTZTPKMoHA4rGAxKMhvG6efVsBkSapOxGTZoO2DVRk9Pj3EmEAgYZ06ePGmcOddrjhdiM+jSZoDp3r17jTMTJ040zrz++uvGGUlav369ceazzz4zzvzwhz80zrS0tBhnbIarSrL6AL3NY1FiovlcaJthwLbbMn0s8jxPnucpFAqd93V95++CAwBcmiggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHDCfCzqIBIfb9e/NtNu/ZqgbXOdMjMzjTOStHLlSuPMY489Zpz55l/YvRjNzc3GGUn673//a5zJzs42zrz44ovGmcLCQuNMfn6+cUaSPvnkE+PM5MmTjTMNDQ3GmVtuucU4U1ZWZpyR7CZH20yJt5l8b6u7u9u3bV0Iz4AAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwImYHkZqM/TThJ8DAP0aYGozaLCqqso4I0mXXXaZcebxxx83ztgOFrVhs8+feeYZ48yKFSuMM3V1dcaZK6+80jgj2Q2onTt3rnFm27ZtxplPP/3UOGNzu0p2jxE293U/H4sSEhKMM6bru9h9wDMgAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHAipoeRRpvNUD5J6unpMc7YDCiMjzf/+cBmO6mpqcYZSaqvrzfONDU1GWemTZtmnGlvbzfOSHYDVl944QXjzNKlS40z7777rnHmxRdfNM5IUnJysnHGZoBpQ0ODcebmm282zhw7dsw4Yysx0fxh1eYxxfbxy8/BpxfCMyAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcCKmh5HGxcVd9GX9GvYp+TeM1GZooMk++8qWLVuMM5I0ZMgQ40xLS4txZs+ePcaZuro644xkt89fffVV44zNsNTrr7/eOLNkyRLjjCT99Kc/Nc7Y3E7/+c9/jDMzZswwztjy635rw3Y7No970bpOPAMCADhBAQEAnDAuoIqKCt1+++3KyclRXFyctm/fHnH+okWLFBcXF3GaPXt2f60XADBIGBdQW1ub8vPztWnTpnNeZvbs2WpoaOg7vfLKK99qkQCAwcf4TQjFxcUqLi4+72UCgYCysrKsFwUAGPyi8hpQWVmZMjIydN1112np0qVqbm4+52U7OjoUDocjTgCAwa/fC2j27Nl66aWXtGvXLv3ud79TeXm5iouLz/nW5dLSUgWDwb5Tbm5ufy8JABCD+v1zQHfddVffvydOnKhJkyZp3LhxKisr08yZM8+4/OrVq7Vq1aq+r8PhMCUEAJeAqL8Ne+zYsUpPT1d1dfVZzw8EAkpNTY04AQAGv6gX0JEjR9Tc3Kzs7OxobwoAMIAY/wruxIkTEc9mamtrdeDAAaWlpSktLU3r16/X/PnzlZWVpZqaGj3yyCO6+uqrNWvWrH5dOABgYDMuoH379unWW2/t+/qr128WLlyo5557TgcPHtRf/vIXtbS0KCcnR0VFRfr1r3+tQCDQf6sGAAx4cZ7NtL0oCofDCgaDxjmbAXu2w0i7u7uNM4mJ5u/3SEpKMs50dHQYZ2wPAZshnDZDLm0GmF555ZXGGUlnfaPMhfz85z83zhQVFRln/Hx99OmnnzbOPProo8aZhx9+2Dhz3333GWfGjx9vnJGk5ORkq5ypzs5O44zN4GHJv2GpkhQKhc573DILDgDgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE7E7DTsuLg4o2mvNlfDdppsQkKCccZm8rbNZGsbNlO3JWnu3LnGmeeff944c+ONNxpnurq6jDOStHnzZuPMxo0bjTPvv/++cSYcDhtnhg0bZpyR7O4bNsfrsWPHjDM205wzMjKMM5LdfrDJ2Fwn28cvPx/ymYYNAIhJFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHAiZoeRDjY2A0xthg3efffdxpmXX37ZOCPZXadAIGCcaW9vN87YHtZXX321cebw4cPGmSFDhhhnbPb3Z599ZpyRpMrKSuPMvHnzjDN33nmnceaFF14wzpxvIGZ/8+sh1XYYqc1g5J6eHqttMYwUABCTKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOBEousFnI/tsL1osxk2aDMAsLu72zizbds244zt8MTMzEzjzKlTp4wzJ0+eNM4sWLDAOCNJTzzxhHFm5MiRxpmkpCTjTHFxsXHG1pQpU4wzvb29xplNmzYZZ2bMmGGcSUy0e6izGcJpc9t2dXUZZ2wfH232hekgXM/zLuo68QwIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyI6WGkJkMybQbz2Q7h9GtIqs1Qw/b2duNMZ2encUayG2r41FNPGWfmzZtnnPnss8+MM5K0bt0648zGjRuNM2vXrjXOlJeXG2d+8pOfGGckqaioyCpnKisryzhTX19vnJk0aZJxRrK7P4VCIeOMzWOKzfBXye7+brq+i31s5RkQAMAJCggA4IRRAZWWlmrKlClKSUlRRkaG5s6dq6qqqojLtLe3q6SkRCNGjNDll1+u+fPnq6mpqV8XDQAY+IwKqLy8XCUlJdqzZ4/eeecddXV1qaioSG1tbX2XWblypd566y298cYbKi8v19GjR61+hw8AGNyMXkXeuXNnxNdbtmxRRkaG9u/fr+nTpysUCunFF1/U1q1b9eMf/1iStHnzZl1//fXas2ePfvCDH/TfygEAA9q3eg3oq3d7pKWlSZL279+vrq4uFRYW9l1m/PjxGj16tCorK8/6f3R0dCgcDkecAACDn3UB9fb2asWKFZo2bZomTJggSWpsbFRycrKGDx8ecdnMzEw1Njae9f8pLS1VMBjsO+Xm5touCQAwgFgXUElJiQ4dOqRXX331Wy1g9erVCoVCfSeb9/gDAAYeqw+iLlu2TG+//bYqKio0atSovu9nZWWps7NTLS0tEc+CmpqazvmBs0AgoEAgYLMMAMAAZvQMyPM8LVu2TNu2bdPu3buVl5cXcf7kyZOVlJSkXbt29X2vqqpKdXV1mjp1av+sGAAwKBg9AyopKdHWrVu1Y8cOpaSk9L2uEwwGNXToUAWDQS1evFirVq1SWlqaUlNTtXz5ck2dOpV3wAEAIhgV0HPPPSdJmjFjRsT3N2/erEWLFkmSnn76acXHx2v+/Pnq6OjQrFmz9Mc//rFfFgsAGDziPNuJnFESDocVDAZ92ZbtUFGbXRYfb/5+D5thgwkJCcaZhx9+2DgjSb/97W+NMy+99JJxxmaSxoMPPmickaTk5GTjjM1wR5vj4dixY8aZuro644wkrVmzxjjz0UcfGWdsPnZhc7+12d+S1N3dbZXzg82xKtldJ9vBp6FQSKmpqec8n1lwAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcMLqL6LCnM0Ebdtp3aZ+97vfWeU6OjqMM0uWLDHOfPe73zXOlJeXG2ck6dChQ8aZ/fv3G2f+9y8JXyyb46GoqMg4I0kjRowwzrS2tlpty5TNfamnp8dqWzbT5W22lZho/lDc1dVlnJHsJ4NHQ+ysBABwSaGAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAEzE9jNSvYZx+8GsYqc12bD377LPGmYqKCuNMU1OTcebLL780zkjSwoULjTM1NTXGmWHDhhlnqqurfdmOJGVkZBhnent7jTN+DftMSkoyzkj2Az9N2Vwn28dHPx6LLnYbPAMCADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACfiPD+nV16EcDisYDBonPNzcKlfg0Vt2GzHZiCkZDeo0WYo5J///GfjzOLFi40zkpSenm6cOX78uNW2TPk1uFOSuru7jTOJieazjf0aLGo7VDSWByLbDH+1ZTuMNBQKKTU19ZyX4xkQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADgxaIaRxsebd6ntVR9sw0j9PARied9JdseRDZvBorYDNf1is+9sbttYHsIp2Q1YtTke/NwPto8RDCMFAMQkCggA4IRRAZWWlmrKlClKSUlRRkaG5s6dq6qqqojLzJgxQ3FxcRGnJUuW9OuiAQADn1EBlZeXq6SkRHv27NE777yjrq4uFRUVqa2tLeJy999/vxoaGvpOGzZs6NdFAwAGPqM/Ybhz586Ir7ds2aKMjAzt379f06dP7/v+ZZddpqysrP5ZIQBgUPpWrwGFQiFJUlpaWsT3X375ZaWnp2vChAlavXq1Tp48ec7/o6OjQ+FwOOIEABj8zP+I+//X29urFStWaNq0aZowYULf9++55x6NGTNGOTk5OnjwoB599FFVVVXpzTffPOv/U1paqvXr19suAwAwQFl/Dmjp0qX629/+pvfff1+jRo065+V2796tmTNnqrq6WuPGjTvj/I6ODnV0dPR9HQ6HlZuba7wePgdkvx0+B/Q1Pgdkj88BncbngL52oc8BWT0DWrZsmd5++21VVFSct3wkqaCgQJLOWUCBQECBQMBmGQCAAcyogDzP0/Lly7Vt2zaVlZUpLy/vgpkDBw5IkrKzs60WCAAYnIwKqKSkRFu3btWOHTuUkpKixsZGSVIwGNTQoUNVU1OjrVu36rbbbtOIESN08OBBrVy5UtOnT9ekSZOicgUAAAOT0WtA5/p96ObNm7Vo0SLV19frZz/7mQ4dOqS2tjbl5ubqjjvu0Jo1a877e8D/xSy4b4fXgL4dXgOyx2tAp/Ea0Nf69TWgCy0iNzdX5eXlJv8lAOASZf027Fhj89OA7U/Wfv2U7Nd18vMZUGKi+SFn8xOlLZvbtru72zhj8xOvze1ke6zaHHs26/PrtrW9r/v5LONSxDBSAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHAipoeRmgwQ9HOgps2AQr8GmNoM++zs7LTals1ATZvBnX7y68962OyHWB8069ef2khOTjbOdHR0GGck//Z5rN+20cIzIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4ETMzYL73/lG0Z51FOtzsmJ5O35vyy+xfDvF+v6O5X0X69uK9dvW1oWuV8wVUGtrq+slRIVfB1hXV5cv25HshrLGOtvBrKYG6wOOH/y6jfzU09PjeglR0draqmAweM7z47wYuyf09vbq6NGjSklJOWNCbDgcVm5ururr65Wamupohe6xH05jP5zGfjiN/XBaLOwHz/PU2tqqnJyc806Yj7lnQPHx8Ro1atR5L5OamnpJH2BfYT+cxn44jf1wGvvhNNf74XzPfL7CmxAAAE5QQAAAJwZUAQUCAa1bt06BQMD1UpxiP5zGfjiN/XAa++G0gbQfYu5NCACAS8OAegYEABg8KCAAgBMUEADACQoIAODEgCmgTZs26aqrrtKQIUNUUFCgDz/80PWSfPfEE08oLi4u4jR+/HjXy4q6iooK3X777crJyVFcXJy2b98ecb7neVq7dq2ys7M1dOhQFRYW6vDhw24WG0UX2g+LFi064/iYPXu2m8VGSWlpqaZMmaKUlBRlZGRo7ty5qqqqirhMe3u7SkpKNGLECF1++eWaP3++mpqaHK04Oi5mP8yYMeOM42HJkiWOVnx2A6KAXnvtNa1atUrr1q3TRx99pPz8fM2aNUvHjh1zvTTf3XDDDWpoaOg7vf/++66XFHVtbW3Kz8/Xpk2bznr+hg0b9Mwzz+j555/X3r17NWzYMM2aNUvt7e0+rzS6LrQfJGn27NkRx8crr7zi4wqjr7y8XCUlJdqzZ4/eeecddXV1qaioSG1tbX2XWblypd566y298cYbKi8v19GjRzVv3jyHq+5/F7MfJOn++++POB42bNjgaMXn4A0AN910k1dSUtL3dU9Pj5eTk+OVlpY6XJX/1q1b5+Xn57tehlOSvG3btvV93dvb62VlZXm///3v+77X0tLiBQIB75VXXnGwQn98cz94nuctXLjQmzNnjpP1uHLs2DFPkldeXu553unbPikpyXvjjTf6LvPpp596krzKykpXy4y6b+4Hz/O8H/3oR96DDz7oblEXIeafAXV2dmr//v0qLCzs+158fLwKCwtVWVnpcGVuHD58WDk5ORo7dqzuvfde1dXVuV6SU7W1tWpsbIw4PoLBoAoKCi7J46OsrEwZGRm67rrrtHTpUjU3N7teUlSFQiFJUlpamiRp//796urqijgexo8fr9GjRw/q4+Gb++ErL7/8stLT0zVhwgStXr1aJ0+edLG8c4q5YaTfdPz4cfX09CgzMzPi+5mZmfrnP//paFVuFBQUaMuWLbruuuvU0NCg9evX65ZbbtGhQ4eUkpLienlONDY2StJZj4+vzrtUzJ49W/PmzVNeXp5qamr02GOPqbi4WJWVlUpISHC9vH7X29urFStWaNq0aZowYYKk08dDcnKyhg8fHnHZwXw8nG0/SNI999yjMWPGKCcnRwcPHtSjjz6qqqoqvfnmmw5XGynmCwhfKy4u7vv3pEmTVFBQoDFjxuj111/X4sWLHa4MseCuu+7q+/fEiRM1adIkjRs3TmVlZZo5c6bDlUVHSUmJDh06dEm8Dno+59oPDzzwQN+/J06cqOzsbM2cOVM1NTUaN26c38s8q5j/FVx6eroSEhLOeBdLU1OTsrKyHK0qNgwfPlzXXnutqqurXS/Fma+OAY6PM40dO1bp6emD8vhYtmyZ3n77bb333nsRf74lKytLnZ2damlpibj8YD0ezrUfzqagoECSYup4iPkCSk5O1uTJk7Vr166+7/X29mrXrl2aOnWqw5W5d+LECdXU1Cg7O9v1UpzJy8tTVlZWxPERDoe1d+/eS/74OHLkiJqbmwfV8eF5npYtW6Zt27Zp9+7dysvLizh/8uTJSkpKijgeqqqqVFdXN6iOhwvth7M5cOCAJMXW8eD6XRAX49VXX/UCgYC3ZcsW75NPPvEeeOABb/jw4V5jY6Prpfnql7/8pVdWVubV1tZ6H3zwgVdYWOilp6d7x44dc720qGptbfU+/vhj7+OPP/YkeU899ZT38ccfe//+9789z/O8//u///OGDx/u7dixwzt48KA3Z84cLy8vzzt16pTjlfev8+2H1tZW76GHHvIqKyu92tpa79133/W+973veddcc43X3t7ueun9ZunSpV4wGPTKysq8hoaGvtPJkyf7LrNkyRJv9OjR3u7du719+/Z5U6dO9aZOnepw1f3vQvuhurrae/LJJ719+/Z5tbW13o4dO7yxY8d606dPd7zySAOigDzP8/7whz94o0eP9pKTk72bbrrJ27Nnj+sl+W7BggVedna2l5yc7F155ZXeggULvOrqatfLirr33nvPk3TGaeHChZ7nnX4r9uOPP+5lZmZ6gUDAmzlzpldVVeV20VFwvv1w8uRJr6ioyBs5cqSXlJTkjRkzxrv//vsH3Q9pZ7v+krzNmzf3XebUqVPeL37xC++KK67wLrvsMu+OO+7wGhoa3C06Ci60H+rq6rzp06d7aWlpXiAQ8K6++mrv4Ycf9kKhkNuFfwN/jgEA4ETMvwYEABicKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAODE/wNFXpPtfmQyvwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.min(x_train2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhuRFc0ro5T_",
        "outputId": "fa0685b7-8209-4b66-c3e2-708e024867b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    }
  ]
}