{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aetev/Learning-stuff-/blob/main/wganworkking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiqIzzIPybri",
        "outputId": "311eb3c3-0802-45b2-86b3-ab52e56ba627"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xI7rEeMMgDQI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgyl_WtbgO5k",
        "outputId": "404ac082-f494-4951-a009-d49e4a9bbf5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "kik7wQ1qgOV-"
      },
      "outputs": [],
      "source": [
        "def make_generator_model():\n",
        "    input_noise = layers.Input(shape=(100,))\n",
        "    noise = layers.Dense(7*7*128)(input_noise)\n",
        "    noise = layers.Reshape((7, 7, 128))(noise)\n",
        "\n",
        "    input_digit = layers.Input(shape=(1,))\n",
        "    digit = layers.Embedding(10, 49)(input_digit)\n",
        "    digit = layers.Reshape((7, 7, 1))(digit)\n",
        "\n",
        "    x = layers.concatenate([noise, digit])\n",
        "\n",
        "    x = layers.Conv2DTranspose(128,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.Conv2DTranspose(128,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.Conv2D(1,3,1,padding='same',activation='sigmoid')(x)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=(input_noise,input_digit), outputs=x)\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "\n",
        "def make_discriminator_model():\n",
        "    input_img = layers.Input(shape=(28,28,1))\n",
        "\n",
        "    input_digit = layers.Input(shape=(1,))\n",
        "    digit = layers.Embedding(10, 28*28)(input_digit)\n",
        "    digit = layers.Reshape((28, 28, 1))(digit)\n",
        "\n",
        "    x = layers.concatenate([input_img, digit])\n",
        "\n",
        "    x = layers.Conv2D(256,5,2,padding='same',activation='LeakyReLU')(input_img)\n",
        "\n",
        "    x = layers.Dropout(.6)(x)\n",
        "\n",
        "    x = layers.Conv2D(256,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.Dropout(.6)(x)\n",
        "\n",
        "    x = layers.Conv2D(256,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.Dropout(.6)(x)\n",
        "\n",
        "    x = layers.Conv2D(256,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.Dropout(.6)(x)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "\n",
        "    dense_output = layers.Dense(128, activation='LeakyReLU')(x)\n",
        "\n",
        "\n",
        "    x = layers.Dropout(.6)(x)\n",
        "\n",
        "    dense_output = layers.Dense(64, activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.Dropout(.6)(x)\n",
        "\n",
        "    dense_output = layers.Dense(1, activation=None)(dense_output)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=(input_img,input_digit), outputs=dense_output)\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qzdSabqdVu_H"
      },
      "outputs": [],
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "lS0DF8rjhHdY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "101df663-0b24-47d1-d11b-6276f138cb37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_12\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_43 (InputLayer)       [(None, 100)]                0         []                            \n",
            "                                                                                                  \n",
            " input_44 (InputLayer)       [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " dense_38 (Dense)            (None, 6272)                 633472    ['input_43[0][0]']            \n",
            "                                                                                                  \n",
            " embedding_11 (Embedding)    (None, 1, 49)                490       ['input_44[0][0]']            \n",
            "                                                                                                  \n",
            " reshape_22 (Reshape)        (None, 7, 7, 128)            0         ['dense_38[0][0]']            \n",
            "                                                                                                  \n",
            " reshape_23 (Reshape)        (None, 7, 7, 1)              0         ['embedding_11[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_11 (Concatenat  (None, 7, 7, 129)            0         ['reshape_22[0][0]',          \n",
            " e)                                                                  'reshape_23[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose_10 (Conv2  (None, 14, 14, 128)          148736    ['concatenate_11[0][0]']      \n",
            " DTranspose)                                                                                      \n",
            "                                                                                                  \n",
            " conv2d_transpose_11 (Conv2  (None, 28, 28, 128)          147584    ['conv2d_transpose_10[0][0]'] \n",
            " DTranspose)                                                                                      \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)          (None, 28, 28, 1)            1153      ['conv2d_transpose_11[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 931435 (3.55 MB)\n",
            "Trainable params: 931435 (3.55 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "generator = make_generator_model()\n",
        "discriminatorW = make_discriminator_model()\n",
        "discriminatorU = make_discriminator_model()\n",
        "generator_optimizer = tf.keras.optimizers.Adam(0.0004)\n",
        "discriminatorW_optimizer = tf.keras.optimizers.Adam(0.0004)\n",
        "discriminatorU_optimizer = tf.keras.optimizers.Adam(0.0004)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "DYQpIZyEgSlN"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "#@tf.function\n",
        "def discriminator_lossW(real_output, fake_output):\n",
        "    real_loss = tf.reduce_mean(real_output)\n",
        "    fake_loss = tf.reduce_mean(fake_output)\n",
        "    total_loss = fake_loss - real_loss\n",
        "    return total_loss\n",
        "\n",
        "#@tf.function\n",
        "def generator_lossW(fake_output):\n",
        "    return -tf.reduce_mean(fake_output)\n",
        "\n",
        "#@tf.function\n",
        "def gradient_penalty(real_images, fake_images,digits):\n",
        "    alpha = tf.random.uniform([BATCH_SIZE, 1, 1, 1], 0., 1.)\n",
        "    real_images, fake_images = tf.cast(real_images, tf.float32), tf.cast(fake_images, tf.float32)\n",
        "    interpolated_images = alpha * real_images + ((1 - alpha) * fake_images)\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(interpolated_images)\n",
        "        pred = discriminatorW((interpolated_images,digits), training=True)\n",
        "    gradients = tape.gradient(pred, [interpolated_images])[0]\n",
        "    norm = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis=[1, 2, 3]))\n",
        "    gp = tf.reduce_mean((norm - 1.)**2)\n",
        "    return gp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "cP3-wZztEeaE"
      },
      "outputs": [],
      "source": [
        "NOISE_DIM = 100\n",
        "GP_WEIGHT = 10\n",
        "\n",
        "\n",
        "#@tf.function\n",
        "def train_step(images,digits):\n",
        "\n",
        "\n",
        "    for i in range(3):\n",
        "      with tf.GradientTape() as disc_tapeU:\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        real_outputU = discriminatorU((images,digits), training=True)\n",
        "        fake_outputU = discriminatorU((generated_images,digits), training=True)\n",
        "        disc_lossU = cross_entropy(tf.ones_like(real_outputU), real_outputU)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      gradients_of_discriminatorU = disc_tapeU.gradient(disc_lossU, discriminatorU.trainable_variables)\n",
        "      discriminatorU_optimizer.apply_gradients(zip(gradients_of_discriminatorU, discriminatorU.trainable_variables))\n",
        "      if i == 0:\n",
        "        weights = discriminatorU.get_weights()\n",
        "\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tapeW:\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        real_outputW = discriminatorW((images,digits), training=True)\n",
        "        fake_outputW = discriminatorW((generated_images,digits), training=True)\n",
        "        real_outputU = discriminatorU((images,digits), training=True)\n",
        "        fake_outputU = discriminatorU((generated_images,digits), training=True)\n",
        "        disc_lossW = discriminator_lossW(real_outputW, fake_outputW)\n",
        "\n",
        "\n",
        "        gen_lossU = cross_entropy(tf.ones_like(fake_outputU), fake_outputU)\n",
        "        gen_lossW = generator_lossW(fake_outputW)\n",
        "        gen_loss = gen_lossW+gen_lossU\n",
        "\n",
        "        gp = gradient_penalty(images, generated_images, digits)\n",
        "        disc_lossW += gp * GP_WEIGHT\n",
        "\n",
        "\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    gradients_of_discriminatorW = disc_tapeW.gradient(disc_lossW, discriminatorW.trainable_variables)\n",
        "    discriminatorW_optimizer.apply_gradients(zip(gradients_of_discriminatorW, discriminatorW.trainable_variables))\n",
        "\n",
        "    discriminatorU.set_weights(weights)\n",
        "\n",
        "    tf.print(\"disc_lossW\",disc_lossW,'disc_lossU',disc_lossU,'gen_lossU',gen_lossU,'gen_lossW',gen_lossW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "Sx_KbIfjiogE"
      },
      "outputs": [],
      "source": [
        "def train(dataset,y_train, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    for batch in range(len(dataset) // BATCH_SIZE):\n",
        "\n",
        "            target_images = dataset[batch * BATCH_SIZE: (batch+1) * BATCH_SIZE]\n",
        "            digits = y_train[batch * BATCH_SIZE: (batch+1) * BATCH_SIZE]\n",
        "\n",
        "            train_step(target_images,digits)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      print(epoch)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWp_3RkPg248",
        "outputId": "d196d775-7802-4fd2-a73e-cc7c59bafab9",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "disc_lossW -1.38501549 disc_lossU 2.49720188e-07 gen_lossU 0.00262015965 gen_lossW 1.64432669\n",
            "disc_lossW -1.37870407 disc_lossU 3.1147033e-07 gen_lossU 0.000263363938 gen_lossW 1.77308631\n",
            "disc_lossW -1.68428087 disc_lossU 2.63864479e-07 gen_lossU 0.000256999629 gen_lossW 1.68128967\n",
            "disc_lossW -2.16783071 disc_lossU 6.02623818e-09 gen_lossU 0.000441346929 gen_lossW 2.76387548\n",
            "disc_lossW -1.56852233 disc_lossU 7.80693085e-07 gen_lossU 0.00125292048 gen_lossW 2.73051262\n",
            "disc_lossW -2.319345 disc_lossU 1.7483103e-08 gen_lossU 0.0012799378 gen_lossW 3.51393747\n",
            "disc_lossW -1.87655199 disc_lossU 5.44313536e-07 gen_lossU 0.000226488759 gen_lossW 3.45790291\n",
            "disc_lossW -1.54369509 disc_lossU 2.61064747e-06 gen_lossU 3.43687e-05 gen_lossW 3.94073725\n",
            "disc_lossW -2.00138545 disc_lossU 1.01819e-06 gen_lossU 0.000237562563 gen_lossW 4.65354061\n",
            "disc_lossW -0.939971268 disc_lossU 1.14563056e-06 gen_lossU 6.56009252e-06 gen_lossW 4.32209921\n",
            "disc_lossW -1.04573464 disc_lossU 2.86265504e-07 gen_lossU 0.000221435592 gen_lossW 4.01777697\n",
            "disc_lossW -0.391711146 disc_lossU 4.12812642e-06 gen_lossU 2.42776186e-05 gen_lossW 4.40635109\n",
            "disc_lossW -1.5796262 disc_lossU 1.24975273e-07 gen_lossU 2.91654087e-05 gen_lossW 4.58814144\n",
            "disc_lossW -0.739693463 disc_lossU 2.29645458e-08 gen_lossU 0.000452354114 gen_lossW 3.79341984\n",
            "disc_lossW -0.877896667 disc_lossU 2.3082049e-07 gen_lossU 0.00186274329 gen_lossW 3.12647581\n",
            "disc_lossW -0.725797534 disc_lossU 1.16334231e-05 gen_lossU 3.14289646e-05 gen_lossW 2.43701267\n",
            "disc_lossW -1.22603559 disc_lossU 2.90028652e-06 gen_lossU 0.00132812373 gen_lossW 2.75401402\n",
            "disc_lossW -0.919548392 disc_lossU 1.66963741e-06 gen_lossU 0.000512490922 gen_lossW 2.12166214\n",
            "disc_lossW -1.4819715 disc_lossU 1.17806781e-06 gen_lossU 0.000681712525 gen_lossW 2.27855253\n",
            "disc_lossW -0.715943813 disc_lossU 2.3411161e-07 gen_lossU 0.00031704962 gen_lossW 1.71477187\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 100\n",
        "x_train2 = np.expand_dims(x_train, axis=-1)\n",
        "x_train2 = (x_train2 - np.min(x_train2)) / (np.max(x_train2) - np.min(x_train2))\n",
        "train(x_train2,y_train, EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "9vPp5AiDkrAF",
        "outputId": "d3c29837-971e-46a2-b4f8-9b3e038eaa54",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 29ms/step\n",
            "tf.Tensor([5], shape=(1,), dtype=int32)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "noise = tf.random.normal(shape=(1,100))\n",
        "random_number = tf.random.uniform(shape=[1,], minval=0, maxval=10, dtype=tf.int32)\n",
        "test = generator.predict((noise,random_number))\n",
        "print(random_number)\n",
        "plt.imshow(test.squeeze(), cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhuRFc0ro5T_"
      },
      "outputs": [],
      "source": [
        "print(np.min(x_train2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojIuJFIAybro"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}