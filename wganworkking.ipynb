{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aetev/Learning-stuff-/blob/main/wganworkking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiqIzzIPybri",
        "outputId": "481659b4-cd1c-4aaa-8c9d-b495ca317750"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "metadata": {
        "id": "xI7rEeMMgDQI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "metadata": {
        "id": "qgyl_WtbgO5k"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 279,
      "metadata": {
        "id": "kik7wQ1qgOV-"
      },
      "outputs": [],
      "source": [
        "def make_generator_model():\n",
        "    input_noise = layers.Input(shape=(100,))\n",
        "    noise = layers.Dense(7*7*64)(input_noise)\n",
        "    noise = layers.Reshape((7, 7, 64))(noise)\n",
        "\n",
        "    input_digit = layers.Input(shape=(1,))\n",
        "    digit = layers.Embedding(10, 49)(input_digit)\n",
        "    digit = layers.Reshape((7, 7, 1))(digit)\n",
        "\n",
        "    x = layers.concatenate([noise, digit])\n",
        "\n",
        "    x = layers.Conv2DTranspose(128,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv2DTranspose(128,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv2D(1,3,1,padding='same',activation='sigmoid')(x)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=(input_noise,input_digit), outputs=x)\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "\n",
        "def make_discriminator_model():\n",
        "    input_img = layers.Input(shape=(28,28,1))\n",
        "\n",
        "    input_digit = layers.Input(shape=(1,))\n",
        "    digit = layers.Embedding(10, 28*28)(input_digit)\n",
        "    digit = layers.Reshape((28, 28, 1))(digit)\n",
        "\n",
        "    x = layers.concatenate([input_img, digit])\n",
        "\n",
        "    x = layers.Conv2D(64,5,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.Dropout(.6)(x)\n",
        "\n",
        "    x = layers.Conv2D(64,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.Dropout(.6)(x)\n",
        "\n",
        "    x = layers.Conv2D(64,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.Dropout(.6)(x)\n",
        "\n",
        "    x = layers.Conv2D(64,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.Dropout(.6)(x)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "\n",
        "    dense_output = layers.Dense(128, activation='LeakyReLU')(x)\n",
        "\n",
        "\n",
        "    x = layers.Dropout(.6)(x)\n",
        "\n",
        "    dense_output = layers.Dense(64, activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.Dropout(.6)(x)\n",
        "\n",
        "    dense_output = layers.Dense(1, activation=None)(dense_output)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=(input_img,input_digit), outputs=dense_output)\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 280,
      "metadata": {
        "id": "qzdSabqdVu_H"
      },
      "outputs": [],
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 281,
      "metadata": {
        "id": "lS0DF8rjhHdY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64dd2571-c9e4-4c2e-dad9-eb3b9144048c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_40\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_81 (InputLayer)       [(None, 100)]                0         []                            \n",
            "                                                                                                  \n",
            " input_82 (InputLayer)       [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " dense_98 (Dense)            (None, 3136)                 316736    ['input_81[0][0]']            \n",
            "                                                                                                  \n",
            " embedding_40 (Embedding)    (None, 1, 49)                490       ['input_82[0][0]']            \n",
            "                                                                                                  \n",
            " reshape_51 (Reshape)        (None, 7, 7, 64)             0         ['dense_98[0][0]']            \n",
            "                                                                                                  \n",
            " reshape_52 (Reshape)        (None, 7, 7, 1)              0         ['embedding_40[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_40 (Concatenat  (None, 7, 7, 65)             0         ['reshape_51[0][0]',          \n",
            " e)                                                                  'reshape_52[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose_22 (Conv2  (None, 14, 14, 128)          75008     ['concatenate_40[0][0]']      \n",
            " DTranspose)                                                                                      \n",
            "                                                                                                  \n",
            " batch_normalization_10 (Ba  (None, 14, 14, 128)          512       ['conv2d_transpose_22[0][0]'] \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_23 (Conv2  (None, 28, 28, 128)          147584    ['batch_normalization_10[0][0]\n",
            " DTranspose)                                                        ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_11 (Ba  (None, 28, 28, 128)          512       ['conv2d_transpose_23[0][0]'] \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_127 (Conv2D)         (None, 28, 28, 1)            1153      ['batch_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 541995 (2.07 MB)\n",
            "Trainable params: 541483 (2.07 MB)\n",
            "Non-trainable params: 512 (2.00 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "generator = make_generator_model()\n",
        "generator_optimizer = tf.keras.optimizers.Adam(0.0004)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "discriminatorW = make_discriminator_model()\n",
        "discriminatorW_optimizer = tf.keras.optimizers.Adam(0.0004)"
      ],
      "metadata": {
        "id": "GJxNxRSHkWfl"
      },
      "execution_count": 282,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminatorU = make_discriminator_model()\n",
        "discriminatorU_optimizer = tf.keras.optimizers.Adam(0.00004)"
      ],
      "metadata": {
        "id": "6cDVGo73jfqZ"
      },
      "execution_count": 283,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 296,
      "metadata": {
        "id": "DYQpIZyEgSlN"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "@tf.function\n",
        "def discriminator_lossW(real_output, fake_output):\n",
        "    real_loss = tf.reduce_mean(real_output)\n",
        "    fake_loss = tf.reduce_mean(fake_output)\n",
        "    total_loss = fake_loss - real_loss\n",
        "    return total_loss\n",
        "\n",
        "@tf.function\n",
        "def generator_lossW(fake_output):\n",
        "    return -tf.reduce_mean(fake_output)\n",
        "\n",
        "@tf.function\n",
        "def gradient_penalty(real_images, fake_images,digits):\n",
        "    alpha = tf.random.uniform([BATCH_SIZE, 1, 1, 1], 0., 1.)\n",
        "    real_images, fake_images = tf.cast(real_images, tf.float32), tf.cast(fake_images, tf.float32)\n",
        "    interpolated_images = alpha * real_images + ((1 - alpha) * fake_images)\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(interpolated_images)\n",
        "        pred = discriminatorW((interpolated_images,digits), training=True)\n",
        "    gradients = tape.gradient(pred, [interpolated_images])[0]\n",
        "    norm = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis=[1, 2, 3]))\n",
        "    gp = tf.reduce_mean((norm - 1.)**2)\n",
        "    return gp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 295,
      "metadata": {
        "id": "cP3-wZztEeaE"
      },
      "outputs": [],
      "source": [
        "NOISE_DIM = 100\n",
        "GP_WEIGHT = 10\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def train_step(images,digits):\n",
        "\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tapeW:\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        real_outputW = discriminatorW((images,digits), training=True)\n",
        "        fake_outputW = discriminatorW((generated_images,digits), training=True)\n",
        "\n",
        "        disc_lossW = discriminator_lossW(real_outputW, fake_outputW)\n",
        "\n",
        "        gen_lossW = generator_lossW(fake_outputW)\n",
        "        gen_loss = gen_lossW\n",
        "\n",
        "        gp = gradient_penalty(images, generated_images, digits)\n",
        "        disc_lossW += gp * GP_WEIGHT\n",
        "\n",
        "\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    gradients_of_discriminatorW = disc_tapeW.gradient(disc_lossW, discriminatorW.trainable_variables)\n",
        "    discriminatorW_optimizer.apply_gradients(zip(gradients_of_discriminatorW, discriminatorW.trainable_variables))\n",
        "\n",
        "\n",
        "    tf.print(\"disc_lossW\",disc_lossW,'gen_lossW',gen_lossW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 290,
      "metadata": {
        "id": "Sx_KbIfjiogE"
      },
      "outputs": [],
      "source": [
        "def train(dataset,y_train, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    for batch in range(len(dataset) // BATCH_SIZE):\n",
        "\n",
        "            target_images = dataset[batch * BATCH_SIZE: (batch+1) * BATCH_SIZE]\n",
        "            digits = y_train[batch * BATCH_SIZE: (batch+1) * BATCH_SIZE]\n",
        "\n",
        "            train_step(target_images,digits)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      print(epoch)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWp_3RkPg248",
        "outputId": "620b308b-6641-46c5-992a-36bfaac2e988",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "disc_lossW -0.0133951306 gen_lossW 0.397389859\n",
            "disc_lossW -0.0629899502 gen_lossW 0.426635683\n",
            "disc_lossW -0.183685184 gen_lossW 0.533283\n",
            "disc_lossW -0.41259253 gen_lossW 0.786251128\n",
            "disc_lossW -0.407827884 gen_lossW 0.84758538\n",
            "disc_lossW -0.424331486 gen_lossW 0.887245238\n",
            "disc_lossW -0.17795676 gen_lossW 0.909009695\n",
            "disc_lossW -0.64380312 gen_lossW 1.49966085\n",
            "disc_lossW -0.961386085 gen_lossW 1.50764537\n",
            "disc_lossW -0.69017756 gen_lossW 1.75176919\n",
            "disc_lossW -0.242033 gen_lossW 1.77406383\n",
            "disc_lossW -0.993554354 gen_lossW 1.93364835\n",
            "disc_lossW -0.67137 gen_lossW 2.21488285\n",
            "disc_lossW -0.850276113 gen_lossW 2.60984135\n",
            "disc_lossW -1.79905081 gen_lossW 2.9215889\n",
            "disc_lossW -1.76566684 gen_lossW 3.17889476\n",
            "disc_lossW -2.24690962 gen_lossW 3.64295936\n",
            "disc_lossW -2.02468181 gen_lossW 3.51699185\n",
            "disc_lossW -2.32472253 gen_lossW 4.26765871\n",
            "disc_lossW -1.55421805 gen_lossW 3.95517564\n",
            "disc_lossW -2.48924351 gen_lossW 4.50924253\n",
            "disc_lossW -2.54937053 gen_lossW 5.09297085\n",
            "disc_lossW -2.00511527 gen_lossW 4.7922039\n",
            "disc_lossW -3.34331298 gen_lossW 5.44486141\n",
            "disc_lossW -2.48001 gen_lossW 5.4400959\n",
            "disc_lossW -2.72042036 gen_lossW 5.99445629\n",
            "disc_lossW -3.64718056 gen_lossW 5.93136644\n",
            "disc_lossW -1.79379392 gen_lossW 5.78600788\n",
            "disc_lossW -3.50060916 gen_lossW 5.90678692\n",
            "disc_lossW -3.19423914 gen_lossW 5.5872364\n",
            "disc_lossW -2.034899 gen_lossW 5.75311565\n",
            "disc_lossW -2.51584816 gen_lossW 5.26813\n",
            "disc_lossW -4.10564613 gen_lossW 5.59339714\n",
            "disc_lossW -3.77241802 gen_lossW 5.04206896\n",
            "disc_lossW -3.54054618 gen_lossW 5.21367741\n",
            "disc_lossW -3.18637705 gen_lossW 5.29341412\n",
            "disc_lossW -3.38620138 gen_lossW 4.7950387\n",
            "disc_lossW -3.54399443 gen_lossW 5.32146168\n",
            "disc_lossW -3.00299573 gen_lossW 4.9268856\n",
            "disc_lossW -2.91776562 gen_lossW 4.8299675\n",
            "disc_lossW -3.34483075 gen_lossW 5.49498367\n",
            "disc_lossW -2.51481295 gen_lossW 5.02909279\n",
            "disc_lossW -3.03595138 gen_lossW 4.38074684\n",
            "disc_lossW -2.68322539 gen_lossW 4.65929604\n",
            "disc_lossW -2.4431 gen_lossW 4.38630199\n",
            "disc_lossW -2.24304867 gen_lossW 4.56716251\n",
            "disc_lossW -3.67015266 gen_lossW 4.60060501\n",
            "disc_lossW -3.08670259 gen_lossW 4.66946745\n",
            "disc_lossW -2.70397806 gen_lossW 4.20773602\n",
            "disc_lossW -3.19132018 gen_lossW 3.76634502\n",
            "disc_lossW -3.82381177 gen_lossW 4.57703447\n",
            "disc_lossW -3.36544561 gen_lossW 4.43738031\n",
            "disc_lossW -3.51411772 gen_lossW 4.58817101\n",
            "disc_lossW -3.17620802 gen_lossW 4.57149696\n",
            "disc_lossW -3.18273067 gen_lossW 4.74022245\n",
            "disc_lossW -3.28749037 gen_lossW 5.45034122\n",
            "disc_lossW -3.82353687 gen_lossW 5.42754269\n",
            "disc_lossW -3.68081951 gen_lossW 5.80135727\n",
            "disc_lossW -4.04855585 gen_lossW 6.39644\n",
            "disc_lossW -3.83406639 gen_lossW 6.22943306\n",
            "disc_lossW -4.62406158 gen_lossW 7.50842762\n",
            "disc_lossW -3.88081264 gen_lossW 7.47142\n",
            "disc_lossW -3.66426611 gen_lossW 6.79542446\n",
            "disc_lossW -3.68245912 gen_lossW 7.21288204\n",
            "disc_lossW -3.82479596 gen_lossW 7.32453775\n",
            "disc_lossW -3.63999987 gen_lossW 7.80370045\n",
            "disc_lossW -3.12690473 gen_lossW 6.83225965\n",
            "disc_lossW -2.54930425 gen_lossW 6.60470772\n",
            "disc_lossW -3.36908412 gen_lossW 6.5862627\n",
            "disc_lossW -3.32413721 gen_lossW 6.26573086\n",
            "disc_lossW -2.84452534 gen_lossW 6.21805477\n",
            "disc_lossW -1.92527568 gen_lossW 5.48058033\n",
            "disc_lossW -3.212466 gen_lossW 5.81109142\n",
            "disc_lossW -1.87679672 gen_lossW 5.12532568\n",
            "disc_lossW -2.36479378 gen_lossW 4.84499788\n",
            "disc_lossW -3.29070282 gen_lossW 6.29819298\n",
            "disc_lossW -2.88014126 gen_lossW 5.25206089\n",
            "disc_lossW -2.65367103 gen_lossW 4.9587431\n",
            "disc_lossW -2.27317262 gen_lossW 5.42235374\n",
            "disc_lossW -1.95113778 gen_lossW 5.09652758\n",
            "disc_lossW -2.27229643 gen_lossW 5.87590694\n",
            "disc_lossW -1.92078245 gen_lossW 5.36952\n",
            "disc_lossW -2.20053816 gen_lossW 5.05983829\n",
            "disc_lossW -1.9336642 gen_lossW 5.385\n",
            "disc_lossW -1.53162587 gen_lossW 4.77918291\n",
            "disc_lossW -1.01694965 gen_lossW 4.58651447\n",
            "disc_lossW -0.727987528 gen_lossW 4.05715847\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 100\n",
        "x_train2 = np.expand_dims(x_train, axis=-1)\n",
        "x_train2 = (x_train2 - np.min(x_train2)) / (np.max(x_train2) - np.min(x_train2))\n",
        "train(x_train2,y_train, EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vPp5AiDkrAF",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "noise = tf.random.normal(shape=(1,100))\n",
        "random_number = tf.random.uniform(shape=[1,], minval=0, maxval=10, dtype=tf.int32)\n",
        "test = generator.predict((noise,random_number))\n",
        "print(random_number)\n",
        "plt.imshow(test.squeeze(), cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NOISE_DIM = 100\n",
        "GP_WEIGHT = 10\n",
        "\n",
        "\n",
        "#@tf.function\n",
        "def train_step(images,digits):\n",
        "\n",
        "\n",
        "    for i in range(3):\n",
        "      with tf.GradientTape() as disc_tapeU:\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        real_outputU = discriminatorU((images,digits), training=True)\n",
        "        fake_outputU = discriminatorU((generated_images,digits), training=True)\n",
        "        disc_lossU = cross_entropy(tf.ones_like(real_outputU), real_outputU)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      gradients_of_discriminatorU = disc_tapeU.gradient(disc_lossU, discriminatorU.trainable_variables)\n",
        "      discriminatorU_optimizer.apply_gradients(zip(gradients_of_discriminatorU, discriminatorU.trainable_variables))\n",
        "      if i == 0:\n",
        "        weights = discriminatorU.get_weights()\n",
        "\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tapeW:\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        real_outputW = discriminatorW((images,digits), training=True)\n",
        "        fake_outputW = discriminatorW((generated_images,digits), training=True)\n",
        "        real_outputU = discriminatorU((images,digits), training=True)\n",
        "        fake_outputU = discriminatorU((generated_images,digits), training=True)\n",
        "        disc_lossW = discriminator_lossW(real_outputW, fake_outputW)\n",
        "\n",
        "\n",
        "        gen_lossU = cross_entropy(tf.ones_like(fake_outputU), fake_outputU)\n",
        "        gen_lossW = generator_lossW(fake_outputW)\n",
        "        gen_loss = gen_lossU#+gen_lossW\n",
        "\n",
        "        gp = gradient_penalty(images, generated_images, digits)\n",
        "        disc_lossW += gp * GP_WEIGHT\n",
        "\n",
        "\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    gradients_of_discriminatorW = disc_tapeW.gradient(disc_lossW, discriminatorW.trainable_variables)\n",
        "    discriminatorW_optimizer.apply_gradients(zip(gradients_of_discriminatorW, discriminatorW.trainable_variables))\n",
        "\n",
        "    discriminatorU.set_weights(weights)\n",
        "\n",
        "    tf.print(\"disc_lossW\",disc_lossW,'disc_lossU',disc_lossU,'gen_lossU',gen_lossU,'gen_lossW',gen_lossW)"
      ],
      "metadata": {
        "id": "_r4IEg2iBLvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhuRFc0ro5T_"
      },
      "outputs": [],
      "source": [
        "print(np.min(x_train2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojIuJFIAybro"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}