{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aetev/Learning-stuff-/blob/main/wganworkking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 310,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiqIzzIPybri",
        "outputId": "d7d1e9ff-8fb5-4baf-f385-247cb85e3e3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 311,
      "metadata": {
        "id": "xI7rEeMMgDQI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 312,
      "metadata": {
        "id": "qgyl_WtbgO5k"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 313,
      "metadata": {
        "id": "kik7wQ1qgOV-"
      },
      "outputs": [],
      "source": [
        "def make_generator_model():\n",
        "    input_noise = layers.Input(shape=(100,))\n",
        "    noise = layers.Dense(7*7*64)(input_noise)\n",
        "    noise = layers.Reshape((7, 7, 64))(noise)\n",
        "\n",
        "    input_digit = layers.Input(shape=(1,))\n",
        "    digit = layers.Embedding(10, 49)(input_digit)\n",
        "    digit = layers.Reshape((7, 7, 1))(digit)\n",
        "\n",
        "    x = layers.concatenate([noise, digit])\n",
        "\n",
        "    x = layers.Conv2DTranspose(128,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv2DTranspose(128,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv2D(1,3,1,padding='same',activation='sigmoid')(x)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=(input_noise,input_digit), outputs=x)\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "\n",
        "def make_discriminator_model():\n",
        "    input_img = layers.Input(shape=(28,28,1))\n",
        "\n",
        "    input_digit = layers.Input(shape=(1,))\n",
        "    digit = layers.Embedding(10, 28*28)(input_digit)\n",
        "    digit = layers.Reshape((28, 28, 1))(digit)\n",
        "\n",
        "    x = layers.concatenate([input_img, digit])\n",
        "\n",
        "    x = layers.Conv2D(64,5,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "\n",
        "    x = layers.Conv2D(64,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "\n",
        "    x = layers.Conv2D(64,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "\n",
        "    x = layers.Conv2D(64,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "\n",
        "    dense_output = layers.Dense(128, activation='LeakyReLU')(x)\n",
        "\n",
        "\n",
        "\n",
        "    dense_output = layers.Dense(64, activation='LeakyReLU')(x)\n",
        "\n",
        "\n",
        "    dense_output = layers.Dense(1, activation=None)(dense_output)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=(input_img,input_digit), outputs=dense_output)\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 314,
      "metadata": {
        "id": "qzdSabqdVu_H"
      },
      "outputs": [],
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 315,
      "metadata": {
        "id": "lS0DF8rjhHdY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c44ca6ce-d389-4113-d101-8861bec41531"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_43\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_87 (InputLayer)       [(None, 100)]                0         []                            \n",
            "                                                                                                  \n",
            " input_88 (InputLayer)       [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " dense_105 (Dense)           (None, 3136)                 316736    ['input_87[0][0]']            \n",
            "                                                                                                  \n",
            " embedding_43 (Embedding)    (None, 1, 49)                490       ['input_88[0][0]']            \n",
            "                                                                                                  \n",
            " reshape_55 (Reshape)        (None, 7, 7, 64)             0         ['dense_105[0][0]']           \n",
            "                                                                                                  \n",
            " reshape_56 (Reshape)        (None, 7, 7, 1)              0         ['embedding_43[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_43 (Concatenat  (None, 7, 7, 65)             0         ['reshape_55[0][0]',          \n",
            " e)                                                                  'reshape_56[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose_24 (Conv2  (None, 14, 14, 128)          75008     ['concatenate_43[0][0]']      \n",
            " DTranspose)                                                                                      \n",
            "                                                                                                  \n",
            " batch_normalization_12 (Ba  (None, 14, 14, 128)          512       ['conv2d_transpose_24[0][0]'] \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_25 (Conv2  (None, 28, 28, 128)          147584    ['batch_normalization_12[0][0]\n",
            " DTranspose)                                                        ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_13 (Ba  (None, 28, 28, 128)          512       ['conv2d_transpose_25[0][0]'] \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_136 (Conv2D)         (None, 28, 28, 1)            1153      ['batch_normalization_13[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 541995 (2.07 MB)\n",
            "Trainable params: 541483 (2.07 MB)\n",
            "Non-trainable params: 512 (2.00 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "generator = make_generator_model()\n",
        "generator_optimizer = tf.keras.optimizers.Adam(0.0004)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "discriminatorW = make_discriminator_model()\n",
        "discriminatorW_optimizer = tf.keras.optimizers.Adam(0.0004)"
      ],
      "metadata": {
        "id": "GJxNxRSHkWfl"
      },
      "execution_count": 316,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminatorU = make_discriminator_model()\n",
        "discriminatorU_optimizer = tf.keras.optimizers.Adam(0.00004)"
      ],
      "metadata": {
        "id": "6cDVGo73jfqZ"
      },
      "execution_count": 317,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 318,
      "metadata": {
        "id": "DYQpIZyEgSlN"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "@tf.function\n",
        "def discriminator_lossW(real_output, fake_output):\n",
        "    real_loss = tf.reduce_mean(real_output)\n",
        "    fake_loss = tf.reduce_mean(fake_output)\n",
        "    total_loss = fake_loss - real_loss\n",
        "    return total_loss\n",
        "\n",
        "@tf.function\n",
        "def generator_lossW(fake_output):\n",
        "    return -tf.reduce_mean(fake_output)\n",
        "\n",
        "@tf.function\n",
        "def gradient_penalty(real_images, fake_images,digits):\n",
        "    alpha = tf.random.uniform([BATCH_SIZE, 1, 1, 1], 0., 1.)\n",
        "    real_images, fake_images = tf.cast(real_images, tf.float32), tf.cast(fake_images, tf.float32)\n",
        "    interpolated_images = alpha * real_images + ((1 - alpha) * fake_images)\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(interpolated_images)\n",
        "        pred = discriminatorW((interpolated_images,digits), training=True)\n",
        "    gradients = tape.gradient(pred, [interpolated_images])[0]\n",
        "    norm = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis=[1, 2, 3]))\n",
        "    gp = tf.reduce_mean((norm - 1.)**2)\n",
        "    return gp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 319,
      "metadata": {
        "id": "cP3-wZztEeaE"
      },
      "outputs": [],
      "source": [
        "NOISE_DIM = 100\n",
        "GP_WEIGHT = 10\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def train_step(images,digits):\n",
        "\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tapeW:\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        real_outputW = discriminatorW((images,digits), training=True)\n",
        "        fake_outputW = discriminatorW((generated_images,digits), training=True)\n",
        "\n",
        "        disc_lossW = discriminator_lossW(real_outputW, fake_outputW)\n",
        "\n",
        "        gen_lossW = generator_lossW(fake_outputW)\n",
        "        gen_loss = gen_lossW\n",
        "\n",
        "        gp = gradient_penalty(images, generated_images, digits)\n",
        "        disc_lossW += gp * GP_WEIGHT\n",
        "\n",
        "\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    gradients_of_discriminatorW = disc_tapeW.gradient(disc_lossW, discriminatorW.trainable_variables)\n",
        "    discriminatorW_optimizer.apply_gradients(zip(gradients_of_discriminatorW, discriminatorW.trainable_variables))\n",
        "\n",
        "\n",
        "    tf.print(\"disc_lossW\",disc_lossW,'gen_lossW',gen_lossW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 320,
      "metadata": {
        "id": "Sx_KbIfjiogE"
      },
      "outputs": [],
      "source": [
        "def train(dataset,y_train, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    for batch in range(len(dataset) // BATCH_SIZE):\n",
        "\n",
        "            target_images = dataset[batch * BATCH_SIZE: (batch+1) * BATCH_SIZE]\n",
        "            digits = y_train[batch * BATCH_SIZE: (batch+1) * BATCH_SIZE]\n",
        "\n",
        "            train_step(target_images,digits)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      print(epoch)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWp_3RkPg248",
        "outputId": "dce42cc2-39af-459d-bf55-b150f2c17ae5",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "disc_lossW -2.12369704 gen_lossW 8.51296711\n",
            "disc_lossW -2.16908646 gen_lossW 8.52337646\n",
            "disc_lossW -1.91314578 gen_lossW 8.0558176\n",
            "disc_lossW -1.8413471 gen_lossW 8.04322433\n",
            "disc_lossW -1.88835108 gen_lossW 7.70927954\n",
            "disc_lossW -1.71988547 gen_lossW 7.59381485\n",
            "disc_lossW -1.69223928 gen_lossW 7.42640877\n",
            "disc_lossW -1.55580807 gen_lossW 7.25116348\n",
            "disc_lossW -1.18684638 gen_lossW 7.02458191\n",
            "disc_lossW -1.24465382 gen_lossW 6.79407024\n",
            "disc_lossW -0.946729839 gen_lossW 6.63072205\n",
            "disc_lossW -0.463275582 gen_lossW 6.1994257\n",
            "disc_lossW -0.6266 gen_lossW 5.76452637\n",
            "disc_lossW -0.549381 gen_lossW 5.28021479\n",
            "disc_lossW -0.573956549 gen_lossW 4.77772713\n",
            "disc_lossW -0.687951744 gen_lossW 4.33458424\n",
            "disc_lossW -0.920193553 gen_lossW 4.01106834\n",
            "disc_lossW -0.900707364 gen_lossW 3.70141292\n",
            "disc_lossW -0.754549 gen_lossW 3.41852617\n",
            "disc_lossW -0.509495139 gen_lossW 2.95297551\n",
            "disc_lossW -0.920658886 gen_lossW 2.47918415\n",
            "disc_lossW -1.17314672 gen_lossW 2.17635965\n",
            "disc_lossW -0.733839095 gen_lossW 1.54584956\n",
            "disc_lossW -0.985143244 gen_lossW 1.53675175\n",
            "disc_lossW -0.842457414 gen_lossW 1.37661135\n",
            "disc_lossW -0.649007797 gen_lossW 1.34112251\n",
            "disc_lossW -0.18849802 gen_lossW 1.40887892\n",
            "disc_lossW -0.0827860832 gen_lossW 1.46649\n",
            "disc_lossW -0.150668621 gen_lossW 2.0281\n",
            "disc_lossW -0.442011356 gen_lossW 1.67533898\n",
            "disc_lossW -1.25768828 gen_lossW 1.70182252\n",
            "disc_lossW -2.06321502 gen_lossW 1.7475822\n",
            "disc_lossW -2.14551187 gen_lossW 1.59008431\n",
            "disc_lossW -1.96797431 gen_lossW 1.24152374\n",
            "disc_lossW -2.05020571 gen_lossW 1.07298732\n",
            "disc_lossW -2.52547455 gen_lossW 1.06623173\n",
            "disc_lossW -2.49717426 gen_lossW 0.92033428\n",
            "disc_lossW -3.11588979 gen_lossW 1.28389835\n",
            "disc_lossW -3.05225682 gen_lossW 0.966419339\n",
            "disc_lossW -2.89174509 gen_lossW 0.952891231\n",
            "disc_lossW -2.37185621 gen_lossW 0.92357856\n",
            "disc_lossW -2.47041059 gen_lossW 1.28019\n",
            "disc_lossW -1.78688228 gen_lossW 1.75910044\n",
            "disc_lossW -1.90740347 gen_lossW 1.93720782\n",
            "disc_lossW -1.98680377 gen_lossW 2.24666047\n",
            "disc_lossW -1.67979574 gen_lossW 2.36315775\n",
            "disc_lossW -1.547436 gen_lossW 2.58263\n",
            "disc_lossW -1.29995191 gen_lossW 2.88885736\n",
            "disc_lossW -1.15583026 gen_lossW 3.03656888\n",
            "disc_lossW -1.07776606 gen_lossW 3.33970308\n",
            "disc_lossW -1.02213633 gen_lossW 3.88297606\n",
            "disc_lossW -1.18716 gen_lossW 4.39097\n",
            "disc_lossW -1.06270587 gen_lossW 5.07726431\n",
            "disc_lossW -1.21433878 gen_lossW 5.65560818\n",
            "disc_lossW -1.10683715 gen_lossW 6.00527\n",
            "disc_lossW -0.333068192 gen_lossW 6.07744312\n",
            "disc_lossW -0.656059 gen_lossW 6.78707886\n",
            "disc_lossW -0.815262079 gen_lossW 6.98537207\n",
            "disc_lossW -0.811352313 gen_lossW 6.67565918\n",
            "disc_lossW -0.785342693 gen_lossW 6.34704685\n",
            "disc_lossW -0.911485851 gen_lossW 6.2606082\n",
            "disc_lossW -0.792756498 gen_lossW 6.11762142\n",
            "disc_lossW -0.886711955 gen_lossW 6.24069214\n",
            "disc_lossW -0.679195404 gen_lossW 6.40345907\n",
            "disc_lossW -0.551506877 gen_lossW 6.26919651\n",
            "disc_lossW -1.17406809 gen_lossW 7.1404357\n",
            "disc_lossW 0.00388708711 gen_lossW 6.60065556\n",
            "disc_lossW -0.782149196 gen_lossW 7.48446703\n",
            "disc_lossW -0.595481694 gen_lossW 7.43081951\n",
            "disc_lossW -0.970174491 gen_lossW 8.2302\n",
            "disc_lossW -0.413439274 gen_lossW 8.48548889\n",
            "disc_lossW -0.301958114 gen_lossW 8.12489891\n",
            "disc_lossW 0.479903102 gen_lossW 7.74869633\n",
            "disc_lossW -0.022208523 gen_lossW 8.2543869\n",
            "disc_lossW -0.668133616 gen_lossW 7.84197474\n",
            "disc_lossW -0.69781363 gen_lossW 8.0456028\n",
            "disc_lossW -0.987641215 gen_lossW 8.11006546\n",
            "disc_lossW -0.782086194 gen_lossW 8.1130209\n",
            "disc_lossW -0.960638762 gen_lossW 8.60753632\n",
            "disc_lossW -0.927150726 gen_lossW 9.05500412\n",
            "disc_lossW -0.10174349 gen_lossW 8.24138451\n",
            "disc_lossW -0.873843193 gen_lossW 8.77685\n",
            "disc_lossW -0.281649351 gen_lossW 7.87391758\n",
            "disc_lossW -0.98397696 gen_lossW 8.08734894\n",
            "disc_lossW -0.601187468 gen_lossW 7.1244216\n",
            "disc_lossW -0.829017639 gen_lossW 6.52266359\n",
            "disc_lossW -1.24629962 gen_lossW 6.03236485\n",
            "disc_lossW -1.25543463 gen_lossW 5.37724\n",
            "disc_lossW -1.02466643 gen_lossW 4.43395615\n",
            "disc_lossW -1.4848299 gen_lossW 4.48627663\n",
            "disc_lossW -1.58238757 gen_lossW 3.91241837\n",
            "disc_lossW -1.37888741 gen_lossW 3.50262976\n",
            "disc_lossW -1.4300108 gen_lossW 3.26265121\n",
            "disc_lossW -1.67309296 gen_lossW 3.40858603\n",
            "disc_lossW -1.50947332 gen_lossW 2.69553137\n",
            "disc_lossW -2.03931737 gen_lossW 2.84328771\n",
            "disc_lossW -2.01660633 gen_lossW 2.39800715\n",
            "disc_lossW -1.89189827 gen_lossW 2.08336186\n",
            "disc_lossW -2.15402842 gen_lossW 2.12833858\n",
            "disc_lossW -2.07292 gen_lossW 1.77949941\n",
            "disc_lossW -2.66205096 gen_lossW 2.39642501\n",
            "disc_lossW -2.26742792 gen_lossW 2.03003144\n",
            "disc_lossW -1.70372629 gen_lossW 1.47818625\n",
            "disc_lossW -2.23262835 gen_lossW 2.35297871\n",
            "disc_lossW -1.44471514 gen_lossW 2.21774578\n",
            "disc_lossW -1.22204936 gen_lossW 2.63789368\n",
            "disc_lossW -1.2482096 gen_lossW 3.11677027\n",
            "disc_lossW -0.914574921 gen_lossW 3.56512022\n",
            "disc_lossW -1.62277055 gen_lossW 5.04700422\n",
            "disc_lossW -1.1871984 gen_lossW 5.29848814\n",
            "disc_lossW -1.12389803 gen_lossW 5.95892429\n",
            "disc_lossW -1.50307131 gen_lossW 6.94510555\n",
            "disc_lossW -0.971004963 gen_lossW 7.40807629\n",
            "disc_lossW -1.11526477 gen_lossW 8.56810284\n",
            "disc_lossW -1.63817298 gen_lossW 9.54322529\n",
            "disc_lossW -1.73826098 gen_lossW 10.6128368\n",
            "disc_lossW -1.38693237 gen_lossW 11.3577976\n",
            "disc_lossW -1.38500702 gen_lossW 11.9746666\n",
            "disc_lossW -1.46152294 gen_lossW 12.6513014\n",
            "disc_lossW -1.03663838 gen_lossW 12.9722271\n",
            "disc_lossW -0.903003335 gen_lossW 13.0039253\n",
            "disc_lossW -0.953930497 gen_lossW 13.3065834\n",
            "disc_lossW -0.504407346 gen_lossW 13.0858278\n",
            "disc_lossW 0.0226909053 gen_lossW 12.7693577\n",
            "disc_lossW 0.338700324 gen_lossW 12.4756517\n",
            "disc_lossW 0.191812068 gen_lossW 12.1966515\n",
            "disc_lossW 0.369108379 gen_lossW 11.7405415\n",
            "disc_lossW -0.151150599 gen_lossW 11.6004257\n",
            "disc_lossW -0.342151761 gen_lossW 11.6561699\n",
            "disc_lossW 0.374380648 gen_lossW 11.6769428\n",
            "disc_lossW 0.359910965 gen_lossW 11.5505009\n",
            "disc_lossW -0.00389111694 gen_lossW 11.9257803\n",
            "disc_lossW 1.06357706 gen_lossW 11.6768265\n",
            "disc_lossW 0.673740864 gen_lossW 11.0146646\n",
            "disc_lossW -0.158116102 gen_lossW 11.0684681\n",
            "disc_lossW -0.313383341 gen_lossW 10.424881\n",
            "disc_lossW -0.0563616082 gen_lossW 9.51235294\n",
            "disc_lossW -0.151107654 gen_lossW 9.13543129\n",
            "disc_lossW -0.199224472 gen_lossW 8.52686119\n",
            "disc_lossW -0.969149828 gen_lossW 8.20219803\n",
            "disc_lossW -0.872231364 gen_lossW 7.63779831\n",
            "disc_lossW -1.05430508 gen_lossW 7.13221169\n",
            "disc_lossW -0.938870668 gen_lossW 6.97759104\n",
            "disc_lossW -1.1707114 gen_lossW 6.51397419\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 100\n",
        "x_train2 = np.expand_dims(x_train, axis=-1)\n",
        "x_train2 = (x_train2 - np.min(x_train2)) / (np.max(x_train2) - np.min(x_train2))\n",
        "train(x_train2,y_train, EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 327,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "9vPp5AiDkrAF",
        "outputId": "7852752f-89e4-46bc-d6fd-5acd4f7d92ed",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 27ms/step\n",
            "tf.Tensor([4], shape=(1,), dtype=int32)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAkl0lEQVR4nO3dfWzV5f3/8dehtKc3tKeU2p52FFbwBhVhE5URlC+OhhsT4w3LvPsDncHIihGZ07B475JumqjRICZmg5l4SyIQzcamKGU6cBN1xN00gnVgoKBIzym9p+f6/cGPauWu19v2XG15PpKT2NPPm+v6XOdzzsvT8/m8T8Q55wQAQJoNCz0BAMCpiQACAARBAAEAgiCAAABBEEAAgCAIIABAEAQQACAIAggAEMTw0BP4tlQqpd27dys/P1+RSCT0dAAAnpxzampqUnl5uYYNO/77nAEXQLt371ZFRUXoaQAAvqNdu3Zp9OjRx/39gAug/Px8SdLYsWNPmJzf1tLS4j1WU1OTd40k5eTkeNccOnTIu2b4cP+Hp7m52bvGsj/S4f/LSQfL2mVkZJjGsuxTZmamd01ra6t3TTQa9a7p6uryrpHs6+fL8leOjo4O7xrr/qRSKe8ay/PWwuf18Zva29u9a0pKSry2T6VS+uyzz7pfz4+n31Zq+fLlevTRR9XQ0KDJkyfrqaee0kUXXXTSuiMH5LBhw7wW2PJgWP/El66x0jXOQP9T50Dfp4F8PFheQKX0rd9AP8bTNVa6joeBNla/nITw8ssva+nSpbr//vv1wQcfaPLkyZozZ4727dvXH8MBAAahfgmgxx57TAsXLtRNN92kc845R88884xyc3P1+9//vj+GAwAMQn0eQB0dHdq6dauqqqq+HmTYMFVVVWnz5s1Hbd/e3q5kMtnjBgAY+vo8gL788kt1dXWptLS0x/2lpaVqaGg4avuamhrFYrHuG2fAAcCpIfiFqMuWLVMikei+7dq1K/SUAABp0OdnwRUXFysjI0N79+7tcf/evXsVj8eP2j4ajZpOLwUADG59/g4oKytLU6ZM0YYNG7rvS6VS2rBhg6ZNm9bXwwEABql+uQ5o6dKlWrBggS644AJddNFFeuKJJ9Tc3KybbrqpP4YDAAxC/RJA11xzjb744gvdd999amho0A9+8AOtX7/+qBMTAACnrohLVz+VXkomk4rFYiotLfW6+jaRSHiPZb26N12tYSxXsVv2qbOz07tGsrUcsRxu6WrXIknZ2dneNZZ2N5a1s7RQSWdLonR1arAcD+lsSZSutluWcSTbPvk+L5xz3SeWFRQUHHe74GfBAQBOTQQQACAIAggAEAQBBAAIggACAARBAAEAgiCAAABBEEAAgCAIIABAEAQQACAIAggAEAQBBAAIol+6YfeFzs5Or+aGlkaI1oaVlmaIlsaBlnHa2tq8ayyNECXbPlkep3Tuk6Xhp2Ws1tZW7xpLE0lrE07L42RZu8zMTO+adDUDlmyvEelqYGptpmxZ8/7COyAAQBAEEAAgCAIIABAEAQQACIIAAgAEQQABAIIggAAAQRBAAIAgCCAAQBAEEAAgCAIIABAEAQQACIIAAgAEMWC7YWdnZ3t1e7V0TM7KyvKukdLX9dfSyTg7O9u7prOz07tGSl8n49zcXO8aa6dzy1jp6mxt6X5s6agu2Y5xy/MplUp516TruEvnWJa1s3Y6tzzffY8951zv/l3vmQAA0AcIIABAEAQQACAIAggAEAQBBAAIggACAARBAAEAgiCAAABBEEAAgCAIIABAEAQQACAIAggAEMSAbUba2trq1Uixt83vvqmlpcW7RpKGD/dfNkvjQEsjSUsTSUtjTCk9TQ0l2+NkbTRreZwsDUwXLVrkXfPkk09611ia9Eq2JpxFRUXeNQcOHPCusTT7tBx3UvqeT5Z9sjaatTTqjUajprFOhndAAIAgCCAAQBAEEAAgCAIIABAEAQQACIIAAgAEQQABAIIggAAAQRBAAIAgCCAAQBAEEAAgCAIIABBExFm6ePajZDKpWCymeDzu1UDQ0tTQ2oTT0uDR0sA0lUp511iaSFqaE0pSTk6Od41l7bKzs71rLI1SJam4uNi7xtIs1dL01FJjaXIp2Zr7Wlj2yXKMW48Hy2tEupp9Wh9by2uR7zo459Tc3KxEIqGCgoLjbsc7IABAEAQQACCIPg+gBx54QJFIpMdtwoQJfT0MAGCQ65cvpDv33HP15ptvfj2I4W+OAIChrV+SYfjw4YrH4/3xTwMAhoh++Qzok08+UXl5ucaNG6cbbrhBO3fuPO627e3tSiaTPW4AgKGvzwNo6tSpWrVqldavX68VK1aovr5el1xyiZqamo65fU1NjWKxWPetoqKir6cEABiA+v06oMbGRo0dO1aPPfaYbr755qN+397ervb29u6fk8mkKioquA5IXAd0BNcB2Wu4DugwrgP62kC6Dqjfzw4oLCzUmWeeqe3btx/z99Fo1LT4AIDBrd+vAzp48KB27NihsrKy/h4KADCI9HkA3XnnnaqtrdVnn32mv/3tb7rqqquUkZGh6667rq+HAgAMYn3+J7jPP/9c1113nfbv36/TTjtNF198sbZs2aLTTjutr4cCAAxiA7YZaSwWUyQS6XWd5YM/ywfiUvourE3XB6CWD3UleT0+R1jWznKyg/Wwtnywe6IPWY/H8jg1NzenZRwry1iWY9xy3FlqJPvJC74szwvrPllObhoxYoTX9s45NTY20owUADAwEUAAgCAIIABAEAQQACAIAggAEAQBBAAIggACAARBAAEAgiCAAABBEEAAgCAIIABAEAQQACCI9HTVNMjNzfX6RtRvfqtqb+Xl5XnXWMeyfvuqr9zcXO+a1tZW01j5+flpGcvyrZnW7uuWhppfffWVd026vu3WetxZ1tzyzbWW55LlCywt6y2l7xuGLY+TdZ98Xlf728CZCQDglEIAAQCCIIAAAEEQQACAIAggAEAQBBAAIAgCCAAQBAEEAAiCAAIABEEAAQCCIIAAAEEQQACAIAggAEAQA7YbdlNTkyKRSL+O0dLSYqqzdK7t7OxMyzhNTU3eNZbuwpLU3NzsXROPx71rPv30U++aCRMmeNdItk7GOTk53jVz5szxrlmzZo13jWV/JNuxZ3k+DR/u/xJkeS5ZO0BbunWnq9u0dZyCggLvmkOHDnlt39tO3bwDAgAEQQABAIIggAAAQRBAAIAgCCAAQBAEEAAgCAIIABAEAQQACIIAAgAEQQABAIIggAAAQRBAAIAgIs45F3oS35RMJhWLxVRSUuLVbO+rr77yHsvScFHyb8wn2RoHdnV1eddYGotaGi5K0qhRo7xr2travGuys7O9a/Lz871rpN43Ufym/fv3e9dYHltLc17LOJKt4WdmZqZ3jaVZajqPccs+WY7x3Nxc7xrrY2vh23DXOafGxkYlEokTNj/lHRAAIAgCCAAQBAEEAAiCAAIABEEAAQCCIIAAAEEQQACAIAggAEAQBBAAIAgCCAAQBAEEAAiCAAIABDE89ASOp6Wlxav5oqXZp6XhonWsdDWfbGlp8a6xNPuUbA1gCwsLvWss651IJLxrJFujWcvjlK7j1bI/kjR8uP9Lg2UsyziWBqaWcSRbY1FLk2PL2lkapUrpOV5729SXd0AAgCAIIABAEN4BtGnTJl1++eUqLy9XJBLR2rVre/zeOaf77rtPZWVlysnJUVVVlT755JO+mi8AYIjwDqDm5mZNnjxZy5cvP+bvH3nkET355JN65pln9N577ykvL09z5swx/S0VADB0eX8yN2/ePM2bN++Yv3PO6YknntA999yjK664QpL03HPPqbS0VGvXrtW111773WYLABgy+vQzoPr6ejU0NKiqqqr7vlgspqlTp2rz5s3HrGlvb1cymexxAwAMfX0aQA0NDZKk0tLSHveXlpZ2/+7bampqFIvFum8VFRV9OSUAwAAV/Cy4ZcuWKZFIdN927doVekoAgDTo0wCKx+OSpL179/a4f+/evd2/+7ZoNKqCgoIeNwDA0NenAVRZWal4PK4NGzZ035dMJvXee+9p2rRpfTkUAGCQ8z4L7uDBg9q+fXv3z/X19froo49UVFSkMWPGaMmSJfr1r3+tM844Q5WVlbr33ntVXl6uK6+8si/nDQAY5LwD6P3339ell17a/fPSpUslSQsWLNCqVat01113qbm5WbfccosaGxt18cUXa/369eZ+YwCAoSninHOhJ/FNyWRSsVhM8XjcqwHevn37vMeyNA2UDl/vlA6WBqaWBoW9bRz4bdFo1LvGckGypXHnyJEjvWukw5cF+LLsk+UYKioq8q6xXgB+8OBB7xpLk8usrCzvGsvaWZ5Lkq2JqaUhcG5urneN9XlrWT/f1xXnnJLJpBKJxAk/1w9+FhwA4NREAAEAgiCAAABBEEAAgCAIIABAEAQQACAIAggAEAQBBAAIggACAARBAAEAgiCAAABBEEAAgCAIIABAEP6tXtOksbHRq7uupWuttRt2Z2end42lc61lfocOHUrLOJLU2trqXWPpfvyPf/zDu2bmzJneNZKtw/fZZ5/tXfPXv/41LeMkk0nvGkkaNWqUd82f//xn75rp06d711g6lluP8aamJu8ay2uR5TXF0iVesnVIz8vL89q+t693vAMCAARBAAEAgiCAAABBEEAAgCAIIABAEAQQACAIAggAEAQBBAAIggACAARBAAEAgiCAAABBEEAAgCAizjkXehLflEwmFYvFVFJS4tVsr7Gx0Xssn2an32RpHGhpUGhpYGoZx9LcUfJvUCjZ1i4zM9O7pqCgwLtGki699FLvmvr6eu+alpYW75qf/OQn3jV//OMfvWskafv27d41zc3N3jXpatzZ0dHhXSPZmtNaHlvLOJbXB8m25r6NT51zampqUiKROOFzkXdAAIAgCCAAQBAEEAAgCAIIABAEAQQACIIAAgAEQQABAIIggAAAQRBAAIAgCCAAQBAEEAAgCAIIABCEf1e6NGlvb/dqFpqRkeE9Rltbm3eNZGuOaen56tsAULI1FrWsnXUsSyNESyNJy9pJtsaiCxYs8K65+eabvWtuv/1275rdu3d710hSUVGRd82IESO8a7744gvvmnQeDwcPHvSusbw+pKvBsSS1trZ61xQWFnpt39tGqbwDAgAEQQABAIIggAAAQRBAAIAgCCAAQBAEEAAgCAIIABAEAQQACIIAAgAEQQABAIIggAAAQRBAAIAgBmwz0pycHK8GggcOHPAeIxqNetdI0qFDh7xrLA0Ke9vQ75ss+2TZHyl9+2Rplpqdne1dI0mXXXaZd80///lP75of/vCH3jXPPfecd01dXZ13jSRt377du6ahocG7pri42LvGcgxZGnBKUm5urneNpUmv5blkfd5aXiN896m3zZd5BwQACIIAAgAE4R1AmzZt0uWXX67y8nJFIhGtXbu2x+9vvPFGRSKRHre5c+f21XwBAEOEdwA1Nzdr8uTJWr58+XG3mTt3rvbs2dN9e/HFF7/TJAEAQ4/3SQjz5s3TvHnzTrhNNBpVPB43TwoAMPT1y2dAGzduVElJic466ywtWrRI+/fvP+627e3tSiaTPW4AgKGvzwNo7ty5eu6557Rhwwb99re/VW1trebNm6eurq5jbl9TU6NYLNZ9q6io6OspAQAGoD6/Dujaa6/t/u/zzjtPkyZN0vjx47Vx40bNmjXrqO2XLVumpUuXdv+cTCYJIQA4BfT7adjjxo1TcXHxcS9si0ajKigo6HEDAAx9/R5An3/+ufbv36+ysrL+HgoAMIh4/wnu4MGDPd7N1NfX66OPPlJRUZGKior04IMPav78+YrH49qxY4fuuusunX766ZozZ06fThwAMLh5B9D777+vSy+9tPvnI5/fLFiwQCtWrNC2bdv0hz/8QY2NjSovL9fs2bP18MMPm/uuAQCGpojrbde4NEkmk91nxEUikV7XdXZ2eo9lbVA4fHh6erj6NGM9Il2NEKXDDWN9+TymR1gai1qvQ3v22We9ayZOnOhdY9mnjRs3etdYGoRKtmak99xzj3fN6aef7l2za9cu7xrLc0myPTc6Ojq8aywvw9Z9srxW5uXleW3vnFNTU5MSicQJP9enFxwAIAgCCAAQBAEEAAiCAAIABEEAAQCCIIAAAEEQQACAIAggAEAQBBAAIAgCCAAQBAEEAAiCAAIABEEAAQCCSE9bZ4O8vDyvbq9ffPGF9xiWjsSSrdtturrqWvbJ0h1XsnXwtXTrTqVS3jUjR470rpGkc845x7umubnZu+Zf//qXd83555/vXfPuu+9610i259MFF1zgXXPaaad513z55ZfeNW1tbd41knTo0CHvmq6uLu8aS4d9y/NCkumrcXz3qbevDbwDAgAEQQABAIIggAAAQRBAAIAgCCAAQBAEEAAgCAIIABAEAQQACIIAAgAEQQABAIIggAAAQRBAAIAgBmwz0paWFkUikV5vn5GR4T2GpdmnJK8mqUdYGn5aGhRa9smyP5KtsailKetDDz3kXfPKK69410jSX/7yF++a2bNne9dMmTLFu2bdunXeNY8//rh3jWRryvrwww9719x6663eNQP9GLc8by2NfS2veZKtwWpeXp7X9s45tbS0nHQ73gEBAIIggAAAQRBAAIAgCCAAQBAEEAAgCAIIABAEAQQACIIAAgAEQQABAIIggAAAQRBAAIAgCCAAQBARZ+mC14+SyaRisZjKysq8GggeOHCgH2fVU7oai6ZSKe8anwauR1ibsubk5HjXWNahq6vLu2bkyJHeNZJ0yy23eNcUFRV517z44oveNT/72c+8a55++mnvGknat2+fd43lOVhQUOBd09jY6F1jOYak9D2fotGod41lbpKt8alvM1fnnJqbm5VIJE74GPMOCAAQBAEEAAiCAAIABEEAAQCCIIAAAEEQQACAIAggAEAQBBAAIAgCCAAQBAEEAAiCAAIABEEAAQCC8O8MmSYtLS1ezfYsjflaWlq8ayRbQ81Dhw551/g2AJSktrY27xrL/ki2ZqmWppAHDx70rrH22H3++ee9ay655BLvmjfeeMO7ZsqUKd41DQ0N3jWSlJeX513z7LPPetcsXLjQu8by2Fobd7a2tnrXpKvhrnWfLK8Rvk1je/sY8Q4IABAEAQQACMIrgGpqanThhRcqPz9fJSUluvLKK1VXV9djm7a2NlVXV2vUqFEaMWKE5s+fr7179/bppAEAg59XANXW1qq6ulpbtmzRG2+8oc7OTs2ePVvNzc3d29xxxx167bXXtHr1atXW1mr37t26+uqr+3ziAIDBzevTsvXr1/f4edWqVSopKdHWrVs1Y8YMJRIJ/e53v9MLL7ygH//4x5KklStX6uyzz9aWLVv0ox/9qO9mDgAY1L7TZ0CJRELS119JvHXrVnV2dqqqqqp7mwkTJmjMmDHavHnzMf+N9vZ2JZPJHjcAwNBnDqBUKqUlS5Zo+vTpmjhxoqTDp3xmZWWpsLCwx7alpaXHPR20pqZGsVis+1ZRUWGdEgBgEDEHUHV1tT7++GO99NJL32kCy5YtUyKR6L7t2rXrO/17AIDBwXQF4uLFi/X6669r06ZNGj16dPf98XhcHR0damxs7PEuaO/evYrH48f8t6LRqKLRqGUaAIBBzOsdkHNOixcv1po1a/TWW2+psrKyx++nTJmizMxMbdiwofu+uro67dy5U9OmTeubGQMAhgSvd0DV1dV64YUXtG7dOuXn53d/rhOLxZSTk6NYLKabb75ZS5cuVVFRkQoKCnTbbbdp2rRpnAEHAOjBK4BWrFghSZo5c2aP+1euXKkbb7xRkvT4449r2LBhmj9/vtrb2zVnzhw9/fTTfTJZAMDQEXHWro39JJlMKhaLKR6PezXj3L9/v/dY1iaclmZ+ls+5Ojo6vGss+9TZ2eldI0k5OTneNe3t7d41lrWzjCPJ9KdiS8NPS3ParKystIwjyXQ5hGXNLQ13Lc8L6zpkZGR411heHyzPJevzNjMz01TnwzmnlpYWJRKJEzYypRccACAIAggAEAQBBAAIggACAARBAAEAgiCAAABBEEAAgCAIIABAEAQQACAIAggAEAQBBAAIggACAARBAAEAghiw3bBHjBihSCTS67quri7vsSxdayVbx+lUKuVdY+nEa+kUbO2Oazl0LGtneWwtXZYl2/yKi4u9a+bOnetd8+qrr3rXtLS0eNdItnWwHA+W4zWdx4Olw7fleevzWneE9XlrWfP8/Hyv7Z1zamxspBs2AGBgIoAAAEEQQACAIAggAEAQBBAAIAgCCAAQBAEEAAiCAAIABEEAAQCCIIAAAEEQQACAIAggAEAQA7YZaUlJiVcDwWQy6T2WpQGgZGtQmJWV5V1jaWBq2SdLc0JJys7O9q5J1+Fm3ae8vLy0jeXLMrfW1lbTWOlq+GkZx9IotbOz07tGsjUWtYwVjUa9ayyvD5LtcfJdc+eckskkzUgBAAMTAQQACIIAAgAEQQABAIIggAAAQRBAAIAgCCAAQBAEEAAgCAIIABAEAQQACIIAAgAEQQABAILw7+qXJu3t7V6NNS1NLtva2rxrJFszxEOHDnnXWBohWvbJMo5k2ydLs1TLPmVmZnrXSFJzc7N3jeV4WL16tXfNT3/6U+8aaxNOyz5ZGp9aHidL89d0HuOWZp+Wx8m6T5b1822m3NvXY94BAQCCIIAAAEEQQACAIAggAEAQBBAAIAgCCAAQBAEEAAiCAAIABEEAAQCCIIAAAEEQQACAIAggAEAQEWfp4tmPksmkYrGY4vG4V1O/AwcOeI9laYwp2Zr5WZouWhohpqu5oyRFo1HvGkvTRcs4lsaYkpSTk+Ndk66GlV1dXd411mPc8jhZGpha9sm3MaZkb8pqafiZruetZRzJtk++z0HnnBKJhBKJhAoKCo67He+AAABBEEAAgCC8AqimpkYXXnih8vPzVVJSoiuvvFJ1dXU9tpk5c6YikUiP26233tqnkwYADH5eAVRbW6vq6mpt2bJFb7zxhjo7OzV79uyjvsRr4cKF2rNnT/ftkUce6dNJAwAGP69PDdevX9/j51WrVqmkpERbt27VjBkzuu/Pzc1VPB7vmxkCAIak7/QZUCKRkCQVFRX1uP/5559XcXGxJk6cqGXLlqmlpeW4/0Z7e7uSyWSPGwBg6PM/b/L/S6VSWrJkiaZPn66JEyd233/99ddr7NixKi8v17Zt23T33Xerrq5Or7766jH/nZqaGj344IPWaQAABinzdUCLFi3Sn/70J73zzjsaPXr0cbd76623NGvWLG3fvl3jx48/6vft7e1qb2/v/jmZTKqiooLrgMR1QN9lHK4DOozrgA7jOqCvDaTrgEzvgBYvXqzXX39dmzZtOmH4SNLUqVMl6bgBFI1GTS8wAIDBzSuAnHO67bbbtGbNGm3cuFGVlZUnrfnoo48kSWVlZaYJAgCGJq8Aqq6u1gsvvKB169YpPz9fDQ0NkqRYLKacnBzt2LFDL7zwgi677DKNGjVK27Zt0x133KEZM2Zo0qRJ/bIDAIDBySuAVqxYIenwxabftHLlSt14443KysrSm2++qSeeeELNzc2qqKjQ/Pnzdc899/TZhAEAQ4P3n+BOpKKiQrW1td9pQgCAU4P5NOz+1t7e7nUGj+Vsn2+efefDchaJ5Wwfy1lFln2yjGMdy3LCyYmuIzsey1lFkm2fLMdDW1ubd026zjKT0neWnmUcyxltlsdIsp1pZnmc0rlPlmM8OzvbNNbJ0IwUABAEAQQACIIAAgAEQQABAIIggAAAQRBAAIAgCCAAQBAEEAAgCAIIABAEAQQACIIAAgAEQQABAIIYsM1Ii4uLvZrtffXVV95jnOirYk/E0szP0hzT0qBwxIgR3jXWr+S2NCi0NHfMy8vzrrF+BbNlnyzHQ25urndNKpXyrrE2rDxZ5/u+kq5mn9amrJbnk+Vxsrw+WJr0SrZjLz8/32v7VCqlxsbGk27HOyAAQBAEEAAgCAIIABAEAQQACIIAAgAEQQABAIIggAAAQRBAAIAgCCAAQBAEEAAgCAIIABDEgOsFd6QHlW/vJkv/JStLnyzL/AbyONaxLDWRSMS7Jp37ZBkrXTXW50W6esFxjNtrrPuUjjU/sv3JxhpwAdTU1CRJ+vTTTwPPBAAgSQcOHDDVNTU1KRaLHff3EZeu/9XppVQqpd27dys/P/+o//NNJpOqqKjQrl27zJ2shwLW4TDW4TDW4TDW4bCBsA7OOTU1Nam8vFzDhh3/k54B9w5o2LBhGj169Am3KSgoOKUPsCNYh8NYh8NYh8NYh8NCr8OJ3vkcwUkIAIAgCCAAQBCDKoCi0ajuv/9+RaPR0FMJinU4jHU4jHU4jHU4bDCtw4A7CQEAcGoYVO+AAABDBwEEAAiCAAIABEEAAQCCGDQBtHz5cn3/+99Xdna2pk6dqr///e+hp5R2DzzwgCKRSI/bhAkTQk+r323atEmXX365ysvLFYlEtHbt2h6/d87pvvvuU1lZmXJyclRVVaVPPvkkzGT70cnW4cYbbzzq+Jg7d26YyfaTmpoaXXjhhcrPz1dJSYmuvPJK1dXV9dimra1N1dXVGjVqlEaMGKH58+dr7969gWbcP3qzDjNnzjzqeLj11lsDzfjYBkUAvfzyy1q6dKnuv/9+ffDBB5o8ebLmzJmjffv2hZ5a2p177rnas2dP9+2dd94JPaV+19zcrMmTJ2v58uXH/P0jjzyiJ598Us8884zee+895eXlac6cOWpra0vzTPvXydZBkubOndvj+HjxxRfTOMP+V1tbq+rqam3ZskVvvPGGOjs7NXv2bDU3N3dvc8cdd+i1117T6tWrVVtbq927d+vqq68OOOu+15t1kKSFCxf2OB4eeeSRQDM+DjcIXHTRRa66urr7566uLldeXu5qamoCzir97r//fjd58uTQ0whKkluzZk33z6lUysXjcffoo49239fY2Oii0ah78cUXA8wwPb69Ds45t2DBAnfFFVcEmU8o+/btc5JcbW2tc+7wY5+ZmelWr17dvc1//vMfJ8lt3rw51DT73bfXwTnn/u///s/dfvvt4SbVCwP+HVBHR4e2bt2qqqqq7vuGDRumqqoqbd68OeDMwvjkk09UXl6ucePG6YYbbtDOnTtDTymo+vp6NTQ09Dg+YrGYpk6dekoeHxs3blRJSYnOOussLVq0SPv37w89pX6VSCQkSUVFRZKkrVu3qrOzs8fxMGHCBI0ZM2ZIHw/fXocjnn/+eRUXF2vixIlatmyZWlpaQkzvuAZcM9Jv+/LLL9XV1aXS0tIe95eWluq///1voFmFMXXqVK1atUpnnXWW9uzZowcffFCXXHKJPv74Y+Xn54eeXhANDQ2SdMzj48jvThVz587V1VdfrcrKSu3YsUO/+tWvNG/ePG3evFkZGRmhp9fnUqmUlixZounTp2vixImSDh8PWVlZKiws7LHtUD4ejrUOknT99ddr7NixKi8v17Zt23T33Xerrq5Or776asDZ9jTgAwhfmzdvXvd/T5o0SVOnTtXYsWP1yiuv6Oabbw44MwwE1157bfd/n3feeZo0aZLGjx+vjRs3atasWQFn1j+qq6v18ccfnxKfg57I8dbhlltu6f7v8847T2VlZZo1a5Z27Nih8ePHp3uaxzTg/wRXXFysjIyMo85i2bt3r+LxeKBZDQyFhYU688wztX379tBTCebIMcDxcbRx48apuLh4SB4fixcv1uuvv6633367x9e3xONxdXR0qLGxscf2Q/V4ON46HMvUqVMlaUAdDwM+gLKysjRlyhRt2LCh+75UKqUNGzZo2rRpAWcW3sGDB7Vjxw6VlZWFnkowlZWVisfjPY6PZDKp995775Q/Pj7//HPt379/SB0fzjktXrxYa9as0VtvvaXKysoev58yZYoyMzN7HA91dXXauXPnkDoeTrYOx/LRRx9J0sA6HkKfBdEbL730kotGo27VqlXu3//+t7vllltcYWGha2hoCD21tPrFL37hNm7c6Orr6927777rqqqqXHFxsdu3b1/oqfWrpqYm9+GHH7oPP/zQSXKPPfaY+/DDD93//vc/55xzv/nNb1xhYaFbt26d27Ztm7viiitcZWWla21tDTzzvnWidWhqanJ33nmn27x5s6uvr3dvvvmmO//8890ZZ5zh2traQk+9zyxatMjFYjG3ceNGt2fPnu5bS0tL9za33nqrGzNmjHvrrbfc+++/76ZNm+amTZsWcNZ972TrsH37dvfQQw+5999/39XX17t169a5cePGuRkzZgSeeU+DIoCcc+6pp55yY8aMcVlZWe6iiy5yW7ZsCT2ltLvmmmtcWVmZy8rKct/73vfcNddc47Zv3x56Wv3u7bffdpKOui1YsMA5d/hU7HvvvdeVlpa6aDTqZs2a5erq6sJOuh+caB1aWlrc7Nmz3WmnneYyMzPd2LFj3cKFC4fc/6Qda/8luZUrV3Zv09ra6n7+85+7kSNHutzcXHfVVVe5PXv2hJt0PzjZOuzcudPNmDHDFRUVuWg06k4//XT3y1/+0iUSibAT/xa+jgEAEMSA/wwIADA0EUAAgCAIIABAEAQQACAIAggAEAQBBAAIggACAARBAAEAgiCAAABBEEAAgCAIIABAEAQQACCI/wc4Y6pUp11EigAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "noise = tf.random.normal(shape=(1,100))\n",
        "random_number = tf.random.uniform(shape=[1,], minval=0, maxval=10, dtype=tf.int32)\n",
        "test = generator.predict((noise,random_number))\n",
        "print(random_number)\n",
        "plt.imshow(test.squeeze(), cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NOISE_DIM = 100\n",
        "GP_WEIGHT = 10\n",
        "\n",
        "\n",
        "#@tf.function\n",
        "def train_step(images,digits):\n",
        "\n",
        "\n",
        "    for i in range(3):\n",
        "      with tf.GradientTape() as disc_tapeU:\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        real_outputU = discriminatorU((images,digits), training=True)\n",
        "        fake_outputU = discriminatorU((generated_images,digits), training=True)\n",
        "        disc_lossU = cross_entropy(tf.ones_like(real_outputU), real_outputU)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      gradients_of_discriminatorU = disc_tapeU.gradient(disc_lossU, discriminatorU.trainable_variables)\n",
        "      discriminatorU_optimizer.apply_gradients(zip(gradients_of_discriminatorU, discriminatorU.trainable_variables))\n",
        "      if i == 0:\n",
        "        weights = discriminatorU.get_weights()\n",
        "\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tapeW:\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        real_outputW = discriminatorW((images,digits), training=True)\n",
        "        fake_outputW = discriminatorW((generated_images,digits), training=True)\n",
        "        real_outputU = discriminatorU((images,digits), training=True)\n",
        "        fake_outputU = discriminatorU((generated_images,digits), training=True)\n",
        "        disc_lossW = discriminator_lossW(real_outputW, fake_outputW)\n",
        "\n",
        "\n",
        "        gen_lossU = cross_entropy(tf.ones_like(fake_outputU), fake_outputU)\n",
        "        gen_lossW = generator_lossW(fake_outputW)\n",
        "        gen_loss = gen_lossU#+gen_lossW\n",
        "\n",
        "        gp = gradient_penalty(images, generated_images, digits)\n",
        "        disc_lossW += gp * GP_WEIGHT\n",
        "\n",
        "\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    gradients_of_discriminatorW = disc_tapeW.gradient(disc_lossW, discriminatorW.trainable_variables)\n",
        "    discriminatorW_optimizer.apply_gradients(zip(gradients_of_discriminatorW, discriminatorW.trainable_variables))\n",
        "\n",
        "    discriminatorU.set_weights(weights)\n",
        "\n",
        "    tf.print(\"disc_lossW\",disc_lossW,'disc_lossU',disc_lossU,'gen_lossU',gen_lossU,'gen_lossW',gen_lossW)"
      ],
      "metadata": {
        "id": "_r4IEg2iBLvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhuRFc0ro5T_"
      },
      "outputs": [],
      "source": [
        "print(np.min(x_train2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojIuJFIAybro"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}