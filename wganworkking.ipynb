{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aetev/Learning-stuff-/blob/main/wganworkking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiqIzzIPybri",
        "outputId": "365f2c01-c474-48b9-92c4-4a20c6808d83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xI7rEeMMgDQI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgyl_WtbgO5k",
        "outputId": "b696d074-4e7c-46ef-8609-1da1cadbbdfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "kik7wQ1qgOV-"
      },
      "outputs": [],
      "source": [
        "def make_generator_model():\n",
        "    input_noise = layers.Input(shape=(100,))\n",
        "    noise = layers.Dense(7*7*64)(input_noise)\n",
        "    noise = layers.Reshape((7, 7, 64))(noise)\n",
        "\n",
        "    input_digit = layers.Input(shape=(1,))\n",
        "    digit = layers.Embedding(10, 49)(input_digit)\n",
        "    digit = layers.Reshape((7, 7, 1))(digit)\n",
        "\n",
        "    x = layers.concatenate([noise, digit])\n",
        "\n",
        "    x = layers.Conv2DTranspose(128,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv2DTranspose(128,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv2D(1,3,1,padding='same',activation='sigmoid')(x)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=(input_noise,input_digit), outputs=x)\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "\n",
        "def make_discriminator_model():\n",
        "    input_img = layers.Input(shape=(28,28,1))\n",
        "\n",
        "    input_digit = layers.Input(shape=(1,))\n",
        "    digit = layers.Embedding(10, 5)(input_digit)\n",
        "    digit = layers.Flatten()(digit)\n",
        "    #digit = layers.Reshape((28, 28, 1))(digit)\n",
        "\n",
        "\n",
        "\n",
        "    x = layers.Conv2D(64,5,2,padding='same',activation='LeakyReLU')(input_img)\n",
        "\n",
        "\n",
        "    x = layers.Conv2D(64,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "\n",
        "    x = layers.Conv2D(64,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "\n",
        "    x = layers.Conv2D(64,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "\n",
        "    x = layers.concatenate([x, digit])\n",
        "\n",
        "    dense_output = layers.Dense(128, activation='LeakyReLU')(x)\n",
        "\n",
        "\n",
        "\n",
        "    dense_output = layers.Dense(64, activation='LeakyReLU')(x)\n",
        "\n",
        "\n",
        "    dense_output = layers.Dense(1, activation=None)(dense_output)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=(input_img,input_digit), outputs=dense_output)\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "qzdSabqdVu_H"
      },
      "outputs": [],
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {
        "id": "lS0DF8rjhHdY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4b8455e-30e4-4c84-9b92-cd34909f6ef6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_42\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_93 (InputLayer)       [(None, 100)]                0         []                            \n",
            "                                                                                                  \n",
            " input_94 (InputLayer)       [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " dense_92 (Dense)            (None, 3136)                 316736    ['input_93[0][0]']            \n",
            "                                                                                                  \n",
            " embedding_46 (Embedding)    (None, 1, 49)                490       ['input_94[0][0]']            \n",
            "                                                                                                  \n",
            " reshape_37 (Reshape)        (None, 7, 7, 64)             0         ['dense_92[0][0]']            \n",
            "                                                                                                  \n",
            " reshape_38 (Reshape)        (None, 7, 7, 1)              0         ['embedding_46[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_43 (Concatenat  (None, 7, 7, 65)             0         ['reshape_37[0][0]',          \n",
            " e)                                                                  'reshape_38[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose_34 (Conv2  (None, 14, 14, 128)          75008     ['concatenate_43[0][0]']      \n",
            " DTranspose)                                                                                      \n",
            "                                                                                                  \n",
            " batch_normalization_34 (Ba  (None, 14, 14, 128)          512       ['conv2d_transpose_34[0][0]'] \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_35 (Conv2  (None, 28, 28, 128)          147584    ['batch_normalization_34[0][0]\n",
            " DTranspose)                                                        ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (Ba  (None, 28, 28, 128)          512       ['conv2d_transpose_35[0][0]'] \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_123 (Conv2D)         (None, 28, 28, 1)            1153      ['batch_normalization_35[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 541995 (2.07 MB)\n",
            "Trainable params: 541483 (2.07 MB)\n",
            "Non-trainable params: 512 (2.00 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "generator = make_generator_model()\n",
        "generator_optimizer = tf.keras.optimizers.Adam(0.00004)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "discriminatorW = make_discriminator_model()\n",
        "discriminatorW_optimizer = tf.keras.optimizers.Adam(0.0004)"
      ],
      "metadata": {
        "id": "GJxNxRSHkWfl"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminatorU = make_discriminator_model()\n",
        "discriminatorU_optimizer = tf.keras.optimizers.Adam(0.00002)"
      ],
      "metadata": {
        "id": "6cDVGo73jfqZ"
      },
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {
        "id": "DYQpIZyEgSlN"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "@tf.function\n",
        "def discriminator_lossW(real_output, fake_output):\n",
        "    real_loss = tf.reduce_mean(real_output)\n",
        "    fake_loss = tf.reduce_mean(fake_output)\n",
        "    total_loss = fake_loss - real_loss\n",
        "    return total_loss\n",
        "\n",
        "@tf.function\n",
        "def generator_lossW(fake_output):\n",
        "    return -tf.reduce_mean(fake_output)\n",
        "\n",
        "@tf.function\n",
        "def gradient_penalty(real_images, fake_images,digits):\n",
        "    alpha = tf.random.uniform([BATCH_SIZE, 1, 1, 1], 0., 1.)\n",
        "    real_images, fake_images = tf.cast(real_images, tf.float32), tf.cast(fake_images, tf.float32)\n",
        "    interpolated_images = alpha * real_images + ((1 - alpha) * fake_images)\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(interpolated_images)\n",
        "        pred = discriminatorW((interpolated_images,digits), training=True)\n",
        "    gradients = tape.gradient(pred, [interpolated_images])[0]\n",
        "    norm = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis=[1, 2, 3]))\n",
        "    gp = tf.reduce_mean((norm - 1.)**2)\n",
        "    return gp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "@tf.function\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "@tf.function\n",
        "def generator_loss(fake_output):\n",
        "    return -tf.reduce_mean(fake_output)"
      ],
      "metadata": {
        "id": "4rgSqI2sf1sT"
      },
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NOISE_DIM = 100\n",
        "\n",
        "@tf.function\n",
        "def train_step(real_images,digits):\n",
        "    with tf.GradientTape() as disc_tape, tf.GradientTape() as gen_tape:\n",
        "        # Generate random noise\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "\n",
        "        # Generate fake images with the generator\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        # Discriminator loss calculation\n",
        "        real_output = discriminatorU((real_images,digits), training=True)\n",
        "        fake_output = discriminatorU((generated_images,digits), training=True)\n",
        "        d_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "        # Generator loss calculation\n",
        "        g_loss = generator_loss(fake_output)\n",
        "\n",
        "    # Update generator and discriminator variables\n",
        "    gradients_of_discriminator = disc_tape.gradient(d_loss, discriminatorU.trainable_variables)\n",
        "    gradients_of_generator = gen_tape.gradient(g_loss, generator.trainable_variables)\n",
        "    discriminatorU_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminatorU.trainable_variables))\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    tf.print(\"disc_loss\",d_loss,'gen_loss',g_loss)"
      ],
      "metadata": {
        "id": "ilj-woz7fSum"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NOISE_DIM = 100\n",
        "\n",
        "#@tf.function\n",
        "def train_step(real_images,digits):\n",
        "\n",
        "    for i in range(5):\n",
        "      with tf.GradientTape() as disc_tape:\n",
        "        # Generate random noise\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "\n",
        "        # Generate fake images with the generator\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        # Discriminator loss calculation\n",
        "        real_output = discriminatorU((real_images,digits), training=True)\n",
        "        fake_output = discriminatorU((generated_images,digits), training=True)\n",
        "        d_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "\n",
        "      gradients_of_discriminator = disc_tape.gradient(d_loss, discriminatorU.trainable_variables)\n",
        "      discriminatorU_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminatorU.trainable_variables))\n",
        "\n",
        "      if i == 0:\n",
        "        weights = discriminatorU.get_weights()\n",
        "\n",
        "    with tf.GradientTape() as gen_tape:\n",
        "      # Generate random noise\n",
        "      noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "\n",
        "      # Generate fake images with the generator\n",
        "      generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "      fake_output = discriminatorU((generated_images,digits), training=True)\n",
        "\n",
        "       # Generator loss calculation\n",
        "      g_loss = generator_loss(fake_output)\n",
        "\n",
        "    # Update generator and discriminator variables\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(g_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    discriminatorU.set_weights(weights)\n",
        "\n",
        "    tf.print(\"disc_loss\",d_loss,'gen_loss',g_loss)"
      ],
      "metadata": {
        "id": "8AuOxPdvp1hu"
      },
      "execution_count": 262,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {
        "id": "cP3-wZztEeaE"
      },
      "outputs": [],
      "source": [
        "NOISE_DIM = 100\n",
        "GP_WEIGHT = 10\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def train_step(images,digits):\n",
        "\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tapeW:\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        real_outputW = discriminatorW((images,digits), training=True)\n",
        "        fake_outputW = discriminatorW((generated_images,digits), training=True)\n",
        "\n",
        "        disc_lossW = discriminator_lossW(real_outputW, fake_outputW)\n",
        "\n",
        "        gen_lossW = generator_lossW(fake_outputW)\n",
        "        gen_loss = gen_lossW\n",
        "\n",
        "        gp = gradient_penalty(images, generated_images, digits)\n",
        "        disc_lossW += gp * GP_WEIGHT\n",
        "\n",
        "\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    gradients_of_discriminatorW = disc_tapeW.gradient(disc_lossW, discriminatorW.trainable_variables)\n",
        "    discriminatorW_optimizer.apply_gradients(zip(gradients_of_discriminatorW, discriminatorW.trainable_variables))\n",
        "\n",
        "\n",
        "    tf.print(\"disc_lossW\",disc_lossW,'gen_lossW',gen_lossW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {
        "id": "Sx_KbIfjiogE"
      },
      "outputs": [],
      "source": [
        "def train(dataset,y_train, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    for batch in range(len(dataset) // BATCH_SIZE):\n",
        "\n",
        "            target_images = dataset[batch * BATCH_SIZE: (batch+1) * BATCH_SIZE]\n",
        "            digits = y_train[batch * BATCH_SIZE: (batch+1) * BATCH_SIZE]\n",
        "\n",
        "            train_step(target_images,digits)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      print(epoch)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWp_3RkPg248",
        "outputId": "dea90522-6682-4b86-c41a-a3f6794fe9de",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "disc_loss 0.962885 gen_loss 0.589842618\n",
            "disc_loss 0.964583397 gen_loss 0.860358059\n",
            "disc_loss 0.981194496 gen_loss 0.749698341\n",
            "disc_loss 0.850427687 gen_loss 0.805403\n",
            "disc_loss 0.903921723 gen_loss 0.809309244\n",
            "disc_loss 0.89505893 gen_loss 0.810013413\n",
            "disc_loss 0.981547594 gen_loss 0.630488873\n",
            "disc_loss 0.848526418 gen_loss 0.748797655\n",
            "disc_loss 0.982369244 gen_loss 0.950960279\n",
            "disc_loss 1.01797795 gen_loss 0.821415067\n",
            "disc_loss 1.04405415 gen_loss 0.829552293\n",
            "disc_loss 1.11571121 gen_loss 0.40096572\n",
            "disc_loss 0.986924648 gen_loss 0.428384393\n",
            "disc_loss 0.940210521 gen_loss 0.687809706\n",
            "disc_loss 1.06095934 gen_loss 0.674026251\n",
            "disc_loss 0.982087791 gen_loss 0.571049809\n",
            "disc_loss 0.91845578 gen_loss 0.829305172\n",
            "disc_loss 0.988244474 gen_loss 0.916212916\n",
            "disc_loss 1.09943783 gen_loss 0.515453875\n",
            "disc_loss 1.27003765 gen_loss -0.0830004439\n",
            "disc_loss 1.15919042 gen_loss -0.0710235387\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 100\n",
        "x_train2 = np.expand_dims(x_train, axis=-1)\n",
        "x_train2 = (x_train2 - np.min(x_train2)) / (np.max(x_train2) - np.min(x_train2))\n",
        "train(x_train2,y_train, EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "9vPp5AiDkrAF",
        "outputId": "d140e1eb-59f2-421c-f391-fc965fd24887",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n",
            "tf.Tensor([0], shape=(1,), dtype=int32)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "noise = tf.random.normal(shape=(1,100))\n",
        "random_number = tf.random.uniform(shape=[1,], minval=0, maxval=10, dtype=tf.int32)\n",
        "test = generator.predict((noise,random_number))\n",
        "print(random_number)\n",
        "plt.imshow(test.squeeze(), cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NOISE_DIM = 100\n",
        "GP_WEIGHT = 10\n",
        "\n",
        "\n",
        "#@tf.function\n",
        "def train_step(images,digits):\n",
        "\n",
        "\n",
        "    for i in range(3):\n",
        "      with tf.GradientTape() as disc_tapeU:\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        real_outputU = discriminatorU((images,digits), training=True)\n",
        "        fake_outputU = discriminatorU((generated_images,digits), training=True)\n",
        "        disc_lossU = cross_entropy(tf.ones_like(real_outputU), real_outputU)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      gradients_of_discriminatorU = disc_tapeU.gradient(disc_lossU, discriminatorU.trainable_variables)\n",
        "      discriminatorU_optimizer.apply_gradients(zip(gradients_of_discriminatorU, discriminatorU.trainable_variables))\n",
        "      if i == 0:\n",
        "        weights = discriminatorU.get_weights()\n",
        "\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tapeW:\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        real_outputW = discriminatorW((images,digits), training=True)\n",
        "        fake_outputW = discriminatorW((generated_images,digits), training=True)\n",
        "        real_outputU = discriminatorU((images,digits), training=True)\n",
        "        fake_outputU = discriminatorU((generated_images,digits), training=True)\n",
        "        disc_lossW = discriminator_lossW(real_outputW, fake_outputW)\n",
        "\n",
        "\n",
        "        gen_lossU = cross_entropy(tf.ones_like(fake_outputU), fake_outputU)\n",
        "        gen_lossW = generator_lossW(fake_outputW)\n",
        "        gen_loss = gen_lossU#+gen_lossW\n",
        "\n",
        "        gp = gradient_penalty(images, generated_images, digits)\n",
        "        disc_lossW += gp * GP_WEIGHT\n",
        "\n",
        "\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    gradients_of_discriminatorW = disc_tapeW.gradient(disc_lossW, discriminatorW.trainable_variables)\n",
        "    discriminatorW_optimizer.apply_gradients(zip(gradients_of_discriminatorW, discriminatorW.trainable_variables))\n",
        "\n",
        "    discriminatorU.set_weights(weights)\n",
        "\n",
        "    tf.print(\"disc_lossW\",disc_lossW,'disc_lossU',disc_lossU,'gen_lossU',gen_lossU,'gen_lossW',gen_lossW)"
      ],
      "metadata": {
        "id": "_r4IEg2iBLvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhuRFc0ro5T_"
      },
      "outputs": [],
      "source": [
        "print(np.min(x_train2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojIuJFIAybro"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}