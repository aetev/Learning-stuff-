{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmxvo81wz6krH/roq1Q7lZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aetev/Learning-stuff-/blob/main/wganworkking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xI7rEeMMgDQI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgyl_WtbgO5k",
        "outputId": "b8fe388b-053f-4353-a985-e218964cd9cb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(7*7,activation='LeakyReLU',use_bias=False, input_shape=(100,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dense(14*14,activation='LeakyReLU',use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dense(28*28,activation='LeakyReLU',use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dense(28*28,activation='sigmoid',use_bias=False))\n",
        "    model.add(layers.Reshape((28,28,1)))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def make_discriminator_model():\n",
        "    input_img = layers.Input(shape=(28,28,1))\n",
        "\n",
        "    x = layers.Conv2D(64,3,2,padding='same',activation='LeakyReLU')(input_img)\n",
        "\n",
        "    x = layers.Dropout(.2)(x)\n",
        "\n",
        "    x = layers.Conv2D(64,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.Dropout(.2)(x)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "\n",
        "    dense_output = layers.Dense(128, activation='LeakyReLU')(x)\n",
        "\n",
        "\n",
        "    x = layers.Dropout(.2)(x)\n",
        "\n",
        "    dense_output = layers.Dense(64, activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.Dropout(.2)(x)\n",
        "\n",
        "    dense_output = layers.Dense(1, activation=None)(dense_output)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=input_img, outputs=dense_output)\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "kik7wQ1qgOV-"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "qzdSabqdVu_H"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = make_generator_model()\n",
        "discriminatorW = make_discriminator_model()\n",
        "discriminatorU = make_discriminator_model()\n",
        "generator_optimizer = tf.keras.optimizers.Adam(0.0004)\n",
        "discriminatorW_optimizer = tf.keras.optimizers.Adam(0.0004)\n",
        "discriminatorU_optimizer = tf.keras.optimizers.Adam(0.0004)"
      ],
      "metadata": {
        "id": "lS0DF8rjhHdY"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 10\n",
        "\n",
        "#@tf.function\n",
        "def discriminator_lossW(real_output, fake_output):\n",
        "    real_loss = tf.reduce_mean(real_output)\n",
        "    fake_loss = tf.reduce_mean(fake_output)\n",
        "    total_loss = fake_loss - real_loss\n",
        "    return total_loss\n",
        "\n",
        "#@tf.function\n",
        "def generator_lossW(fake_output):\n",
        "    return -tf.reduce_mean(fake_output)\n",
        "\n",
        "#@tf.function\n",
        "def gradient_penalty(real_images, fake_images):\n",
        "    alpha = tf.random.uniform([BATCH_SIZE, 1, 1, 1], 0., 1.)\n",
        "    real_images, fake_images = tf.cast(real_images, tf.float32), tf.cast(fake_images, tf.float32)\n",
        "    interpolated_images = alpha * real_images + ((1 - alpha) * fake_images)\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(interpolated_images)\n",
        "        pred = discriminatorW(interpolated_images, training=True)\n",
        "    gradients = tape.gradient(pred, [interpolated_images])[0]\n",
        "    norm = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis=[1, 2, 3]))\n",
        "    gp = tf.reduce_mean((norm - 1.)**2)\n",
        "    return gp"
      ],
      "metadata": {
        "id": "DYQpIZyEgSlN"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NOISE_DIM = 100\n",
        "GP_WEIGHT = 10\n",
        "\n",
        "\n",
        "#@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "\n",
        "    for i in range(5):\n",
        "      with tf.GradientTape() as disc_tapeU:\n",
        "        generated_images = generator(noise, training=True)\n",
        "\n",
        "        real_outputU = discriminatorU(images, training=True)\n",
        "        fake_outputU = discriminatorU(generated_images, training=True)\n",
        "        disc_lossU = cross_entropy(tf.ones_like(real_outputU), real_outputU)\n",
        "\n",
        "\n",
        "      if i == 0:\n",
        "        weights = discriminatorU.get_weights()\n",
        "\n",
        "      gradients_of_discriminatorU = disc_tapeU.gradient(disc_lossU, discriminatorU.trainable_variables)\n",
        "      discriminatorU_optimizer.apply_gradients(zip(gradients_of_discriminatorU, discriminatorU.trainable_variables))\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tapeW:\n",
        "        generated_images = generator(noise, training=True)\n",
        "\n",
        "        real_outputW = discriminatorW(images, training=True)\n",
        "        fake_outputW = discriminatorW(generated_images, training=True)\n",
        "        real_outputU = discriminatorU(images, training=True)\n",
        "        fake_outputU = discriminatorU(generated_images, training=True)\n",
        "        disc_lossW = discriminator_lossW(real_outputW, fake_outputW)\n",
        "\n",
        "\n",
        "        gen_loss = cross_entropy(tf.ones_like(fake_outputU), fake_outputU)*10\n",
        "        gen_loss += generator_lossW(fake_outputW)\n",
        "        gp = gradient_penalty(images, generated_images)\n",
        "        disc_lossW += gp * GP_WEIGHT\n",
        "\n",
        "\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    gradients_of_discriminatorW = disc_tapeW.gradient(disc_lossW, discriminatorW.trainable_variables)\n",
        "    discriminatorW_optimizer.apply_gradients(zip(gradients_of_discriminatorW, discriminatorW.trainable_variables))\n",
        "\n",
        "    discriminatorU.set_weights(weights)\n",
        "\n",
        "    tf.print(\"disc_lossW\",disc_lossW,'disc_lossU',disc_lossU,'gen_loss',gen_loss)"
      ],
      "metadata": {
        "id": "cP3-wZztEeaE"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6ihRh4v9euLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    for batch in range(len(dataset) // BATCH_SIZE):\n",
        "\n",
        "            target_images = dataset[batch * BATCH_SIZE: (batch+1) * BATCH_SIZE]\n",
        "\n",
        "\n",
        "            train_step(target_images)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      print(epoch)\n",
        "\n"
      ],
      "metadata": {
        "id": "Sx_KbIfjiogE"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "x_train2 = np.expand_dims(x_train, axis=-1)\n",
        "x_train2 = (x_train2 - np.min(x_train2)) / (np.max(x_train2) - np.min(x_train2))\n",
        "train(x_train2, EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWp_3RkPg248",
        "outputId": "beb461ba-0260-40e7-883b-57059fa56d2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "disc_lossW 6.90054035 disc_lossU 0.45835042 gen_loss 2.37739277\n",
            "disc_lossW 6.53204 disc_lossU 0.459397495 gen_loss 1.95085871\n",
            "disc_lossW 6.10145426 disc_lossU 0.407045841 gen_loss 1.89839697\n",
            "disc_lossW 5.53061 disc_lossU 0.393525541 gen_loss 2.12516665\n",
            "disc_lossW 4.81439972 disc_lossU 0.446115345 gen_loss 2.53339148\n",
            "disc_lossW 4.2238121 disc_lossU 0.405833155 gen_loss 2.56168437\n",
            "disc_lossW 3.36054897 disc_lossU 0.407244503 gen_loss 2.54141426\n",
            "disc_lossW 2.58726811 disc_lossU 0.437751383 gen_loss 3.0748539\n",
            "disc_lossW 1.73031044 disc_lossU 0.400571883 gen_loss 3.3279171\n",
            "disc_lossW 0.524638891 disc_lossU 0.42383337 gen_loss 3.92497253\n",
            "disc_lossW -0.33714962 disc_lossU 0.455731332 gen_loss 4.49579239\n",
            "disc_lossW -1.59448218 disc_lossU 0.409378588 gen_loss 4.97507238\n",
            "disc_lossW -2.67085743 disc_lossU 0.412194192 gen_loss 5.68595409\n",
            "disc_lossW -4.15577698 disc_lossU 0.445569575 gen_loss 6.74882412\n",
            "disc_lossW -5.36972284 disc_lossU 0.4335455 gen_loss 7.77009106\n",
            "disc_lossW -6.2840066 disc_lossU 0.432655245 gen_loss 8.61484718\n",
            "disc_lossW -6.92131186 disc_lossU 0.412234604 gen_loss 9.78438\n",
            "disc_lossW -8.1791687 disc_lossU 0.448288441 gen_loss 11.2507086\n",
            "disc_lossW -8.12617683 disc_lossU 0.437500089 gen_loss 12.7634926\n",
            "disc_lossW -6.73545 disc_lossU 0.413646549 gen_loss 13.8143082\n",
            "disc_lossW -7.36532736 disc_lossU 0.417085588 gen_loss 15.0699673\n",
            "disc_lossW -8.70290565 disc_lossU 0.432792515 gen_loss 15.9747829\n",
            "disc_lossW -4.19988823 disc_lossU 0.404677927 gen_loss 16.559267\n",
            "disc_lossW -7.01508141 disc_lossU 0.435305834 gen_loss 16.7674294\n",
            "disc_lossW -7.09849548 disc_lossU 0.407775313 gen_loss 16.6199169\n",
            "disc_lossW -9.31796455 disc_lossU 0.445069879 gen_loss 16.4387932\n",
            "disc_lossW -5.73260498 disc_lossU 0.425098747 gen_loss 16.456562\n",
            "disc_lossW -9.14911842 disc_lossU 0.45630312 gen_loss 16.0667725\n",
            "disc_lossW -8.72942924 disc_lossU 0.447951972 gen_loss 15.4019709\n",
            "disc_lossW -9.57180309 disc_lossU 0.397929609 gen_loss 14.6210556\n",
            "disc_lossW -10.3082104 disc_lossU 0.439261138 gen_loss 14.5447273\n",
            "disc_lossW -10.1125526 disc_lossU 0.451819032 gen_loss 13.637042\n",
            "disc_lossW -10.5094261 disc_lossU 0.400518358 gen_loss 13.3858032\n",
            "disc_lossW -9.82083511 disc_lossU 0.428074658 gen_loss 12.8223076\n",
            "disc_lossW -9.78530788 disc_lossU 0.425522804 gen_loss 12.2300653\n",
            "disc_lossW -10.9932022 disc_lossU 0.443273693 gen_loss 12.96245\n",
            "disc_lossW -11.356432 disc_lossU 0.447939217 gen_loss 13.2335405\n",
            "disc_lossW -10.7193184 disc_lossU 0.431762516 gen_loss 12.6864834\n",
            "disc_lossW -10.0936136 disc_lossU 0.442413032 gen_loss 13.2386341\n",
            "disc_lossW -11.36623 disc_lossU 0.423891395 gen_loss 13.5783558\n",
            "disc_lossW -11.7662649 disc_lossU 0.470853657 gen_loss 15.060976\n",
            "disc_lossW -12.612093 disc_lossU 0.464183718 gen_loss 15.8866196\n",
            "disc_lossW -11.5108547 disc_lossU 0.408745676 gen_loss 16.3870049\n",
            "disc_lossW -13.1540833 disc_lossU 0.437292635 gen_loss 17.853241\n",
            "disc_lossW -12.9421692 disc_lossU 0.447551399 gen_loss 18.4876347\n",
            "disc_lossW -12.230155 disc_lossU 0.433612287 gen_loss 19.4317074\n",
            "disc_lossW -11.9893246 disc_lossU 0.423429728 gen_loss 19.9220123\n",
            "disc_lossW -13.2815771 disc_lossU 0.448901415 gen_loss 20.0755272\n",
            "disc_lossW -13.3177471 disc_lossU 0.439339101 gen_loss 20.6668262\n",
            "disc_lossW -12.2169724 disc_lossU 0.426683903 gen_loss 20.5330715\n",
            "disc_lossW -13.2377777 disc_lossU 0.465988576 gen_loss 21.0023327\n",
            "disc_lossW -13.1203604 disc_lossU 0.439053118 gen_loss 20.6574783\n",
            "disc_lossW -12.9294224 disc_lossU 0.386719793 gen_loss 20.0644493\n",
            "disc_lossW -13.7028437 disc_lossU 0.455516815 gen_loss 19.3212662\n",
            "disc_lossW -13.9325666 disc_lossU 0.416465521 gen_loss 18.9911366\n",
            "disc_lossW -13.5006647 disc_lossU 0.417149246 gen_loss 19.0172043\n",
            "disc_lossW -13.957118 disc_lossU 0.431907654 gen_loss 18.9124794\n",
            "disc_lossW -13.9120522 disc_lossU 0.454513878 gen_loss 18.9018574\n",
            "disc_lossW -13.3381748 disc_lossU 0.45622763 gen_loss 18.7321053\n",
            "disc_lossW -12.8792706 disc_lossU 0.441188574 gen_loss 19.1828136\n",
            "disc_lossW -13.8340931 disc_lossU 0.454291731 gen_loss 19.4611015\n",
            "disc_lossW -13.6746845 disc_lossU 0.447176546 gen_loss 19.8505936\n",
            "disc_lossW -13.6168337 disc_lossU 0.410402298 gen_loss 19.6528072\n",
            "disc_lossW -14.1019325 disc_lossU 0.444904238 gen_loss 19.8521423\n",
            "disc_lossW -13.0655527 disc_lossU 0.445628 gen_loss 20.136097\n",
            "disc_lossW -12.9128828 disc_lossU 0.424539655 gen_loss 19.9348488\n",
            "disc_lossW -12.7946167 disc_lossU 0.404616058 gen_loss 19.7441616\n",
            "disc_lossW -14.1930599 disc_lossU 0.413256109 gen_loss 19.9662781\n",
            "disc_lossW -13.5547085 disc_lossU 0.432598978 gen_loss 19.6973057\n",
            "disc_lossW -13.6991825 disc_lossU 0.430114657 gen_loss 19.2789383\n",
            "disc_lossW -13.1618214 disc_lossU 0.404641807 gen_loss 19.2595921\n",
            "disc_lossW -14.2425556 disc_lossU 0.372695833 gen_loss 19.4904461\n",
            "disc_lossW -13.4805622 disc_lossU 0.392833322 gen_loss 19.2758675\n",
            "disc_lossW -13.3269978 disc_lossU 0.394882262 gen_loss 18.6860104\n",
            "disc_lossW -13.5990973 disc_lossU 0.41736871 gen_loss 18.8459415\n",
            "disc_lossW -13.3068571 disc_lossU 0.356528938 gen_loss 19.3447418\n",
            "disc_lossW -12.3172922 disc_lossU 0.387799859 gen_loss 18.287529\n",
            "disc_lossW -13.0436974 disc_lossU 0.412348092 gen_loss 18.6467266\n",
            "disc_lossW -13.6270313 disc_lossU 0.41467905 gen_loss 18.2653618\n",
            "disc_lossW -13.3676434 disc_lossU 0.404258877 gen_loss 18.4346676\n",
            "disc_lossW -13.8577738 disc_lossU 0.431885242 gen_loss 18.3801117\n",
            "disc_lossW -13.2082129 disc_lossU 0.391138554 gen_loss 18.6027565\n",
            "disc_lossW -13.21665 disc_lossU 0.423212916 gen_loss 18.1484718\n",
            "disc_lossW -13.26299 disc_lossU 0.427354634 gen_loss 18.363493\n",
            "disc_lossW -12.8080864 disc_lossU 0.396005958 gen_loss 18.687603\n",
            "disc_lossW -13.0654411 disc_lossU 0.41075334 gen_loss 18.4830284\n",
            "disc_lossW -12.9603882 disc_lossU 0.414334 gen_loss 18.7175255\n",
            "disc_lossW -12.6788712 disc_lossU 0.423302 gen_loss 18.6932602\n",
            "disc_lossW -13.0852566 disc_lossU 0.421129763 gen_loss 18.71311\n",
            "disc_lossW -12.829957 disc_lossU 0.404996783 gen_loss 19.0513287\n",
            "disc_lossW -12.7494869 disc_lossU 0.406720549 gen_loss 19.1075535\n",
            "disc_lossW -12.856123 disc_lossU 0.411213577 gen_loss 18.8898621\n",
            "disc_lossW -13.3041306 disc_lossU 0.409876972 gen_loss 19.3913479\n",
            "disc_lossW -13.6962976 disc_lossU 0.445077956 gen_loss 19.4943218\n",
            "disc_lossW -12.7489634 disc_lossU 0.404675961 gen_loss 19.4567089\n",
            "disc_lossW -13.5272694 disc_lossU 0.408225596 gen_loss 19.3559494\n",
            "disc_lossW -12.9979439 disc_lossU 0.437947512 gen_loss 19.5521889\n",
            "disc_lossW -13.6288586 disc_lossU 0.415518701 gen_loss 20.7132797\n",
            "disc_lossW -12.1859684 disc_lossU 0.420696169 gen_loss 20.0368614\n",
            "disc_lossW -12.7669363 disc_lossU 0.421578497 gen_loss 20.2149277\n",
            "disc_lossW -13.1012 disc_lossU 0.451791108 gen_loss 19.9569435\n",
            "disc_lossW -12.9534225 disc_lossU 0.435397565 gen_loss 20.4018059\n",
            "disc_lossW -13.2600136 disc_lossU 0.474485308 gen_loss 19.7645779\n",
            "disc_lossW -13.664175 disc_lossU 0.461372077 gen_loss 20.2404938\n",
            "disc_lossW -12.5865 disc_lossU 0.42853564 gen_loss 20.0794392\n",
            "disc_lossW -13.5868444 disc_lossU 0.495019019 gen_loss 19.745615\n",
            "disc_lossW -13.2105198 disc_lossU 0.480578512 gen_loss 20.2782383\n",
            "disc_lossW -12.5996313 disc_lossU 0.467538506 gen_loss 19.9865913\n",
            "disc_lossW -13.8339319 disc_lossU 0.490891159 gen_loss 20.2564278\n",
            "disc_lossW -12.1958017 disc_lossU 0.450830847 gen_loss 20.4300232\n",
            "disc_lossW -12.8052282 disc_lossU 0.42168197 gen_loss 20.4733124\n",
            "disc_lossW -13.774004 disc_lossU 0.48371768 gen_loss 20.667099\n",
            "disc_lossW -12.6843138 disc_lossU 0.455777317 gen_loss 20.6000156\n",
            "disc_lossW -13.1121922 disc_lossU 0.47352463 gen_loss 20.4593163\n",
            "disc_lossW -12.3614092 disc_lossU 0.457461536 gen_loss 20.4027596\n",
            "disc_lossW -12.4997425 disc_lossU 0.457542509 gen_loss 20.3718433\n",
            "disc_lossW -12.7629833 disc_lossU 0.488292396 gen_loss 20.0014133\n",
            "disc_lossW -12.2081633 disc_lossU 0.456973314 gen_loss 19.753933\n",
            "disc_lossW -11.7952967 disc_lossU 0.406033427 gen_loss 19.8756237\n",
            "disc_lossW -11.340271 disc_lossU 0.413271189 gen_loss 18.8876915\n",
            "disc_lossW -11.437706 disc_lossU 0.346080035 gen_loss 18.7023087\n",
            "disc_lossW -12.2187185 disc_lossU 0.374486387 gen_loss 18.5036831\n",
            "disc_lossW -11.6399708 disc_lossU 0.359817982 gen_loss 17.9212685\n",
            "disc_lossW -12.1161537 disc_lossU 0.362032026 gen_loss 18.1478767\n",
            "disc_lossW -11.8028498 disc_lossU 0.374516666 gen_loss 18.0753803\n",
            "disc_lossW -11.8550282 disc_lossU 0.380557477 gen_loss 17.6794453\n",
            "disc_lossW -10.288372 disc_lossU 0.304489493 gen_loss 17.7257252\n",
            "disc_lossW -11.2351065 disc_lossU 0.346724719 gen_loss 17.202467\n",
            "disc_lossW -11.594492 disc_lossU 0.384087712 gen_loss 16.713131\n",
            "disc_lossW -11.465724 disc_lossU 0.350355744 gen_loss 16.7432365\n",
            "disc_lossW -11.2197647 disc_lossU 0.349250197 gen_loss 16.4734497\n",
            "disc_lossW -10.8237762 disc_lossU 0.326884806 gen_loss 16.335556\n",
            "disc_lossW -11.486495 disc_lossU 0.372701257 gen_loss 15.6588564\n",
            "disc_lossW -11.2426338 disc_lossU 0.377761751 gen_loss 15.3101854\n",
            "disc_lossW -11.1291676 disc_lossU 0.373791963 gen_loss 15.1998062\n",
            "disc_lossW -10.5548944 disc_lossU 0.348341972 gen_loss 14.9549389\n",
            "disc_lossW -10.2332993 disc_lossU 0.337918848 gen_loss 14.6954126\n",
            "disc_lossW -10.3238945 disc_lossU 0.336017162 gen_loss 14.5214214\n",
            "disc_lossW -10.7441359 disc_lossU 0.332264662 gen_loss 14.5742054\n",
            "disc_lossW -10.4237995 disc_lossU 0.343145221 gen_loss 14.1276\n",
            "disc_lossW -10.3073416 disc_lossU 0.357343465 gen_loss 14.4339924\n",
            "disc_lossW -10.4104881 disc_lossU 0.419877708 gen_loss 14.1559181\n",
            "disc_lossW -9.84285259 disc_lossU 0.424234629 gen_loss 14.312952\n",
            "disc_lossW -10.1144142 disc_lossU 0.423820734 gen_loss 14.4835453\n",
            "disc_lossW -9.33013725 disc_lossU 0.398659796 gen_loss 14.6091099\n",
            "disc_lossW -10.2598934 disc_lossU 0.462508202 gen_loss 15.0313807\n",
            "disc_lossW -9.64948463 disc_lossU 0.449849069 gen_loss 15.4400778\n",
            "disc_lossW -9.91266727 disc_lossU 0.44355908 gen_loss 15.796813\n",
            "disc_lossW -9.57728767 disc_lossU 0.439562649 gen_loss 15.4153137\n",
            "disc_lossW -9.8655405 disc_lossU 0.453698814 gen_loss 15.5955877\n",
            "disc_lossW -9.32812881 disc_lossU 0.432268709 gen_loss 15.7005119\n",
            "disc_lossW -9.42865276 disc_lossU 0.427182764 gen_loss 15.5470772\n",
            "disc_lossW -9.40582085 disc_lossU 0.489811122 gen_loss 15.6550226\n",
            "disc_lossW -8.76537609 disc_lossU 0.427585542 gen_loss 15.5974941\n",
            "disc_lossW -10.0169621 disc_lossU 0.491033852 gen_loss 15.5419149\n",
            "disc_lossW -8.8135519 disc_lossU 0.467237 gen_loss 15.1284637\n",
            "disc_lossW -8.88258743 disc_lossU 0.461771905 gen_loss 15.5580673\n",
            "disc_lossW -9.13699055 disc_lossU 0.470134676 gen_loss 15.634738\n",
            "disc_lossW -8.18677807 disc_lossU 0.432232857 gen_loss 15.4528847\n",
            "disc_lossW -8.316535 disc_lossU 0.439635366 gen_loss 15.3901577\n",
            "disc_lossW -8.27586269 disc_lossU 0.424803734 gen_loss 15.1293144\n",
            "disc_lossW -8.09835815 disc_lossU 0.437199533 gen_loss 14.936368\n",
            "disc_lossW -7.73780346 disc_lossU 0.431352437 gen_loss 14.6207619\n",
            "disc_lossW -8.3971014 disc_lossU 0.448061168 gen_loss 14.6125126\n",
            "disc_lossW -7.64097404 disc_lossU 0.440911591 gen_loss 14.3244238\n",
            "disc_lossW -8.51237774 disc_lossU 0.479590565 gen_loss 14.4517155\n",
            "disc_lossW -8.13462162 disc_lossU 0.475014508 gen_loss 14.2604198\n",
            "disc_lossW -7.42867279 disc_lossU 0.441466957 gen_loss 14.1110468\n",
            "disc_lossW -7.62172031 disc_lossU 0.452887952 gen_loss 13.5930767\n",
            "disc_lossW -8.85683537 disc_lossU 0.479676306 gen_loss 14.2325487\n",
            "disc_lossW -7.24980068 disc_lossU 0.449025154 gen_loss 14.0228043\n",
            "disc_lossW -7.49714 disc_lossU 0.490059 gen_loss 13.9569159\n",
            "disc_lossW -6.48349762 disc_lossU 0.404353291 gen_loss 14.0632658\n",
            "disc_lossW -7.87365 disc_lossU 0.482072413 gen_loss 13.814703\n",
            "disc_lossW -7.06522274 disc_lossU 0.460443348 gen_loss 13.7381573\n",
            "disc_lossW -6.95584345 disc_lossU 0.412525 gen_loss 13.3866243\n",
            "disc_lossW -7.04748964 disc_lossU 0.42918998 gen_loss 13.196558\n",
            "disc_lossW -6.16701794 disc_lossU 0.428407729 gen_loss 12.644805\n",
            "disc_lossW -7.26448965 disc_lossU 0.452388585 gen_loss 12.5625124\n",
            "disc_lossW -6.3482666 disc_lossU 0.405003875 gen_loss 12.4464331\n",
            "disc_lossW -6.11227083 disc_lossU 0.460166067 gen_loss 11.6684675\n",
            "disc_lossW -6.41409254 disc_lossU 0.477191836 gen_loss 11.9230328\n",
            "disc_lossW -5.93089056 disc_lossU 0.464334786 gen_loss 12.0521412\n",
            "disc_lossW -6.37104797 disc_lossU 0.459773213 gen_loss 11.7304583\n",
            "disc_lossW -5.37655497 disc_lossU 0.417359293 gen_loss 11.5216446\n",
            "disc_lossW -5.98591566 disc_lossU 0.429060549 gen_loss 11.3142509\n",
            "disc_lossW -5.24742222 disc_lossU 0.401194572 gen_loss 11.0447302\n",
            "disc_lossW -5.24423075 disc_lossU 0.394993603 gen_loss 10.718811\n",
            "disc_lossW -5.08684158 disc_lossU 0.425713867 gen_loss 10.4385166\n",
            "disc_lossW -5.21828032 disc_lossU 0.434657395 gen_loss 10.2793703\n",
            "disc_lossW -5.51157284 disc_lossU 0.437073857 gen_loss 10.3568716\n",
            "disc_lossW -5.45166159 disc_lossU 0.449827105 gen_loss 10.3802404\n",
            "disc_lossW -4.3784833 disc_lossU 0.394868076 gen_loss 10.0617\n",
            "disc_lossW -5.30003309 disc_lossU 0.446267366 gen_loss 10.1805344\n",
            "disc_lossW -4.92068577 disc_lossU 0.422234714 gen_loss 9.90282917\n",
            "disc_lossW -4.30505276 disc_lossU 0.392586648 gen_loss 9.56553\n",
            "disc_lossW -4.11541319 disc_lossU 0.360528886 gen_loss 9.26073265\n",
            "disc_lossW -4.56010771 disc_lossU 0.407224178 gen_loss 8.85370636\n",
            "disc_lossW -5.07038927 disc_lossU 0.386860073 gen_loss 9.01979065\n",
            "disc_lossW -3.87307405 disc_lossU 0.368631929 gen_loss 8.50980568\n",
            "disc_lossW -4.05592918 disc_lossU 0.34839043 gen_loss 8.44252682\n",
            "disc_lossW -4.51701641 disc_lossU 0.37187 gen_loss 8.0559864\n",
            "disc_lossW -3.9468863 disc_lossU 0.376000881 gen_loss 7.54537725\n",
            "disc_lossW -3.89591599 disc_lossU 0.388119608 gen_loss 7.5593977\n",
            "disc_lossW -4.72477293 disc_lossU 0.455150217 gen_loss 7.7274847\n",
            "disc_lossW -3.993083 disc_lossU 0.435965717 gen_loss 7.65805149\n",
            "disc_lossW -4.22339153 disc_lossU 0.404714197 gen_loss 7.93448\n",
            "disc_lossW -3.54453254 disc_lossU 0.37725383 gen_loss 7.16143417\n",
            "disc_lossW -3.56696463 disc_lossU 0.402014822 gen_loss 6.91213465\n",
            "disc_lossW -3.87387705 disc_lossU 0.403855085 gen_loss 7.04426289\n",
            "disc_lossW -3.53726864 disc_lossU 0.386266291 gen_loss 7.00953531\n",
            "disc_lossW -3.62167478 disc_lossU 0.412222326 gen_loss 6.89654255\n",
            "disc_lossW -3.45668125 disc_lossU 0.432411611 gen_loss 6.75161266\n",
            "disc_lossW -3.86121798 disc_lossU 0.433452845 gen_loss 6.78772974\n",
            "disc_lossW -3.19935894 disc_lossU 0.388505518 gen_loss 6.59033\n",
            "disc_lossW -3.6763587 disc_lossU 0.424283028 gen_loss 6.3317523\n",
            "disc_lossW -3.50241566 disc_lossU 0.427961111 gen_loss 6.48119068\n",
            "disc_lossW -3.48052239 disc_lossU 0.414191425 gen_loss 6.7025\n",
            "disc_lossW -3.26352 disc_lossU 0.42489925 gen_loss 6.50148678\n",
            "disc_lossW -3.1214447 disc_lossU 0.3984541 gen_loss 6.70396137\n",
            "disc_lossW -3.16764712 disc_lossU 0.38034457 gen_loss 6.63726902\n",
            "disc_lossW -3.25187492 disc_lossU 0.421124279 gen_loss 6.48976421\n",
            "disc_lossW -3.80656672 disc_lossU 0.461160839 gen_loss 6.96626234\n",
            "disc_lossW -2.94649792 disc_lossU 0.438258588 gen_loss 7.02206\n",
            "disc_lossW -2.86685038 disc_lossU 0.396055758 gen_loss 6.942379\n",
            "disc_lossW -2.67721987 disc_lossU 0.39553684 gen_loss 6.72180557\n",
            "disc_lossW -2.78339815 disc_lossU 0.384355962 gen_loss 6.56254435\n",
            "disc_lossW -2.77411 disc_lossU 0.406698316 gen_loss 6.37651157\n",
            "disc_lossW -2.74998 disc_lossU 0.374897599 gen_loss 6.49670315\n",
            "disc_lossW -3.24429512 disc_lossU 0.405107409 gen_loss 6.49326134\n",
            "disc_lossW -3.16614151 disc_lossU 0.433384955 gen_loss 6.38077068\n",
            "disc_lossW -3.05625892 disc_lossU 0.45735532 gen_loss 6.40979385\n",
            "disc_lossW -2.50339532 disc_lossU 0.395874202 gen_loss 6.25251102\n",
            "disc_lossW -2.89437222 disc_lossU 0.434356928 gen_loss 6.40049314\n",
            "disc_lossW -2.52582788 disc_lossU 0.446364492 gen_loss 6.24735594\n",
            "disc_lossW -1.82865393 disc_lossU 0.390968353 gen_loss 5.98087502\n",
            "disc_lossW -2.9014492 disc_lossU 0.460584551 gen_loss 6.2126503\n",
            "disc_lossW -2.26636338 disc_lossU 0.4293046 gen_loss 6.08956909\n",
            "disc_lossW -2.7147367 disc_lossU 0.433245748 gen_loss 6.69259501\n",
            "disc_lossW -2.49282408 disc_lossU 0.440994352 gen_loss 6.34259701\n",
            "disc_lossW -2.4050169 disc_lossU 0.404570282 gen_loss 6.51322508\n",
            "disc_lossW -2.33532476 disc_lossU 0.403729826 gen_loss 6.20323944\n",
            "disc_lossW -2.67863178 disc_lossU 0.449856102 gen_loss 6.32628679\n",
            "disc_lossW -2.54654551 disc_lossU 0.462913811 gen_loss 6.11411\n",
            "disc_lossW -2.83602858 disc_lossU 0.444769472 gen_loss 6.76493931\n",
            "disc_lossW -2.78936815 disc_lossU 0.436969578 gen_loss 6.59749889\n",
            "disc_lossW -2.80697179 disc_lossU 0.430560589 gen_loss 6.76632214\n",
            "disc_lossW -2.28824377 disc_lossU 0.394294024 gen_loss 6.31332397\n",
            "disc_lossW -2.12523985 disc_lossU 0.386195481 gen_loss 6.12810612\n",
            "disc_lossW -2.71276259 disc_lossU 0.436881 gen_loss 5.72209167\n",
            "disc_lossW -2.01120901 disc_lossU 0.391715705 gen_loss 5.53578472\n",
            "disc_lossW -2.9473896 disc_lossU 0.408234775 gen_loss 5.7297368\n",
            "disc_lossW -2.23418212 disc_lossU 0.37587896 gen_loss 5.20711422\n",
            "disc_lossW -2.36171246 disc_lossU 0.379788935 gen_loss 5.25468922\n",
            "disc_lossW -2.59458709 disc_lossU 0.415868938 gen_loss 4.97798157\n",
            "disc_lossW -2.0237782 disc_lossU 0.42344436 gen_loss 4.59515095\n",
            "disc_lossW -1.88208461 disc_lossU 0.41666469 gen_loss 4.83768654\n",
            "disc_lossW -2.2491703 disc_lossU 0.402928263 gen_loss 4.8180995\n",
            "disc_lossW -2.35128117 disc_lossU 0.388410389 gen_loss 4.92824316\n",
            "disc_lossW -1.79401267 disc_lossU 0.432629108 gen_loss 4.29276085\n",
            "disc_lossW -2.69675446 disc_lossU 0.423121035 gen_loss 4.87838221\n",
            "disc_lossW -2.53678751 disc_lossU 0.459556192 gen_loss 4.62357855\n",
            "disc_lossW -2.06130099 disc_lossU 0.400540531 gen_loss 4.15841866\n",
            "disc_lossW -2.27897453 disc_lossU 0.428240925 gen_loss 4.34960556\n",
            "disc_lossW -2.24390531 disc_lossU 0.444606245 gen_loss 4.05276537\n",
            "disc_lossW -1.76186347 disc_lossU 0.400260985 gen_loss 3.99728775\n",
            "disc_lossW -2.28714728 disc_lossU 0.414057016 gen_loss 3.88529253\n",
            "disc_lossW -1.88301027 disc_lossU 0.379915 gen_loss 3.88453984\n",
            "disc_lossW -2.07457733 disc_lossU 0.407351881 gen_loss 3.85569501\n",
            "disc_lossW -2.06813407 disc_lossU 0.435929 gen_loss 3.37775469\n",
            "disc_lossW -1.84963655 disc_lossU 0.407487243 gen_loss 3.69940615\n",
            "disc_lossW -2.41716814 disc_lossU 0.467238128 gen_loss 3.83131027\n",
            "disc_lossW -2.09372854 disc_lossU 0.46906966 gen_loss 3.92725754\n",
            "disc_lossW -2.03492761 disc_lossU 0.443799496 gen_loss 3.88837242\n",
            "disc_lossW -1.67801154 disc_lossU 0.415168107 gen_loss 3.55316162\n",
            "disc_lossW -1.83710992 disc_lossU 0.451332331 gen_loss 3.48002362\n",
            "disc_lossW -1.81147313 disc_lossU 0.459662974 gen_loss 3.55568647\n",
            "disc_lossW -1.78980374 disc_lossU 0.436250508 gen_loss 3.96522355\n",
            "disc_lossW -1.42026031 disc_lossU 0.390050977 gen_loss 3.49051094\n",
            "disc_lossW -1.77390873 disc_lossU 0.440287024 gen_loss 3.31699061\n",
            "disc_lossW -1.36089921 disc_lossU 0.412839651 gen_loss 3.36602974\n",
            "disc_lossW -1.55521166 disc_lossU 0.389351428 gen_loss 3.45278835\n",
            "disc_lossW -1.87542284 disc_lossU 0.414699 gen_loss 3.89920235\n",
            "disc_lossW -1.53799343 disc_lossU 0.444728225 gen_loss 3.24496889\n",
            "disc_lossW -1.36609066 disc_lossU 0.409386158 gen_loss 3.36906314\n",
            "disc_lossW -1.81030023 disc_lossU 0.403822571 gen_loss 3.33214903\n",
            "disc_lossW -1.18481135 disc_lossU 0.388423145 gen_loss 3.30605221\n",
            "disc_lossW -1.62629437 disc_lossU 0.411625564 gen_loss 3.75060916\n",
            "disc_lossW -1.84084928 disc_lossU 0.40904218 gen_loss 3.70891285\n",
            "disc_lossW -1.5306921 disc_lossU 0.415256888 gen_loss 3.66406155\n",
            "disc_lossW -1.78031051 disc_lossU 0.453124225 gen_loss 3.7174058\n",
            "disc_lossW -0.927540839 disc_lossU 0.388973564 gen_loss 3.64182162\n",
            "disc_lossW -1.37459779 disc_lossU 0.410922825 gen_loss 3.68936729\n",
            "disc_lossW -2.3097198 disc_lossU 0.444621 gen_loss 4.04698849\n",
            "disc_lossW -1.04602313 disc_lossU 0.420920193 gen_loss 3.51172423\n",
            "disc_lossW -1.88923061 disc_lossU 0.432835042 gen_loss 4.08539963\n",
            "disc_lossW -1.50392246 disc_lossU 0.42880407 gen_loss 4.0864234\n",
            "disc_lossW -2.18372297 disc_lossU 0.440932512 gen_loss 4.02237511\n",
            "disc_lossW -2.45210481 disc_lossU 0.483224571 gen_loss 4.37418\n",
            "disc_lossW -2.14434791 disc_lossU 0.463213861 gen_loss 4.45675278\n",
            "disc_lossW -2.41322803 disc_lossU 0.466453642 gen_loss 4.62571621\n",
            "disc_lossW -2.0945158 disc_lossU 0.427796662 gen_loss 4.49572849\n",
            "disc_lossW -1.46553957 disc_lossU 0.418407619 gen_loss 3.93478465\n",
            "disc_lossW -1.60752952 disc_lossU 0.401370585 gen_loss 4.23750353\n",
            "disc_lossW -1.87690914 disc_lossU 0.454819024 gen_loss 4.03953838\n",
            "disc_lossW -1.8609544 disc_lossU 0.430517763 gen_loss 4.10515165\n",
            "disc_lossW -1.86322856 disc_lossU 0.438860327 gen_loss 4.1901741\n",
            "disc_lossW -2.14141655 disc_lossU 0.456513 gen_loss 4.3002882\n",
            "disc_lossW -1.99978292 disc_lossU 0.446679115 gen_loss 4.52826738\n",
            "disc_lossW -1.75082922 disc_lossU 0.452545732 gen_loss 4.28727627\n",
            "disc_lossW -1.62904072 disc_lossU 0.435726076 gen_loss 4.06735802\n",
            "disc_lossW -1.98106289 disc_lossU 0.463656723 gen_loss 4.46878958\n",
            "disc_lossW -2.4670167 disc_lossU 0.477592289 gen_loss 4.48779583\n",
            "disc_lossW -2.20618 disc_lossU 0.468905509 gen_loss 4.34787\n",
            "disc_lossW -1.35577524 disc_lossU 0.431899697 gen_loss 4.40412331\n",
            "disc_lossW -1.71989286 disc_lossU 0.433625787 gen_loss 4.54887629\n",
            "disc_lossW -1.75435758 disc_lossU 0.443529546 gen_loss 4.18552542\n",
            "disc_lossW -1.63249159 disc_lossU 0.437611401 gen_loss 4.27736187\n",
            "disc_lossW -2.47108722 disc_lossU 0.471739531 gen_loss 4.32394075\n",
            "disc_lossW -1.73800194 disc_lossU 0.453096211 gen_loss 4.07279348\n",
            "disc_lossW -2.36673355 disc_lossU 0.476760715 gen_loss 4.3042841\n",
            "disc_lossW -2.09773064 disc_lossU 0.463298023 gen_loss 4.47349644\n",
            "disc_lossW -2.88776159 disc_lossU 0.49017486 gen_loss 4.53110743\n",
            "disc_lossW -2.52001166 disc_lossU 0.480740458 gen_loss 4.7264452\n",
            "disc_lossW -1.4298141 disc_lossU 0.441457361 gen_loss 4.23110867\n",
            "disc_lossW -1.38618982 disc_lossU 0.414429903 gen_loss 4.25058\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noise = tf.random.normal(shape=(1,100))\n",
        "test = generator.predict(noise)\n",
        "plt.imshow(test.squeeze(), cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "9vPp5AiDkrAF",
        "outputId": "265e11d6-380c-41ce-bd36-1be78639058f"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 84ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.min(x_train2))"
      ],
      "metadata": {
        "id": "fhuRFc0ro5T_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}