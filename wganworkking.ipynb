{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0lRX+nQ5JEV5PF4VmInVm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aetev/Learning-stuff-/blob/main/wganworkking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xI7rEeMMgDQI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgyl_WtbgO5k",
        "outputId": "b8fe388b-053f-4353-a985-e218964cd9cb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(7*7,activation='LeakyReLU',use_bias=False, input_shape=(100,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dense(14*14,activation='LeakyReLU',use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dense(28*28,activation='LeakyReLU',use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dense(28*28,activation='sigmoid',use_bias=False))\n",
        "    model.add(layers.Reshape((28,28,1)))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def make_discriminator_model():\n",
        "    input_img = layers.Input(shape=(28,28,1))\n",
        "\n",
        "    x = layers.Conv2D(64,3,2,padding='same',activation='LeakyReLU')(input_img)\n",
        "\n",
        "    x = layers.Dropout(.2)(x)\n",
        "\n",
        "    x = layers.Conv2D(64,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.Dropout(.2)(x)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "\n",
        "    dense_output = layers.Dense(128, activation='LeakyReLU')(x)\n",
        "\n",
        "\n",
        "    x = layers.Dropout(.2)(x)\n",
        "\n",
        "    dense_output = layers.Dense(64, activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.Dropout(.2)(x)\n",
        "\n",
        "    dense_output = layers.Dense(1, activation=None)(dense_output)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=input_img, outputs=dense_output)\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "kik7wQ1qgOV-"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "qzdSabqdVu_H"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = make_generator_model()\n",
        "discriminatorW = make_discriminator_model()\n",
        "discriminatorU = make_discriminator_model()\n",
        "generator_optimizer = tf.keras.optimizers.Adam(0.0004)\n",
        "discriminatorW_optimizer = tf.keras.optimizers.Adam(0.0004)\n",
        "discriminatorU_optimizer = tf.keras.optimizers.Adam(0.0004)"
      ],
      "metadata": {
        "id": "lS0DF8rjhHdY"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 10\n",
        "\n",
        "#@tf.function\n",
        "def discriminator_lossW(real_output, fake_output):\n",
        "    real_loss = tf.reduce_mean(real_output)\n",
        "    fake_loss = tf.reduce_mean(fake_output)\n",
        "    total_loss = fake_loss - real_loss\n",
        "    return total_loss\n",
        "\n",
        "#@tf.function\n",
        "def generator_lossW(fake_output):\n",
        "    return -tf.reduce_mean(fake_output)\n",
        "\n",
        "#@tf.function\n",
        "def gradient_penalty(real_images, fake_images):\n",
        "    alpha = tf.random.uniform([BATCH_SIZE, 1, 1, 1], 0., 1.)\n",
        "    real_images, fake_images = tf.cast(real_images, tf.float32), tf.cast(fake_images, tf.float32)\n",
        "    interpolated_images = alpha * real_images + ((1 - alpha) * fake_images)\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(interpolated_images)\n",
        "        pred = discriminatorW(interpolated_images, training=True)\n",
        "    gradients = tape.gradient(pred, [interpolated_images])[0]\n",
        "    norm = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis=[1, 2, 3]))\n",
        "    gp = tf.reduce_mean((norm - 1.)**2)\n",
        "    return gp"
      ],
      "metadata": {
        "id": "DYQpIZyEgSlN"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NOISE_DIM = 100\n",
        "GP_WEIGHT = 10\n",
        "\n",
        "\n",
        "#@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "\n",
        "    for i in range(5):\n",
        "      with tf.GradientTape() as disc_tapeU:\n",
        "        generated_images = generator(noise, training=True)\n",
        "\n",
        "        real_outputU = discriminatorU(images, training=True)\n",
        "        fake_outputU = discriminatorU(generated_images, training=True)\n",
        "        disc_lossU = cross_entropy(tf.ones_like(real_outputU), real_outputU)\n",
        "\n",
        "\n",
        "      if i == 0:\n",
        "        weights = discriminatorU.get_weights()\n",
        "\n",
        "      gradients_of_discriminatorU = disc_tapeU.gradient(disc_lossU, discriminatorU.trainable_variables)\n",
        "      discriminatorU_optimizer.apply_gradients(zip(gradients_of_discriminatorU, discriminatorU.trainable_variables))\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tapeW:\n",
        "        generated_images = generator(noise, training=True)\n",
        "\n",
        "        real_outputW = discriminatorW(images, training=True)\n",
        "        fake_outputW = discriminatorW(generated_images, training=True)\n",
        "        real_outputU = discriminatorU(images, training=True)\n",
        "        fake_outputU = discriminatorU(generated_images, training=True)\n",
        "        disc_lossW = discriminator_lossW(real_outputW, fake_outputW)\n",
        "\n",
        "\n",
        "        gen_lossU = cross_entropy(tf.ones_like(fake_outputU), fake_outputU)*10\n",
        "        gen_lossW = generator_lossW(fake_outputW)\n",
        "        gen_loss = gen_lossU+gen_lossW\n",
        "\n",
        "        gp = gradient_penalty(images, generated_images)\n",
        "        disc_lossW += gp * GP_WEIGHT\n",
        "\n",
        "\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    gradients_of_discriminatorW = disc_tapeW.gradient(disc_lossW, discriminatorW.trainable_variables)\n",
        "    discriminatorW_optimizer.apply_gradients(zip(gradients_of_discriminatorW, discriminatorW.trainable_variables))\n",
        "\n",
        "    discriminatorU.set_weights(weights)\n",
        "\n",
        "    tf.print(\"disc_lossW\",disc_lossW,'disc_lossU',disc_lossU,'gen_lossU',gen_lossU,'gen_lossW',gen_lossW)"
      ],
      "metadata": {
        "id": "cP3-wZztEeaE"
      },
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6ihRh4v9euLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    for batch in range(len(dataset) // BATCH_SIZE):\n",
        "\n",
        "            target_images = dataset[batch * BATCH_SIZE: (batch+1) * BATCH_SIZE]\n",
        "\n",
        "\n",
        "            train_step(target_images)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      print(epoch)\n",
        "\n"
      ],
      "metadata": {
        "id": "Sx_KbIfjiogE"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "x_train2 = np.expand_dims(x_train, axis=-1)\n",
        "x_train2 = (x_train2 - np.min(x_train2)) / (np.max(x_train2) - np.min(x_train2))\n",
        "train(x_train2, EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWp_3RkPg248",
        "outputId": "e6f22ce5-c7af-4121-ff3b-30e64d7d1966"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "disc_lossW -1.75500607 disc_lossU 0.0558799729 gen_lossU 0.124224365 gen_lossW -0.118759677\n",
            "disc_lossW -1.99352956 disc_lossU 0.0623434708 gen_lossU 0.122600265 gen_lossW 0.110442892\n",
            "disc_lossW -0.992637157 disc_lossU 0.0494099781 gen_lossU 0.14468421 gen_lossW -0.374886453\n",
            "disc_lossW -1.27605391 disc_lossU 0.0477704 gen_lossU 0.188658372 gen_lossW -0.114154138\n",
            "disc_lossW -1.88697982 disc_lossU 0.0703648 gen_lossU 0.164864093 gen_lossW -0.221902177\n",
            "disc_lossW -0.680765808 disc_lossU 0.0479777567 gen_lossU 0.159537256 gen_lossW -0.511010945\n",
            "disc_lossW -0.947370827 disc_lossU 0.0517151244 gen_lossU 0.154557765 gen_lossW -0.27446419\n",
            "disc_lossW -2.29519963 disc_lossU 0.0559996441 gen_lossU 0.189881802 gen_lossW -0.197780147\n",
            "disc_lossW -1.02377558 disc_lossU 0.0405091308 gen_lossU 0.19689694 gen_lossW -0.265772671\n",
            "disc_lossW -1.26871085 disc_lossU 0.0549989566 gen_lossU 0.182696164 gen_lossW -0.586975694\n",
            "disc_lossW -1.61422968 disc_lossU 0.0712617487 gen_lossU 0.158975124 gen_lossW -0.658786952\n",
            "disc_lossW -1.1030302 disc_lossU 0.0482323356 gen_lossU 0.182251215 gen_lossW -0.249199435\n",
            "disc_lossW -1.15032303 disc_lossU 0.054697372 gen_lossU 0.20111233 gen_lossW -0.543202102\n",
            "disc_lossW -1.87161636 disc_lossU 0.0540782586 gen_lossU 0.204699352 gen_lossW -0.550357461\n",
            "disc_lossW -1.50894415 disc_lossU 0.0606238246 gen_lossU 0.187690228 gen_lossW -0.562075734\n",
            "disc_lossW -1.04226589 disc_lossU 0.0586285964 gen_lossU 0.170032009 gen_lossW -0.65561986\n",
            "disc_lossW -1.03797424 disc_lossU 0.0393011197 gen_lossU 0.213385552 gen_lossW -0.724922538\n",
            "disc_lossW -1.89644742 disc_lossU 0.0609660223 gen_lossU 0.210556775 gen_lossW -0.704089\n",
            "disc_lossW -0.963692367 disc_lossU 0.0500564463 gen_lossU 0.208229154 gen_lossW -0.722708225\n",
            "disc_lossW -1.08860266 disc_lossU 0.0423407517 gen_lossU 0.212543517 gen_lossW -0.516567111\n",
            "disc_lossW -1.29822671 disc_lossU 0.0543118529 gen_lossU 0.202414364 gen_lossW -0.839863777\n",
            "disc_lossW -0.87161839 disc_lossU 0.0517867692 gen_lossU 0.210476726 gen_lossW -0.972233593\n",
            "disc_lossW -0.337335765 disc_lossU 0.043279916 gen_lossU 0.187040046 gen_lossW -1.08387125\n",
            "disc_lossW -0.919251 disc_lossU 0.0538581237 gen_lossU 0.273253143 gen_lossW -0.931309104\n",
            "disc_lossW -0.764544427 disc_lossU 0.0485720225 gen_lossU 0.237745583 gen_lossW -0.939049542\n",
            "disc_lossW -1.35651994 disc_lossU 0.0526756123 gen_lossU 0.230394885 gen_lossW -1.1159662\n",
            "disc_lossW -0.989815593 disc_lossU 0.0583858 gen_lossU 0.222297877 gen_lossW -1.03382516\n",
            "disc_lossW -1.40841103 disc_lossU 0.0650695413 gen_lossU 0.218538135 gen_lossW -1.41674209\n",
            "disc_lossW -0.76173836 disc_lossU 0.0537783876 gen_lossU 0.236924708 gen_lossW -1.59006023\n",
            "disc_lossW -0.481046438 disc_lossU 0.0451087691 gen_lossU 0.253074169 gen_lossW -1.66452193\n",
            "disc_lossW -0.640504301 disc_lossU 0.0563204959 gen_lossU 0.267301381 gen_lossW -1.76451302\n",
            "disc_lossW -0.341330528 disc_lossU 0.0656239092 gen_lossU 0.250015199 gen_lossW -1.9858557\n",
            "disc_lossW -0.684928834 disc_lossU 0.0398691222 gen_lossU 0.266515493 gen_lossW -1.58404982\n",
            "disc_lossW -0.736374497 disc_lossU 0.0559518561 gen_lossU 0.25369978 gen_lossW -1.76795924\n",
            "disc_lossW -0.756082535 disc_lossU 0.0534382276 gen_lossU 0.296760678 gen_lossW -2.06726718\n",
            "disc_lossW -0.945269763 disc_lossU 0.0647893324 gen_lossU 0.242094249 gen_lossW -2.19910097\n",
            "disc_lossW -1.09912312 disc_lossU 0.0543253124 gen_lossU 0.26454705 gen_lossW -1.90919149\n",
            "disc_lossW -0.71642673 disc_lossU 0.0521443263 gen_lossU 0.275819272 gen_lossW -2.31622553\n",
            "disc_lossW -0.775048375 disc_lossU 0.0504189357 gen_lossU 0.218605071 gen_lossW -2.35733461\n",
            "disc_lossW -0.701483846 disc_lossU 0.0603808686 gen_lossU 0.269183397 gen_lossW -2.48834062\n",
            "disc_lossW -1.00174 disc_lossU 0.0673553571 gen_lossU 0.272698551 gen_lossW -2.4844718\n",
            "disc_lossW -1.13284218 disc_lossU 0.0713962689 gen_lossU 0.278149068 gen_lossW -2.28882527\n",
            "disc_lossW -0.533365846 disc_lossU 0.0412103832 gen_lossU 0.264147848 gen_lossW -2.41127467\n",
            "disc_lossW -1.14504588 disc_lossU 0.0571685806 gen_lossU 0.297997117 gen_lossW -2.28504801\n",
            "disc_lossW -1.14161336 disc_lossU 0.0603820272 gen_lossU 0.267556757 gen_lossW -2.48482323\n",
            "disc_lossW -1.04443443 disc_lossU 0.0534646623 gen_lossU 0.248870522 gen_lossW -2.42826509\n",
            "disc_lossW -0.907774746 disc_lossU 0.0595705397 gen_lossU 0.246007025 gen_lossW -2.48668242\n",
            "disc_lossW -0.722792447 disc_lossU 0.0644355267 gen_lossU 0.31584388 gen_lossW -2.5659585\n",
            "disc_lossW -0.474455744 disc_lossU 0.052939795 gen_lossU 0.292289853 gen_lossW -2.70518661\n",
            "disc_lossW -0.587495625 disc_lossU 0.0503708608 gen_lossU 0.294550359 gen_lossW -2.91992092\n",
            "disc_lossW -0.555742 disc_lossU 0.0598191023 gen_lossU 0.289324522 gen_lossW -2.73142242\n",
            "disc_lossW -0.590485752 disc_lossU 0.0561949313 gen_lossU 0.276392579 gen_lossW -3.02701068\n",
            "disc_lossW -0.428876609 disc_lossU 0.0381066725 gen_lossU 0.323927969 gen_lossW -3.07768917\n",
            "disc_lossW -0.670246243 disc_lossU 0.0709284171 gen_lossU 0.330168664 gen_lossW -3.05053377\n",
            "disc_lossW -0.502252281 disc_lossU 0.0399243 gen_lossU 0.318018258 gen_lossW -3.11503649\n",
            "disc_lossW -0.781297565 disc_lossU 0.0479708798 gen_lossU 0.313852966 gen_lossW -3.00232887\n",
            "disc_lossW -0.653220952 disc_lossU 0.0514058881 gen_lossU 0.278980106 gen_lossW -3.24070811\n",
            "disc_lossW -0.450273335 disc_lossU 0.059394829 gen_lossU 0.316737831 gen_lossW -3.08577156\n",
            "disc_lossW -0.228723526 disc_lossU 0.0679838508 gen_lossU 0.280569553 gen_lossW -3.29211116\n",
            "disc_lossW -0.738562703 disc_lossU 0.0514868721 gen_lossU 0.275082439 gen_lossW -3.19789147\n",
            "disc_lossW -1.0490011 disc_lossU 0.0631635636 gen_lossU 0.300659955 gen_lossW -2.72938466\n",
            "disc_lossW -0.919330716 disc_lossU 0.0514584109 gen_lossU 0.289249241 gen_lossW -2.71527719\n",
            "disc_lossW -0.86865741 disc_lossU 0.041798085 gen_lossU 0.301969349 gen_lossW -2.36789465\n",
            "disc_lossW -0.53269732 disc_lossU 0.0726956874 gen_lossU 0.307495415 gen_lossW -2.7611084\n",
            "disc_lossW -0.880438328 disc_lossU 0.0583773479 gen_lossU 0.312148184 gen_lossW -2.48839617\n",
            "disc_lossW -0.599298835 disc_lossU 0.0473215766 gen_lossU 0.284367353 gen_lossW -2.58742428\n",
            "disc_lossW -1.55918837 disc_lossU 0.0452069975 gen_lossU 0.286749184 gen_lossW -2.38204813\n",
            "disc_lossW -0.847563922 disc_lossU 0.0585220344 gen_lossU 0.289936721 gen_lossW -2.59241819\n",
            "disc_lossW -0.816123426 disc_lossU 0.0574560836 gen_lossU 0.283365548 gen_lossW -2.52196407\n",
            "disc_lossW -0.234073058 disc_lossU 0.0529186949 gen_lossU 0.284310699 gen_lossW -3.0024848\n",
            "disc_lossW -0.840570331 disc_lossU 0.0415156111 gen_lossU 0.338796496 gen_lossW -2.67887473\n",
            "disc_lossW -1.02220619 disc_lossU 0.0485396795 gen_lossU 0.337753832 gen_lossW -2.61378551\n",
            "disc_lossW 0.275628328 disc_lossU 0.0517748818 gen_lossU 0.328410268 gen_lossW -3.05509043\n",
            "disc_lossW -0.475764573 disc_lossU 0.0507575981 gen_lossU 0.272316694 gen_lossW -3.17680407\n",
            "disc_lossW -0.810028791 disc_lossU 0.0608356111 gen_lossU 0.301245332 gen_lossW -2.90974808\n",
            "disc_lossW -1.10813487 disc_lossU 0.0443122238 gen_lossU 0.358671099 gen_lossW -3.34406137\n",
            "disc_lossW -0.297002375 disc_lossU 0.0473486446 gen_lossU 0.343490422 gen_lossW -3.12863278\n",
            "disc_lossW -0.443736285 disc_lossU 0.0643837154 gen_lossU 0.36104089 gen_lossW -3.50462842\n",
            "disc_lossW -0.581304908 disc_lossU 0.0571733788 gen_lossU 0.281463742 gen_lossW -3.72213507\n",
            "disc_lossW -0.741963267 disc_lossU 0.0443195328 gen_lossU 0.291719973 gen_lossW -3.64803386\n",
            "disc_lossW -0.372651517 disc_lossU 0.0560336113 gen_lossU 0.283459395 gen_lossW -3.7958138\n",
            "disc_lossW -0.350526303 disc_lossU 0.0359999798 gen_lossU 0.263471872 gen_lossW -4.04807377\n",
            "disc_lossW -0.900518715 disc_lossU 0.0585682467 gen_lossU 0.25572437 gen_lossW -3.94061804\n",
            "disc_lossW -0.29125163 disc_lossU 0.0530794337 gen_lossU 0.268339753 gen_lossW -4.06338882\n",
            "disc_lossW -1.1721946 disc_lossU 0.0373275355 gen_lossU 0.308011919 gen_lossW -3.78705716\n",
            "disc_lossW -0.590323389 disc_lossU 0.0554748289 gen_lossU 0.270620883 gen_lossW -3.97188687\n",
            "disc_lossW -0.445094943 disc_lossU 0.0537592284 gen_lossU 0.231625602 gen_lossW -4.19336939\n",
            "disc_lossW -0.402538419 disc_lossU 0.0589346476 gen_lossU 0.249125436 gen_lossW -4.03211355\n",
            "disc_lossW -0.489870846 disc_lossU 0.0367265753 gen_lossU 0.222825974 gen_lossW -4.03104305\n",
            "disc_lossW -0.837710738 disc_lossU 0.050773479 gen_lossU 0.232337981 gen_lossW -3.78259897\n",
            "disc_lossW -0.945097566 disc_lossU 0.0511255451 gen_lossU 0.267519563 gen_lossW -3.91190481\n",
            "disc_lossW -1.11172712 disc_lossU 0.044482965 gen_lossU 0.281498671 gen_lossW -3.60600233\n",
            "disc_lossW -0.965816319 disc_lossU 0.0471827686 gen_lossU 0.231714368 gen_lossW -4.00283\n",
            "disc_lossW -0.570349514 disc_lossU 0.0641976818 gen_lossU 0.200949177 gen_lossW -3.86491513\n",
            "disc_lossW -0.396694899 disc_lossU 0.0544553474 gen_lossU 0.238308296 gen_lossW -3.74114847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noise = tf.random.normal(shape=(1,100))\n",
        "test = generator.predict(noise)\n",
        "plt.imshow(test.squeeze(), cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "9vPp5AiDkrAF",
        "outputId": "bc5fd54e-47d0-4a43-a1a8-35f4e9a35497"
      },
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.min(x_train2))"
      ],
      "metadata": {
        "id": "fhuRFc0ro5T_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}