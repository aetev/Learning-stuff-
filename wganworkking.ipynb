{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aetev/Learning-stuff-/blob/main/wganworkking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiqIzzIPybri",
        "outputId": "365f2c01-c474-48b9-92c4-4a20c6808d83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xI7rEeMMgDQI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgyl_WtbgO5k",
        "outputId": "b696d074-4e7c-46ef-8609-1da1cadbbdfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "kik7wQ1qgOV-"
      },
      "outputs": [],
      "source": [
        "def make_generator_model():\n",
        "    input_noise = layers.Input(shape=(100,))\n",
        "    noise = layers.Dense(7*7*64)(input_noise)\n",
        "    noise = layers.Reshape((7, 7, 64))(noise)\n",
        "\n",
        "    input_digit = layers.Input(shape=(1,))\n",
        "    digit = layers.Embedding(10, 49)(input_digit)\n",
        "    digit = layers.Reshape((7, 7, 1))(digit)\n",
        "\n",
        "    x = layers.concatenate([noise, digit])\n",
        "\n",
        "    x = layers.Conv2DTranspose(128,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv2DTranspose(128,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv2D(1,3,1,padding='same',activation='sigmoid')(x)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=(input_noise,input_digit), outputs=x)\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "\n",
        "def make_discriminator_model():\n",
        "    input_img = layers.Input(shape=(28,28,1))\n",
        "\n",
        "    input_digit = layers.Input(shape=(1,))\n",
        "    digit = layers.Embedding(10, 5)(input_digit)\n",
        "    digit = layers.Flatten()(digit)\n",
        "    #digit = layers.Reshape((28, 28, 1))(digit)\n",
        "\n",
        "\n",
        "\n",
        "    x = layers.Conv2D(64,5,2,padding='same',activation='LeakyReLU')(input_img)\n",
        "\n",
        "\n",
        "    x = layers.Conv2D(64,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "\n",
        "    x = layers.Conv2D(64,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "\n",
        "    x = layers.Conv2D(64,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "\n",
        "    x = layers.concatenate([x, digit])\n",
        "\n",
        "    dense_output = layers.Dense(128, activation='LeakyReLU')(x)\n",
        "\n",
        "\n",
        "\n",
        "    dense_output = layers.Dense(64, activation='LeakyReLU')(x)\n",
        "\n",
        "\n",
        "    dense_output = layers.Dense(1, activation=None)(dense_output)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=(input_img,input_digit), outputs=dense_output)\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "qzdSabqdVu_H"
      },
      "outputs": [],
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "metadata": {
        "id": "lS0DF8rjhHdY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccc4170c-2844-40e9-b92a-e8d9d0eab352"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_47\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_103 (InputLayer)      [(None, 100)]                0         []                            \n",
            "                                                                                                  \n",
            " input_104 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " dense_103 (Dense)           (None, 3136)                 316736    ['input_103[0][0]']           \n",
            "                                                                                                  \n",
            " embedding_51 (Embedding)    (None, 1, 49)                490       ['input_104[0][0]']           \n",
            "                                                                                                  \n",
            " reshape_41 (Reshape)        (None, 7, 7, 64)             0         ['dense_103[0][0]']           \n",
            "                                                                                                  \n",
            " reshape_42 (Reshape)        (None, 7, 7, 1)              0         ['embedding_51[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_48 (Concatenat  (None, 7, 7, 65)             0         ['reshape_41[0][0]',          \n",
            " e)                                                                  'reshape_42[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose_38 (Conv2  (None, 14, 14, 128)          75008     ['concatenate_48[0][0]']      \n",
            " DTranspose)                                                                                      \n",
            "                                                                                                  \n",
            " batch_normalization_38 (Ba  (None, 14, 14, 128)          512       ['conv2d_transpose_38[0][0]'] \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_39 (Conv2  (None, 28, 28, 128)          147584    ['batch_normalization_38[0][0]\n",
            " DTranspose)                                                        ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_39 (Ba  (None, 28, 28, 128)          512       ['conv2d_transpose_39[0][0]'] \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_137 (Conv2D)         (None, 28, 28, 1)            1153      ['batch_normalization_39[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 541995 (2.07 MB)\n",
            "Trainable params: 541483 (2.07 MB)\n",
            "Non-trainable params: 512 (2.00 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "generator = make_generator_model()\n",
        "generator_optimizer = tf.keras.optimizers.Adam(0.0004)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "discriminatorW = make_discriminator_model()\n",
        "discriminatorW_optimizer = tf.keras.optimizers.Adam(0.0004)"
      ],
      "metadata": {
        "id": "GJxNxRSHkWfl"
      },
      "execution_count": 279,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminatorU = make_discriminator_model()\n",
        "discriminatorU_optimizer = tf.keras.optimizers.Adam(0.0002)"
      ],
      "metadata": {
        "id": "6cDVGo73jfqZ"
      },
      "execution_count": 280,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {
        "id": "DYQpIZyEgSlN"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "@tf.function\n",
        "def discriminator_lossW(real_output, fake_output):\n",
        "    real_loss = tf.reduce_mean(real_output)\n",
        "    fake_loss = tf.reduce_mean(fake_output)\n",
        "    total_loss = fake_loss - real_loss\n",
        "    return total_loss\n",
        "\n",
        "@tf.function\n",
        "def generator_lossW(fake_output):\n",
        "    return -tf.reduce_mean(fake_output)\n",
        "\n",
        "@tf.function\n",
        "def gradient_penalty(real_images, fake_images,digits):\n",
        "    alpha = tf.random.uniform([BATCH_SIZE, 1, 1, 1], 0., 1.)\n",
        "    real_images, fake_images = tf.cast(real_images, tf.float32), tf.cast(fake_images, tf.float32)\n",
        "    interpolated_images = alpha * real_images + ((1 - alpha) * fake_images)\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(interpolated_images)\n",
        "        pred = discriminatorW((interpolated_images,digits), training=True)\n",
        "    gradients = tape.gradient(pred, [interpolated_images])[0]\n",
        "    norm = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis=[1, 2, 3]))\n",
        "    gp = tf.reduce_mean((norm - 1.)**2)\n",
        "    return gp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "@tf.function\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "@tf.function\n",
        "def generator_loss(fake_output):\n",
        "    return -tf.reduce_mean(fake_output)"
      ],
      "metadata": {
        "id": "4rgSqI2sf1sT"
      },
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NOISE_DIM = 100\n",
        "\n",
        "@tf.function\n",
        "def train_step(real_images,digits):\n",
        "    with tf.GradientTape() as disc_tape, tf.GradientTape() as gen_tape:\n",
        "        # Generate random noise\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "\n",
        "        # Generate fake images with the generator\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        # Discriminator loss calculation\n",
        "        real_output = discriminatorU((real_images,digits), training=True)\n",
        "        fake_output = discriminatorU((generated_images,digits), training=True)\n",
        "        d_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "        # Generator loss calculation\n",
        "        g_loss = generator_loss(fake_output)\n",
        "\n",
        "    # Update generator and discriminator variables\n",
        "    gradients_of_discriminator = disc_tape.gradient(d_loss, discriminatorU.trainable_variables)\n",
        "    gradients_of_generator = gen_tape.gradient(g_loss, generator.trainable_variables)\n",
        "    discriminatorU_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminatorU.trainable_variables))\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    tf.print(\"disc_loss\",d_loss,'gen_loss',g_loss)"
      ],
      "metadata": {
        "id": "ilj-woz7fSum"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NOISE_DIM = 100\n",
        "\n",
        "#@tf.function\n",
        "def train_step(real_images,digits):\n",
        "\n",
        "    for i in range(5):\n",
        "      with tf.GradientTape() as disc_tape:\n",
        "        # Generate random noise\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "\n",
        "        # Generate fake images with the generator\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        # Discriminator loss calculation\n",
        "        real_output = discriminatorU((real_images,digits), training=True)\n",
        "        fake_output = discriminatorU((generated_images,digits), training=True)\n",
        "        d_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "\n",
        "      gradients_of_discriminator = disc_tape.gradient(d_loss, discriminatorU.trainable_variables)\n",
        "      discriminatorU_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminatorU.trainable_variables))\n",
        "\n",
        "      if i == 0:\n",
        "        weights = discriminatorU.get_weights()\n",
        "\n",
        "    with tf.GradientTape() as gen_tape:\n",
        "      # Generate random noise\n",
        "      noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "\n",
        "      # Generate fake images with the generator\n",
        "      generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "      fake_output = discriminatorU((generated_images,digits), training=True)\n",
        "\n",
        "       # Generator loss calculation\n",
        "      g_loss = generator_loss(fake_output)\n",
        "\n",
        "    # Update generator and discriminator variables\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(g_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    discriminatorU.set_weights(weights)\n",
        "\n",
        "    tf.print(\"disc_loss\",d_loss,'gen_loss',g_loss)"
      ],
      "metadata": {
        "id": "8AuOxPdvp1hu"
      },
      "execution_count": 281,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {
        "id": "cP3-wZztEeaE"
      },
      "outputs": [],
      "source": [
        "NOISE_DIM = 100\n",
        "GP_WEIGHT = 10\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def train_step(images,digits):\n",
        "\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tapeW:\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        real_outputW = discriminatorW((images,digits), training=True)\n",
        "        fake_outputW = discriminatorW((generated_images,digits), training=True)\n",
        "\n",
        "        disc_lossW = discriminator_lossW(real_outputW, fake_outputW)\n",
        "\n",
        "        gen_lossW = generator_lossW(fake_outputW)\n",
        "        gen_loss = gen_lossW\n",
        "\n",
        "        gp = gradient_penalty(images, generated_images, digits)\n",
        "        disc_lossW += gp * GP_WEIGHT\n",
        "\n",
        "\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    gradients_of_discriminatorW = disc_tapeW.gradient(disc_lossW, discriminatorW.trainable_variables)\n",
        "    discriminatorW_optimizer.apply_gradients(zip(gradients_of_discriminatorW, discriminatorW.trainable_variables))\n",
        "\n",
        "\n",
        "    tf.print(\"disc_lossW\",disc_lossW,'gen_lossW',gen_lossW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 274,
      "metadata": {
        "id": "Sx_KbIfjiogE"
      },
      "outputs": [],
      "source": [
        "def train(dataset,y_train, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    for batch in range(len(dataset) // BATCH_SIZE):\n",
        "\n",
        "            target_images = dataset[batch * BATCH_SIZE: (batch+1) * BATCH_SIZE]\n",
        "            digits = y_train[batch * BATCH_SIZE: (batch+1) * BATCH_SIZE]\n",
        "\n",
        "            train_step(target_images,digits)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      print(epoch)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWp_3RkPg248",
        "outputId": "998dffb3-9a00-428f-9a26-2b8615753162",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "disc_loss 1.28918862 gen_loss 0.246765047\n",
            "disc_loss 1.26520872 gen_loss 0.321545869\n",
            "disc_loss 1.22603333 gen_loss 0.392985016\n",
            "disc_loss 1.20744562 gen_loss 0.4819628\n",
            "disc_loss 1.16422844 gen_loss 0.597998381\n",
            "disc_loss 1.11205864 gen_loss 0.710936785\n",
            "disc_loss 1.07110465 gen_loss 0.872304797\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 100\n",
        "x_train2 = np.expand_dims(x_train, axis=-1)\n",
        "x_train2 = (x_train2 - np.min(x_train2)) / (np.max(x_train2) - np.min(x_train2))\n",
        "train(x_train2,y_train, EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "9vPp5AiDkrAF",
        "outputId": "5df9130b-c079-46d1-dd81-53325df89d93",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n",
            "tf.Tensor([5], shape=(1,), dtype=int32)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "noise = tf.random.normal(shape=(1,100))\n",
        "random_number = tf.random.uniform(shape=[1,], minval=0, maxval=10, dtype=tf.int32)\n",
        "test = generator.predict((noise,random_number))\n",
        "print(random_number)\n",
        "plt.imshow(test.squeeze(), cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NOISE_DIM = 100\n",
        "GP_WEIGHT = 10\n",
        "\n",
        "\n",
        "#@tf.function\n",
        "def train_step(images,digits):\n",
        "\n",
        "\n",
        "    for i in range(3):\n",
        "      with tf.GradientTape() as disc_tapeU:\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        real_outputU = discriminatorU((images,digits), training=True)\n",
        "        fake_outputU = discriminatorU((generated_images,digits), training=True)\n",
        "        disc_lossU = cross_entropy(tf.ones_like(real_outputU), real_outputU)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      gradients_of_discriminatorU = disc_tapeU.gradient(disc_lossU, discriminatorU.trainable_variables)\n",
        "      discriminatorU_optimizer.apply_gradients(zip(gradients_of_discriminatorU, discriminatorU.trainable_variables))\n",
        "      if i == 0:\n",
        "        weights = discriminatorU.get_weights()\n",
        "\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tapeW:\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        real_outputW = discriminatorW((images,digits), training=True)\n",
        "        fake_outputW = discriminatorW((generated_images,digits), training=True)\n",
        "        real_outputU = discriminatorU((images,digits), training=True)\n",
        "        fake_outputU = discriminatorU((generated_images,digits), training=True)\n",
        "        disc_lossW = discriminator_lossW(real_outputW, fake_outputW)\n",
        "\n",
        "\n",
        "        gen_lossU = cross_entropy(tf.ones_like(fake_outputU), fake_outputU)\n",
        "        gen_lossW = generator_lossW(fake_outputW)\n",
        "        gen_loss = gen_lossU#+gen_lossW\n",
        "\n",
        "        gp = gradient_penalty(images, generated_images, digits)\n",
        "        disc_lossW += gp * GP_WEIGHT\n",
        "\n",
        "\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    gradients_of_discriminatorW = disc_tapeW.gradient(disc_lossW, discriminatorW.trainable_variables)\n",
        "    discriminatorW_optimizer.apply_gradients(zip(gradients_of_discriminatorW, discriminatorW.trainable_variables))\n",
        "\n",
        "    discriminatorU.set_weights(weights)\n",
        "\n",
        "    tf.print(\"disc_lossW\",disc_lossW,'disc_lossU',disc_lossU,'gen_lossU',gen_lossU,'gen_lossW',gen_lossW)"
      ],
      "metadata": {
        "id": "_r4IEg2iBLvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhuRFc0ro5T_"
      },
      "outputs": [],
      "source": [
        "print(np.min(x_train2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojIuJFIAybro"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}