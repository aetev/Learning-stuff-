{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aetev/Learning-stuff-/blob/main/wganworkking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiqIzzIPybri",
        "outputId": "365f2c01-c474-48b9-92c4-4a20c6808d83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xI7rEeMMgDQI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgyl_WtbgO5k",
        "outputId": "b696d074-4e7c-46ef-8609-1da1cadbbdfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "kik7wQ1qgOV-"
      },
      "outputs": [],
      "source": [
        "def make_generator_model():\n",
        "    input_noise = layers.Input(shape=(100,))\n",
        "    noise = layers.Dense(7*7*64)(input_noise)\n",
        "    noise = layers.Reshape((7, 7, 64))(noise)\n",
        "\n",
        "    input_digit = layers.Input(shape=(1,))\n",
        "    digit = layers.Embedding(10, 49)(input_digit)\n",
        "    digit = layers.Reshape((7, 7, 1))(digit)\n",
        "\n",
        "    x = layers.concatenate([noise, digit])\n",
        "\n",
        "    x = layers.Conv2DTranspose(128,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv2DTranspose(128,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv2D(1,3,1,padding='same',activation='sigmoid')(x)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=(input_noise,input_digit), outputs=x)\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "\n",
        "def make_discriminator_model():\n",
        "    input_img = layers.Input(shape=(28,28,1))\n",
        "\n",
        "    input_digit = layers.Input(shape=(1,))\n",
        "    digit = layers.Embedding(10, 5)(input_digit)\n",
        "    digit = layers.Flatten()(digit)\n",
        "    #digit = layers.Reshape((28, 28, 1))(digit)\n",
        "\n",
        "\n",
        "\n",
        "    x = layers.Conv2D(64,5,2,padding='same',activation='LeakyReLU')(input_img)\n",
        "\n",
        "\n",
        "    x = layers.Conv2D(64,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "\n",
        "    x = layers.Conv2D(64,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "\n",
        "    x = layers.Conv2D(64,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "\n",
        "    x = layers.concatenate([x, digit])\n",
        "\n",
        "    dense_output = layers.Dense(128, activation='LeakyReLU')(x)\n",
        "\n",
        "\n",
        "\n",
        "    dense_output = layers.Dense(64, activation='LeakyReLU')(x)\n",
        "\n",
        "\n",
        "    dense_output = layers.Dense(1, activation=None)(dense_output)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=(input_img,input_digit), outputs=dense_output)\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "qzdSabqdVu_H"
      },
      "outputs": [],
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 303,
      "metadata": {
        "id": "lS0DF8rjhHdY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d25b6d7b-6ff5-4d08-e078-ebcca2e2568a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_50\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_109 (InputLayer)      [(None, 100)]                0         []                            \n",
            "                                                                                                  \n",
            " input_110 (InputLayer)      [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " dense_110 (Dense)           (None, 3136)                 316736    ['input_109[0][0]']           \n",
            "                                                                                                  \n",
            " embedding_54 (Embedding)    (None, 1, 49)                490       ['input_110[0][0]']           \n",
            "                                                                                                  \n",
            " reshape_43 (Reshape)        (None, 7, 7, 64)             0         ['dense_110[0][0]']           \n",
            "                                                                                                  \n",
            " reshape_44 (Reshape)        (None, 7, 7, 1)              0         ['embedding_54[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_51 (Concatenat  (None, 7, 7, 65)             0         ['reshape_43[0][0]',          \n",
            " e)                                                                  'reshape_44[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose_40 (Conv2  (None, 14, 14, 128)          75008     ['concatenate_51[0][0]']      \n",
            " DTranspose)                                                                                      \n",
            "                                                                                                  \n",
            " batch_normalization_40 (Ba  (None, 14, 14, 128)          512       ['conv2d_transpose_40[0][0]'] \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_41 (Conv2  (None, 28, 28, 128)          147584    ['batch_normalization_40[0][0]\n",
            " DTranspose)                                                        ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_41 (Ba  (None, 28, 28, 128)          512       ['conv2d_transpose_41[0][0]'] \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_146 (Conv2D)         (None, 28, 28, 1)            1153      ['batch_normalization_41[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 541995 (2.07 MB)\n",
            "Trainable params: 541483 (2.07 MB)\n",
            "Non-trainable params: 512 (2.00 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "generator = make_generator_model()\n",
        "generator_optimizer = tf.keras.optimizers.Adam(0.0004)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "discriminatorW = make_discriminator_model()\n",
        "discriminatorW_optimizer = tf.keras.optimizers.Adam(0.0004)"
      ],
      "metadata": {
        "id": "GJxNxRSHkWfl"
      },
      "execution_count": 304,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminatorU = make_discriminator_model()\n",
        "discriminatorU_optimizer = tf.keras.optimizers.Adam(0.0003)"
      ],
      "metadata": {
        "id": "6cDVGo73jfqZ"
      },
      "execution_count": 305,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 306,
      "metadata": {
        "id": "DYQpIZyEgSlN"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "@tf.function\n",
        "def discriminator_lossW(real_output, fake_output):\n",
        "    real_loss = tf.reduce_mean(real_output)\n",
        "    fake_loss = tf.reduce_mean(fake_output)\n",
        "    total_loss = fake_loss - real_loss\n",
        "    return total_loss\n",
        "\n",
        "@tf.function\n",
        "def generator_lossW(fake_output):\n",
        "    return -tf.reduce_mean(fake_output)\n",
        "\n",
        "@tf.function\n",
        "def gradient_penalty(real_images, fake_images,digits):\n",
        "    alpha = tf.random.uniform([BATCH_SIZE, 1, 1, 1], 0., 1.)\n",
        "    real_images, fake_images = tf.cast(real_images, tf.float32), tf.cast(fake_images, tf.float32)\n",
        "    interpolated_images = alpha * real_images + ((1 - alpha) * fake_images)\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(interpolated_images)\n",
        "        pred = discriminatorW((interpolated_images,digits), training=True)\n",
        "    gradients = tape.gradient(pred, [interpolated_images])[0]\n",
        "    norm = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis=[1, 2, 3]))\n",
        "    gp = tf.reduce_mean((norm - 1.)**2)\n",
        "    return gp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "@tf.function\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "@tf.function\n",
        "def generator_loss(fake_output):\n",
        "    return -tf.reduce_mean(fake_output)"
      ],
      "metadata": {
        "id": "4rgSqI2sf1sT"
      },
      "execution_count": 307,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NOISE_DIM = 100\n",
        "\n",
        "@tf.function\n",
        "def train_step(real_images,digits):\n",
        "    with tf.GradientTape() as disc_tape, tf.GradientTape() as gen_tape:\n",
        "        # Generate random noise\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "\n",
        "        # Generate fake images with the generator\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        # Discriminator loss calculation\n",
        "        real_output = discriminatorU((real_images,digits), training=True)\n",
        "        fake_output = discriminatorU((generated_images,digits), training=True)\n",
        "        d_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "        # Generator loss calculation\n",
        "        g_loss = generator_loss(fake_output)\n",
        "\n",
        "    # Update generator and discriminator variables\n",
        "    gradients_of_discriminator = disc_tape.gradient(d_loss, discriminatorU.trainable_variables)\n",
        "    gradients_of_generator = gen_tape.gradient(g_loss, generator.trainable_variables)\n",
        "    discriminatorU_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminatorU.trainable_variables))\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    tf.print(\"disc_loss\",d_loss,'gen_loss',g_loss)"
      ],
      "metadata": {
        "id": "ilj-woz7fSum"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NOISE_DIM = 100\n",
        "\n",
        "#@tf.function\n",
        "def train_step(real_images,digits):\n",
        "\n",
        "    for i in range(5):\n",
        "      with tf.GradientTape() as disc_tape:\n",
        "        # Generate random noise\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "\n",
        "        # Generate fake images with the generator\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        # Discriminator loss calculation\n",
        "        real_output = discriminatorU((real_images,digits), training=True)\n",
        "        fake_output = discriminatorU((generated_images,digits), training=True)\n",
        "        d_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "\n",
        "      gradients_of_discriminator = disc_tape.gradient(d_loss, discriminatorU.trainable_variables)\n",
        "      discriminatorU_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminatorU.trainable_variables))\n",
        "\n",
        "      if i == 0:\n",
        "        weights = discriminatorU.get_weights()\n",
        "\n",
        "    with tf.GradientTape() as gen_tape:\n",
        "      # Generate random noise\n",
        "      noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "\n",
        "      # Generate fake images with the generator\n",
        "      generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "      fake_output = discriminatorU((generated_images,digits), training=True)\n",
        "\n",
        "       # Generator loss calculation\n",
        "      g_loss = generator_loss(fake_output)\n",
        "\n",
        "    # Update generator and discriminator variables\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(g_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    discriminatorU.set_weights(weights)\n",
        "\n",
        "    tf.print(\"disc_loss\",d_loss,'gen_loss',g_loss)"
      ],
      "metadata": {
        "id": "8AuOxPdvp1hu"
      },
      "execution_count": 308,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {
        "id": "cP3-wZztEeaE"
      },
      "outputs": [],
      "source": [
        "NOISE_DIM = 100\n",
        "GP_WEIGHT = 10\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def train_step(images,digits):\n",
        "\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tapeW:\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        real_outputW = discriminatorW((images,digits), training=True)\n",
        "        fake_outputW = discriminatorW((generated_images,digits), training=True)\n",
        "\n",
        "        disc_lossW = discriminator_lossW(real_outputW, fake_outputW)\n",
        "\n",
        "        gen_lossW = generator_lossW(fake_outputW)\n",
        "        gen_loss = gen_lossW\n",
        "\n",
        "        gp = gradient_penalty(images, generated_images, digits)\n",
        "        disc_lossW += gp * GP_WEIGHT\n",
        "\n",
        "\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    gradients_of_discriminatorW = disc_tapeW.gradient(disc_lossW, discriminatorW.trainable_variables)\n",
        "    discriminatorW_optimizer.apply_gradients(zip(gradients_of_discriminatorW, discriminatorW.trainable_variables))\n",
        "\n",
        "\n",
        "    tf.print(\"disc_lossW\",disc_lossW,'gen_lossW',gen_lossW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 309,
      "metadata": {
        "id": "Sx_KbIfjiogE"
      },
      "outputs": [],
      "source": [
        "def train(dataset,y_train, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    for batch in range(len(dataset) // BATCH_SIZE):\n",
        "\n",
        "            target_images = dataset[batch * BATCH_SIZE: (batch+1) * BATCH_SIZE]\n",
        "            digits = y_train[batch * BATCH_SIZE: (batch+1) * BATCH_SIZE]\n",
        "\n",
        "            train_step(target_images,digits)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      print(epoch)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWp_3RkPg248",
        "outputId": "abdea0dc-0c72-4e0c-f1b8-89df38857a04",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "disc_loss 0.121565267 gen_loss 4.41849\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 100\n",
        "x_train2 = np.expand_dims(x_train, axis=-1)\n",
        "x_train2 = (x_train2 - np.min(x_train2)) / (np.max(x_train2) - np.min(x_train2))\n",
        "train(x_train2,y_train, EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 315,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "9vPp5AiDkrAF",
        "outputId": "dee342bd-3b1c-4b31-d70d-ea05688be34e",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 34ms/step\n",
            "tf.Tensor([2], shape=(1,), dtype=int32)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "noise = tf.random.normal(shape=(1,100))\n",
        "random_number = tf.random.uniform(shape=[1,], minval=0, maxval=10, dtype=tf.int32)\n",
        "test = generator.predict((noise,random_number))\n",
        "print(random_number)\n",
        "plt.imshow(test.squeeze(), cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NOISE_DIM = 100\n",
        "GP_WEIGHT = 10\n",
        "\n",
        "\n",
        "#@tf.function\n",
        "def train_step(images,digits):\n",
        "\n",
        "\n",
        "    for i in range(3):\n",
        "      with tf.GradientTape() as disc_tapeU:\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        real_outputU = discriminatorU((images,digits), training=True)\n",
        "        fake_outputU = discriminatorU((generated_images,digits), training=True)\n",
        "        disc_lossU = cross_entropy(tf.ones_like(real_outputU), real_outputU)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      gradients_of_discriminatorU = disc_tapeU.gradient(disc_lossU, discriminatorU.trainable_variables)\n",
        "      discriminatorU_optimizer.apply_gradients(zip(gradients_of_discriminatorU, discriminatorU.trainable_variables))\n",
        "      if i == 0:\n",
        "        weights = discriminatorU.get_weights()\n",
        "\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tapeW:\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        real_outputW = discriminatorW((images,digits), training=True)\n",
        "        fake_outputW = discriminatorW((generated_images,digits), training=True)\n",
        "        real_outputU = discriminatorU((images,digits), training=True)\n",
        "        fake_outputU = discriminatorU((generated_images,digits), training=True)\n",
        "        disc_lossW = discriminator_lossW(real_outputW, fake_outputW)\n",
        "\n",
        "\n",
        "        gen_lossU = cross_entropy(tf.ones_like(fake_outputU), fake_outputU)\n",
        "        gen_lossW = generator_lossW(fake_outputW)\n",
        "        gen_loss = gen_lossU#+gen_lossW\n",
        "\n",
        "        gp = gradient_penalty(images, generated_images, digits)\n",
        "        disc_lossW += gp * GP_WEIGHT\n",
        "\n",
        "\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    gradients_of_discriminatorW = disc_tapeW.gradient(disc_lossW, discriminatorW.trainable_variables)\n",
        "    discriminatorW_optimizer.apply_gradients(zip(gradients_of_discriminatorW, discriminatorW.trainable_variables))\n",
        "\n",
        "    discriminatorU.set_weights(weights)\n",
        "\n",
        "    tf.print(\"disc_lossW\",disc_lossW,'disc_lossU',disc_lossU,'gen_lossU',gen_lossU,'gen_lossW',gen_lossW)"
      ],
      "metadata": {
        "id": "_r4IEg2iBLvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhuRFc0ro5T_"
      },
      "outputs": [],
      "source": [
        "print(np.min(x_train2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojIuJFIAybro"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}