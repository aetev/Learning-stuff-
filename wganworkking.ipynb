{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/an/B9qU5O3uWSEIdSqgw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aetev/Learning-stuff-/blob/main/wganworkking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xI7rEeMMgDQI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgyl_WtbgO5k",
        "outputId": "b8fe388b-053f-4353-a985-e218964cd9cb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(7*7,activation='LeakyReLU',use_bias=False, input_shape=(100,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dense(14*14,activation='LeakyReLU',use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dense(28*28,activation='LeakyReLU',use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dense(28*28,activation='sigmoid',use_bias=False))\n",
        "    model.add(layers.Reshape((28,28,1)))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def make_discriminator_model():\n",
        "    input_img = layers.Input(shape=(28,28,1))\n",
        "\n",
        "    x = layers.Conv2D(64,3,2,padding='same',activation='LeakyReLU')(input_img)\n",
        "\n",
        "    x = layers.Dropout(.2)(x)\n",
        "\n",
        "    x = layers.Conv2D(64,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.Dropout(.2)(x)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "\n",
        "    dense_output = layers.Dense(128, activation='LeakyReLU')(x)\n",
        "\n",
        "\n",
        "    x = layers.Dropout(.2)(x)\n",
        "\n",
        "    dense_output = layers.Dense(64, activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.Dropout(.2)(x)\n",
        "\n",
        "    dense_output = layers.Dense(1, activation=None)(dense_output)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=input_img, outputs=dense_output)\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "kik7wQ1qgOV-"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "qzdSabqdVu_H"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = make_generator_model()\n",
        "discriminatorW = make_discriminator_model()\n",
        "discriminatorU = make_discriminator_model()\n",
        "generator_optimizer = tf.keras.optimizers.Adam(0.0004)\n",
        "discriminatorW_optimizer = tf.keras.optimizers.Adam(0.0004)\n",
        "discriminatorU_optimizer = tf.keras.optimizers.Adam(0.00004)"
      ],
      "metadata": {
        "id": "lS0DF8rjhHdY"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 10\n",
        "\n",
        "#@tf.function\n",
        "def discriminator_lossW(real_output, fake_output):\n",
        "    real_loss = tf.reduce_mean(real_output)\n",
        "    fake_loss = tf.reduce_mean(fake_output)\n",
        "    total_loss = fake_loss - real_loss\n",
        "    return total_loss\n",
        "\n",
        "#@tf.function\n",
        "def generator_lossW(fake_output):\n",
        "    return -tf.reduce_mean(fake_output)\n",
        "\n",
        "#@tf.function\n",
        "def gradient_penalty(real_images, fake_images):\n",
        "    alpha = tf.random.uniform([BATCH_SIZE, 1, 1, 1], 0., 1.)\n",
        "    real_images, fake_images = tf.cast(real_images, tf.float32), tf.cast(fake_images, tf.float32)\n",
        "    interpolated_images = alpha * real_images + ((1 - alpha) * fake_images)\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(interpolated_images)\n",
        "        pred = discriminatorW(interpolated_images, training=True)\n",
        "    gradients = tape.gradient(pred, [interpolated_images])[0]\n",
        "    norm = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis=[1, 2, 3]))\n",
        "    gp = tf.reduce_mean((norm - 1.)**2)\n",
        "    return gp"
      ],
      "metadata": {
        "id": "DYQpIZyEgSlN"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NOISE_DIM = 100\n",
        "GP_WEIGHT = 10\n",
        "\n",
        "\n",
        "#@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "\n",
        "\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tapeW, tf.GradientTape() as disc_tapeU:\n",
        "        generated_images = generator(noise, training=True)\n",
        "\n",
        "        real_outputW = discriminatorW(images, training=True)\n",
        "        fake_outputW = discriminatorW(generated_images, training=True)\n",
        "\n",
        "        real_outputU = discriminatorU(images, training=True)\n",
        "        fake_outputU = discriminatorU(generated_images, training=True)\n",
        "\n",
        "        disc_lossW = discriminator_lossW(real_outputW, fake_outputW)\n",
        "        disc_lossU = cross_entropy(tf.ones_like(real_outputU), real_outputU)\n",
        "\n",
        "\n",
        "        gen_loss = cross_entropy(tf.ones_like(fake_outputU), fake_outputU)*25\n",
        "        gen_loss += generator_lossW(fake_outputW)\n",
        "\n",
        "        gp = gradient_penalty(images, generated_images)\n",
        "        disc_lossW += gp * GP_WEIGHT\n",
        "\n",
        "\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    gradients_of_discriminatorW = disc_tapeW.gradient(disc_lossW, discriminatorW.trainable_variables)\n",
        "    gradients_of_discriminatorU = disc_tapeU.gradient(disc_lossU, discriminatorU.trainable_variables)\n",
        "    discriminatorW_optimizer.apply_gradients(zip(gradients_of_discriminatorW, discriminatorW.trainable_variables))\n",
        "    discriminatorU_optimizer.apply_gradients(zip(gradients_of_discriminatorU, discriminatorU.trainable_variables))\n",
        "\n",
        "    tf.print(\"disc_lossW\",disc_lossW,'disc_lossU',disc_lossU,'gen_loss',gen_loss)"
      ],
      "metadata": {
        "id": "cP3-wZztEeaE"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    for batch in range(len(dataset) // BATCH_SIZE):\n",
        "\n",
        "            target_images = dataset[batch * BATCH_SIZE: (batch+1) * BATCH_SIZE]\n",
        "\n",
        "\n",
        "            train_step(target_images)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      print(epoch)\n",
        "\n"
      ],
      "metadata": {
        "id": "Sx_KbIfjiogE"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "x_train2 = np.expand_dims(x_train, axis=-1)\n",
        "x_train2 = (x_train2 - np.min(x_train2)) / (np.max(x_train2) - np.min(x_train2))\n",
        "train(x_train2, EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IWp_3RkPg248",
        "outputId": "a5e42a56-db74-4652-9dc8-9973ccdfc787"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "disc_lossW -12.5298901 disc_lossU 0.0225407258 gen_loss 17.4304619\n",
            "disc_lossW -12.6457148 disc_lossU 0.0237496402 gen_loss 17.3700867\n",
            "disc_lossW -11.947258 disc_lossU 0.0180955119 gen_loss 17.3964729\n",
            "disc_lossW -12.5145702 disc_lossU 0.0138050644 gen_loss 17.3065948\n",
            "disc_lossW -12.3337383 disc_lossU 0.0260891765 gen_loss 16.7424278\n",
            "disc_lossW -11.9052296 disc_lossU 0.0135772526 gen_loss 16.8522644\n",
            "disc_lossW -11.7369528 disc_lossU 0.0157211032 gen_loss 16.8954182\n",
            "disc_lossW -12.2761278 disc_lossU 0.0181069914 gen_loss 16.4557095\n",
            "disc_lossW -11.3550653 disc_lossU 0.00990600232 gen_loss 16.502985\n",
            "disc_lossW -12.4294233 disc_lossU 0.0149081247 gen_loss 16.4538269\n",
            "disc_lossW -11.8115282 disc_lossU 0.0202697478 gen_loss 15.890626\n",
            "disc_lossW -11.1055565 disc_lossU 0.0117165083 gen_loss 15.5780392\n",
            "disc_lossW -11.4090319 disc_lossU 0.0142109366 gen_loss 15.7628965\n",
            "disc_lossW -11.7481298 disc_lossU 0.0119959386 gen_loss 15.4509239\n",
            "disc_lossW -11.7920609 disc_lossU 0.0153074414 gen_loss 15.5803156\n",
            "disc_lossW -11.2286043 disc_lossU 0.0157722775 gen_loss 15.0529308\n",
            "disc_lossW -11.5331287 disc_lossU 0.00683592167 gen_loss 15.1390619\n",
            "disc_lossW -11.7855186 disc_lossU 0.0158750787 gen_loss 15.6312017\n",
            "disc_lossW -10.8472462 disc_lossU 0.00982222147 gen_loss 15.1076889\n",
            "disc_lossW -10.9911613 disc_lossU 0.00911235716 gen_loss 15.0477924\n",
            "disc_lossW -11.243288 disc_lossU 0.0113360211 gen_loss 14.8489895\n",
            "disc_lossW -11.0110092 disc_lossU 0.0121135768 gen_loss 14.3004303\n",
            "disc_lossW -10.1104221 disc_lossU 0.00693502929 gen_loss 14.373539\n",
            "disc_lossW -11.1588974 disc_lossU 0.0105576459 gen_loss 14.068799\n",
            "disc_lossW -10.4981 disc_lossU 0.00849014614 gen_loss 14.0150108\n",
            "disc_lossW -10.8098202 disc_lossU 0.0105336038 gen_loss 13.9032354\n",
            "disc_lossW -10.9031429 disc_lossU 0.0125644151 gen_loss 13.8778286\n",
            "disc_lossW -10.8933744 disc_lossU 0.019702537 gen_loss 13.6500139\n",
            "disc_lossW -9.95909309 disc_lossU 0.0130099151 gen_loss 13.6171885\n",
            "disc_lossW -9.59621 disc_lossU 0.00668277359 gen_loss 13.3103838\n",
            "disc_lossW -10.9598665 disc_lossU 0.0114698624 gen_loss 13.6226139\n",
            "disc_lossW -11.0515518 disc_lossU 0.0150827039 gen_loss 13.6898975\n",
            "disc_lossW -9.85626 disc_lossU 0.00531661976 gen_loss 13.3519402\n",
            "disc_lossW -10.1181021 disc_lossU 0.00783031 gen_loss 13.3416595\n",
            "disc_lossW -10.0007906 disc_lossU 0.00876289606 gen_loss 13.167161\n",
            "disc_lossW -10.274725 disc_lossU 0.0132720452 gen_loss 12.6173811\n",
            "disc_lossW -10.1777859 disc_lossU 0.0116897281 gen_loss 12.6646862\n",
            "disc_lossW -9.70583534 disc_lossU 0.00880283862 gen_loss 12.2542353\n",
            "disc_lossW -9.72740841 disc_lossU 0.00915698893 gen_loss 12.1846113\n",
            "disc_lossW -9.62400436 disc_lossU 0.012587212 gen_loss 12.3812304\n",
            "disc_lossW -10.006238 disc_lossU 0.0115259495 gen_loss 12.4693203\n",
            "disc_lossW -9.38002205 disc_lossU 0.0156930629 gen_loss 11.7549849\n",
            "disc_lossW -8.94988346 disc_lossU 0.00648352131 gen_loss 12.063015\n",
            "disc_lossW -8.79538631 disc_lossU 0.0101308255 gen_loss 11.7247858\n",
            "disc_lossW -9.23045731 disc_lossU 0.011678962 gen_loss 11.7253017\n",
            "disc_lossW -8.88983 disc_lossU 0.0117525971 gen_loss 11.5663319\n",
            "disc_lossW -8.11345387 disc_lossU 0.0110182557 gen_loss 11.3494015\n",
            "disc_lossW -8.7767067 disc_lossU 0.0119331647 gen_loss 11.1638212\n",
            "disc_lossW -8.35723686 disc_lossU 0.00935596693 gen_loss 10.8080349\n",
            "disc_lossW -8.51032257 disc_lossU 0.00671125064 gen_loss 10.8798132\n",
            "disc_lossW -8.49091244 disc_lossU 0.00993100274 gen_loss 10.5477304\n",
            "disc_lossW -8.22963524 disc_lossU 0.00946569908 gen_loss 10.5648298\n",
            "disc_lossW -7.39826679 disc_lossU 0.00455013709 gen_loss 10.2858419\n",
            "disc_lossW -8.79497528 disc_lossU 0.0116668325 gen_loss 10.3771334\n",
            "disc_lossW -7.70053768 disc_lossU 0.00516219437 gen_loss 10.0768728\n",
            "disc_lossW -8.06388283 disc_lossU 0.00723893801 gen_loss 10.156455\n",
            "disc_lossW -7.94978857 disc_lossU 0.00713251671 gen_loss 10.007163\n",
            "disc_lossW -7.86761 disc_lossU 0.00949305296 gen_loss 9.87841225\n",
            "disc_lossW -7.92233229 disc_lossU 0.0120080095 gen_loss 9.51155758\n",
            "disc_lossW -7.45768499 disc_lossU 0.00663383026 gen_loss 9.64522743\n",
            "disc_lossW -7.8612833 disc_lossU 0.0129288863 gen_loss 9.46441174\n",
            "disc_lossW -7.208395 disc_lossU 0.00799114723 gen_loss 8.81225491\n",
            "disc_lossW -6.4323678 disc_lossU 0.004105167 gen_loss 9.14869785\n",
            "disc_lossW -7.36659145 disc_lossU 0.0137701873 gen_loss 8.91446686\n",
            "disc_lossW -6.85104465 disc_lossU 0.0097027747 gen_loss 8.68637562\n",
            "disc_lossW -6.68489933 disc_lossU 0.0037794509 gen_loss 8.46277\n",
            "disc_lossW -6.02429819 disc_lossU 0.00457804231 gen_loss 8.01131153\n",
            "disc_lossW -6.76297426 disc_lossU 0.00775693636 gen_loss 8.06830215\n",
            "disc_lossW -6.68001842 disc_lossU 0.00643777195 gen_loss 7.95533609\n",
            "disc_lossW -6.45578718 disc_lossU 0.00501753716 gen_loss 7.65119123\n",
            "disc_lossW -6.097826 disc_lossU 0.00429278379 gen_loss 7.53774309\n",
            "disc_lossW -5.84915543 disc_lossU 0.004960272 gen_loss 7.40152693\n",
            "disc_lossW -6.13021278 disc_lossU 0.00486941 gen_loss 7.36528683\n",
            "disc_lossW -5.94628859 disc_lossU 0.0062863254 gen_loss 7.43187904\n",
            "disc_lossW -6.07598972 disc_lossU 0.00597957242 gen_loss 7.05749655\n",
            "disc_lossW -5.53888607 disc_lossU 0.00587879401 gen_loss 6.77758646\n",
            "disc_lossW -5.55054712 disc_lossU 0.00381063786 gen_loss 6.67281151\n",
            "disc_lossW -5.90476418 disc_lossU 0.00881916843 gen_loss 6.33991289\n",
            "disc_lossW -5.90659285 disc_lossU 0.00626398763 gen_loss 6.1336627\n",
            "disc_lossW -5.30485535 disc_lossU 0.00321574276 gen_loss 5.82060766\n",
            "disc_lossW -5.93237209 disc_lossU 0.00494967168 gen_loss 5.92992496\n",
            "disc_lossW -5.24304199 disc_lossU 0.00219649449 gen_loss 5.40616608\n",
            "disc_lossW -5.22733593 disc_lossU 0.00582791772 gen_loss 5.63121843\n",
            "disc_lossW -5.38892555 disc_lossU 0.00590269128 gen_loss 5.1366806\n",
            "disc_lossW -4.8173933 disc_lossU 0.00196542195 gen_loss 5.18150091\n",
            "disc_lossW -5.35959196 disc_lossU 0.00479513919 gen_loss 5.11622047\n",
            "disc_lossW -4.78988695 disc_lossU 0.00522485096 gen_loss 4.73657846\n",
            "disc_lossW -4.39704704 disc_lossU 0.00641666725 gen_loss 4.72461653\n",
            "disc_lossW -4.60185289 disc_lossU 0.00315931137 gen_loss 4.49320745\n",
            "disc_lossW -4.43013048 disc_lossU 0.00417418918 gen_loss 4.31875849\n",
            "disc_lossW -4.53562832 disc_lossU 0.00543487072 gen_loss 4.26203489\n",
            "disc_lossW -4.39162827 disc_lossU 0.00390735222 gen_loss 4.09744167\n",
            "disc_lossW -4.79780912 disc_lossU 0.00391697325 gen_loss 4.06635046\n",
            "disc_lossW -4.38622808 disc_lossU 0.00603458937 gen_loss 3.5853982\n",
            "disc_lossW -4.36219215 disc_lossU 0.00694323611 gen_loss 3.57013369\n",
            "disc_lossW -4.30635405 disc_lossU 0.00301624951 gen_loss 3.26089597\n",
            "disc_lossW -4.13295507 disc_lossU 0.00578675792 gen_loss 2.91134596\n",
            "disc_lossW -4.03213167 disc_lossU 0.00514744082 gen_loss 3.2137053\n",
            "disc_lossW -3.86632347 disc_lossU 0.0030103859 gen_loss 3.03121281\n",
            "disc_lossW -4.02216959 disc_lossU 0.00497463252 gen_loss 2.77188063\n",
            "disc_lossW -4.20994139 disc_lossU 0.0094806375 gen_loss 2.85063148\n",
            "disc_lossW -3.92679453 disc_lossU 0.00595978182 gen_loss 2.56625509\n",
            "disc_lossW -3.72138929 disc_lossU 0.00737496372 gen_loss 2.42824841\n",
            "disc_lossW -3.72316885 disc_lossU 0.00698931655 gen_loss 2.46493387\n",
            "disc_lossW -3.10635471 disc_lossU 0.00396377686 gen_loss 2.2175293\n",
            "disc_lossW -3.72596431 disc_lossU 0.0070470022 gen_loss 2.22424507\n",
            "disc_lossW -4.0787 disc_lossU 0.00760118803 gen_loss 2.48819375\n",
            "disc_lossW -3.68896914 disc_lossU 0.00470513757 gen_loss 2.40343809\n",
            "disc_lossW -3.92468452 disc_lossU 0.0129962713 gen_loss 2.26468277\n",
            "disc_lossW -3.18840027 disc_lossU 0.00503165135 gen_loss 2.27486086\n",
            "disc_lossW -3.09546542 disc_lossU 0.0026086783 gen_loss 2.30031109\n",
            "disc_lossW -3.84882259 disc_lossU 0.0071933018 gen_loss 2.3327632\n",
            "disc_lossW -3.39972711 disc_lossU 0.0063110427 gen_loss 2.16000056\n",
            "disc_lossW -3.40534425 disc_lossU 0.00894131605 gen_loss 1.87422061\n",
            "disc_lossW -3.0368557 disc_lossU 0.00349549274 gen_loss 1.78837931\n",
            "disc_lossW -3.18770504 disc_lossU 0.00664396817 gen_loss 1.8746469\n",
            "disc_lossW -3.21933436 disc_lossU 0.00733483 gen_loss 1.72054172\n",
            "disc_lossW -3.10403085 disc_lossU 0.00538930437 gen_loss 1.69185376\n",
            "disc_lossW -2.75960231 disc_lossU 0.00289240573 gen_loss 1.69809926\n",
            "disc_lossW -2.63245487 disc_lossU 0.00451444741 gen_loss 1.70284176\n",
            "disc_lossW -2.23599362 disc_lossU 0.00199090363 gen_loss 1.56057787\n",
            "disc_lossW -2.44175363 disc_lossU 0.00219709566 gen_loss 1.27470875\n",
            "disc_lossW -2.21731901 disc_lossU 0.00260971789 gen_loss 0.963231385\n",
            "disc_lossW -2.52673316 disc_lossU 0.00426875893 gen_loss 0.688782871\n",
            "disc_lossW -2.41153 disc_lossU 0.00602194946 gen_loss 0.572701037\n",
            "disc_lossW -2.5441916 disc_lossU 0.00317247957 gen_loss 0.426904\n",
            "disc_lossW -1.50925612 disc_lossU 0.000528052391 gen_loss 0.0660298318\n",
            "disc_lossW -2.4256103 disc_lossU 0.00177584088 gen_loss -0.255418748\n",
            "disc_lossW -2.45441365 disc_lossU 0.00391491828 gen_loss -0.628836632\n",
            "disc_lossW -2.38180876 disc_lossU 0.000918508507 gen_loss -0.741704702\n",
            "disc_lossW -1.97852635 disc_lossU 0.00182309956 gen_loss -1.16620612\n",
            "disc_lossW -1.91654408 disc_lossU 0.00119011803 gen_loss -1.50385237\n",
            "disc_lossW -2.09009504 disc_lossU 0.00207667053 gen_loss -2.14885592\n",
            "disc_lossW -2.34975767 disc_lossU 0.00238922751 gen_loss -2.21942592\n",
            "disc_lossW -2.82592511 disc_lossU 0.00183362165 gen_loss -2.26929951\n",
            "disc_lossW -2.46167159 disc_lossU 0.00205313065 gen_loss -2.73440599\n",
            "disc_lossW -2.10620737 disc_lossU 0.00104021677 gen_loss -3.24115777\n",
            "disc_lossW -2.6977489 disc_lossU 0.00215251744 gen_loss -3.38040805\n",
            "disc_lossW -2.64575243 disc_lossU 0.000605348556 gen_loss -3.60052896\n",
            "disc_lossW -2.4613781 disc_lossU 0.00211670203 gen_loss -4.29422188\n",
            "disc_lossW -2.37066031 disc_lossU 0.00151525473 gen_loss -4.58061409\n",
            "disc_lossW -1.75323951 disc_lossU 0.00305842748 gen_loss -4.8455739\n",
            "disc_lossW -1.21033931 disc_lossU 0.0028131851 gen_loss -5.46270323\n",
            "disc_lossW -1.61106062 disc_lossU 0.00235080207 gen_loss -5.35812283\n",
            "disc_lossW -1.31684589 disc_lossU 0.00218912424 gen_loss -5.2261405\n",
            "disc_lossW -1.71630836 disc_lossU 0.00470458483 gen_loss -5.06003046\n",
            "disc_lossW -1.23504293 disc_lossU 0.00397556508 gen_loss -5.35419607\n",
            "disc_lossW -0.982003272 disc_lossU 0.00316918199 gen_loss -5.2087245\n",
            "disc_lossW -1.97223866 disc_lossU 0.00425242865 gen_loss -4.62608957\n",
            "disc_lossW -1.8805306 disc_lossU 0.00396759715 gen_loss -4.50325632\n",
            "disc_lossW -1.73681927 disc_lossU 0.00273776776 gen_loss -4.35844374\n",
            "disc_lossW -1.79888928 disc_lossU 0.00230279821 gen_loss -4.13476801\n",
            "disc_lossW -1.5509218 disc_lossU 0.00539090578 gen_loss -3.7936213\n",
            "disc_lossW -1.48904085 disc_lossU 0.00221568905 gen_loss -3.51438928\n",
            "disc_lossW -1.8233093 disc_lossU 0.00441648718 gen_loss -3.26464128\n",
            "disc_lossW -1.32245445 disc_lossU 0.00312053668 gen_loss -3.1346066\n",
            "disc_lossW -1.83370757 disc_lossU 0.00195122324 gen_loss -2.83768749\n",
            "disc_lossW -1.9068718 disc_lossU 0.00422088 gen_loss -2.73462915\n",
            "disc_lossW -1.58695006 disc_lossU 0.00186924194 gen_loss -2.60570669\n",
            "disc_lossW -1.80337799 disc_lossU 0.00260529 gen_loss -2.27719188\n",
            "disc_lossW -1.43097353 disc_lossU 0.00300127501 gen_loss -2.29865837\n",
            "disc_lossW -2.01460361 disc_lossU 0.00351862097 gen_loss -2.03461313\n",
            "disc_lossW -2.0067451 disc_lossU 0.00201593782 gen_loss -1.93148613\n",
            "disc_lossW -1.50119174 disc_lossU 0.00276708836 gen_loss -2.13879275\n",
            "disc_lossW -1.93389308 disc_lossU 0.0035727974 gen_loss -1.89132142\n",
            "disc_lossW -2.34508562 disc_lossU 0.00551566668 gen_loss -1.87771869\n",
            "disc_lossW -2.07105064 disc_lossU 0.00482713338 gen_loss -1.88931406\n",
            "disc_lossW -1.80382299 disc_lossU 0.00243508 gen_loss -1.84146369\n",
            "disc_lossW -1.77043629 disc_lossU 0.00332597946 gen_loss -1.83201909\n",
            "disc_lossW -2.04330635 disc_lossU 0.0052780793 gen_loss -1.85992944\n",
            "disc_lossW -2.02743673 disc_lossU 0.00472151767 gen_loss -1.64817\n",
            "disc_lossW -2.2374897 disc_lossU 0.00660862261 gen_loss -1.46814346\n",
            "disc_lossW -1.76305139 disc_lossU 0.00129349565 gen_loss -1.47882736\n",
            "disc_lossW -2.28494215 disc_lossU 0.00357443164 gen_loss -1.61157429\n",
            "disc_lossW -1.91424704 disc_lossU 0.00225840183 gen_loss -1.70364285\n",
            "disc_lossW -1.51020265 disc_lossU 0.00132237421 gen_loss -1.84011006\n",
            "disc_lossW -1.49493933 disc_lossU 0.00298714498 gen_loss -2.01829696\n",
            "disc_lossW -1.71534479 disc_lossU 0.00194966083 gen_loss -1.98958647\n",
            "disc_lossW -1.9111352 disc_lossU 0.00589762535 gen_loss -1.9591769\n",
            "disc_lossW -1.54096127 disc_lossU 0.00143668172 gen_loss -2.22049427\n",
            "disc_lossW -2.04574 disc_lossU 0.00355351157 gen_loss -2.30236983\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-140-fb4f987b5b30>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx_train2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx_train2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_train2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-139-17e27b39feb0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, epochs)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Save the model every 15 epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-138-8b687621da10>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(images)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mgradients_of_discriminatorW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisc_tapeW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_lossW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminatorW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mgradients_of_discriminatorU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisc_tapeU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_lossU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminatorU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mdiscriminatorW_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients_of_discriminatorW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminatorW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mdiscriminatorU_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients_of_discriminatorU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminatorU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, skip_gradients_aggregation, **kwargs)\u001b[0m\n\u001b[1;32m   1228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_gradients_aggregation\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mexperimental_aggregate_gradients\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m             \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply_weight_decay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_weight_decay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m             \u001b[0miteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_apply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0;31m# Apply variable constraints after applying gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\u001b[0m in \u001b[0;36m_internal_apply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m   1258\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_apply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m         return tf.__internal__.distribute.interim.maybe_merge_call(\n\u001b[0m\u001b[1;32m   1261\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distributed_apply_gradients_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution_strategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/merge_call_interim.py\u001b[0m in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m   \"\"\"\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mstrategy_supports_no_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     return distribute_lib.get_replica_context().merge_call(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\u001b[0m in \u001b[0;36m_distributed_apply_gradients_fn\u001b[0;34m(self, distribution, grads_and_vars, **kwargs)\u001b[0m\n\u001b[1;32m   1350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m             distribution.extended.update(\n\u001b[0m\u001b[1;32m   1353\u001b[0m                 \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_grad_to_update_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2990\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m   2991\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2992\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2993\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2994\u001b[0m       return self._replica_ctx_update(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   4060\u001b[0m     \u001b[0;31m# The implementations of _update() and _update_non_slot() are identical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4061\u001b[0m     \u001b[0;31m# except _update() passes `var` as the first argument to `fn()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4062\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4064\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_with\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   4066\u001b[0m     \u001b[0;31m# once that value is used for something.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4067\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mUpdateContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4068\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4069\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4070\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\u001b[0m in \u001b[0;36mapply_grad_to_update_var\u001b[0;34m(var, grad)\u001b[0m\n\u001b[1;32m   1347\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_step_xla\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_var_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\u001b[0m in \u001b[0;36m_update_step\u001b[0;34m(self, gradient, variable)\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0;34mf\"`tf.keras.optimizers.legacy.{self.__class__.__name__}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             )\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/adam.py\u001b[0m in \u001b[0;36mupdate_step\u001b[0;34m(self, gradient, variable)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;31m# Dense gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m             \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m             \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36massign_add\u001b[0;34m(self, delta, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m    982\u001b[0m           name=name)\n\u001b[1;32m    983\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mread_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 984\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_add_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    985\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0massign_add_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_lazy_read\u001b[0;34m(self, op)\u001b[0m\n\u001b[1;32m    987\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_lazy_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m     \u001b[0mvariable_accessed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m     return _UnreadVariable(\n\u001b[0m\u001b[1;32m    990\u001b[0m         \u001b[0mhandle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mvariable_call\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvariable_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, handle, dtype, shape, in_graph_mode, parent_op, unique_id)\u001b[0m\n\u001b[1;32m   2344\u001b[0m             handle, dtype)\n\u001b[1;32m   2345\u001b[0m         \u001b[0m_maybe_set_handle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2346\u001b[0;31m     super(_UnreadVariable, self).__init__(\n\u001b[0m\u001b[1;32m   2347\u001b[0m         \u001b[0mhandle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2348\u001b[0m         \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, trainable, shape, dtype, handle, constraint, synchronization, aggregation, distribute_strategy, name, unique_id, handle_name, graph_element, initial_value, initializer_op, is_initialized_op, cached_value, save_slice_info, caching_device, in_graph_mode, validate_shape, **unused_kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \"\"\"\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0min_graph_mode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_graph_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;34m\"\"\"Helper for @contextmanager decorator.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0;31m# do not keep args and kwds alive unnecessarily\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;31m# they are only needed for recreation, which is not possible anymore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noise = tf.random.normal(shape=(1,100))\n",
        "test = generator.predict(noise)\n",
        "plt.imshow(test.squeeze(), cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "9vPp5AiDkrAF",
        "outputId": "42bbb343-281e-4a6f-dc55-a2545e8e6a2f"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 17ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.min(x_train2))"
      ],
      "metadata": {
        "id": "fhuRFc0ro5T_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}