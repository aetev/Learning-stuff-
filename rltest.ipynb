{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aetev/Learning-stuff-/blob/main/rltest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tf-agents[reverb]\n",
        "!pip install ta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKT3FPrkywkd",
        "outputId": "a1bd91a6-1601-4b1d-ce18-f0f5d657a152"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tf-agents[reverb] in /usr/local/lib/python3.10/dist-packages (0.16.0)\n",
            "Requirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (1.4.0)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (2.2.1)\n",
            "Requirement already satisfied: gin-config>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (0.5.0)\n",
            "Requirement already satisfied: gym<=0.23.0,>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (0.23.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (1.22.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (8.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (1.16.0)\n",
            "Requirement already satisfied: protobuf>=3.11.3 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (3.20.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (1.14.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (4.5.0)\n",
            "Requirement already satisfied: pygame==2.1.3 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (2.1.3)\n",
            "Requirement already satisfied: tensorflow-probability~=0.19.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (0.19.0)\n",
            "Requirement already satisfied: rlds in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (0.1.8)\n",
            "Requirement already satisfied: dm-reverb~=0.11.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (0.11.0)\n",
            "Requirement already satisfied: tensorflow~=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (2.12.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from dm-reverb~=0.11.0->tf-agents[reverb]) (0.1.8)\n",
            "Requirement already satisfied: portpicker in /usr/local/lib/python3.10/dist-packages (from dm-reverb~=0.11.0->tf-agents[reverb]) (1.3.9)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym<=0.23.0,>=0.17.0->tf-agents[reverb]) (0.0.8)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (0.4.10)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (16.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (23.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (67.7.2)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (2.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (0.32.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability~=0.19.0->tf-agents[reverb]) (4.4.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.12.0->tf-agents[reverb]) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow~=2.12.0->tf-agents[reverb]) (0.1.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow~=2.12.0->tf-agents[reverb]) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (3.2.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ta in /usr/local/lib/python3.10/dist-packages (0.10.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ta) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from ta) (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->ta) (1.16.0)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3108, in _dep_map\n",
            "    return self.__dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2901, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _DistInfoDistribution__dep_map\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 242, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 441, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 572, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n",
            "    dependencies = list(dist.iter_dependencies())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/metadata/pkg_resources.py\", line 216, in iter_dependencies\n",
            "    return self._dist.requires(extras)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2821, in requires\n",
            "    dm = self._dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3110, in _dep_map\n",
            "    self.__dep_map = self._compute_dependencies()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3120, in _compute_dependencies\n",
            "    reqs.extend(parse_requirements(req))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3173, in __init__\n",
            "    super(Requirement, self).__init__(requirement_string)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/requirements.py\", line 102, in __init__\n",
            "    req = REQUIREMENT.parseString(requirement_string)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 1131, in parse_string\n",
            "    loc, tokens = self._parse(instring, 0)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n",
            "    return e._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4959, in parseImpl\n",
            "    loc, tokens = self_expr._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 5226, in parseImpl\n",
            "    return super().parseImpl(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4375, in parseImpl\n",
            "    return self.expr._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3864, in parseImpl\n",
            "    loc, resultlist = self.exprs[0]._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n",
            "    return e._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4375, in parseImpl\n",
            "    return self.expr._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3864, in parseImpl\n",
            "    loc, resultlist = self.exprs[0]._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n",
            "    return e._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n",
            "    return e._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 821, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 2336, in parseImpl\n",
            "    def parseImpl(self, instring, loc, doActions=True):\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 79, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 206, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1524, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1612, in _log\n",
            "    fn, lno, func, sinfo = self.findCaller(stack_info, stacklevel)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1566, in findCaller\n",
            "    while hasattr(f, \"f_code\"):\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import pandas_ta as ta\n",
        "\n",
        "import reverb\n",
        "\n",
        "import tf_agents\n",
        "\n",
        "from tf_agents.environments import py_environment\n",
        "from tf_agents.environments import tf_environment\n",
        "from tf_agents.environments import tf_py_environment\n",
        "from tf_agents.environments import utils\n",
        "from tf_agents.specs import array_spec\n",
        "from tf_agents.environments import wrappers\n",
        "from tf_agents.environments import suite_gym\n",
        "from tf_agents.trajectories import time_step as ts\n",
        "\n",
        "from tf_agents.specs import array_spec\n",
        "from tf_agents.specs import tensor_spec\n",
        "from tf_agents.networks import network\n",
        "\n",
        "from tf_agents.policies import py_policy\n",
        "from tf_agents.policies import random_py_policy\n",
        "from tf_agents.policies import scripted_py_policy\n",
        "\n",
        "from tf_agents.policies import tf_policy\n",
        "from tf_agents.policies import random_tf_policy\n",
        "from tf_agents.policies import actor_policy\n",
        "from tf_agents.policies import q_policy\n",
        "from tf_agents.policies import greedy_policy\n",
        "\n",
        "from tf_agents.networks import sequential\n",
        "\n",
        "from tf_agents.agents.dqn import dqn_agent\n",
        "\n",
        "from tf_agents.trajectories import time_step as ts\n",
        "\n",
        "from tensorflow.keras import layers, models, Sequential\n",
        "\n",
        "from tensorflow.keras.layers import Flatten\n",
        "\n",
        "from tf_agents.networks import q_network\n",
        "from tf_agents.agents.dqn import dqn_agent\n",
        "from tf_agents.utils import common\n",
        "\n",
        "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
        "\n",
        "from tf_agents.trajectories import trajectory\n",
        "\n",
        "from tf_agents.drivers import dynamic_step_driver\n",
        "\n",
        "from tf_agents.agents.dqn import dqn_agent\n",
        "from tf_agents.drivers import py_driver\n",
        "from tf_agents.environments import suite_gym\n",
        "from tf_agents.environments import tf_py_environment\n",
        "from tf_agents.eval import metric_utils\n",
        "from tf_agents.metrics import tf_metrics\n",
        "from tf_agents.networks import sequential\n",
        "from tf_agents.policies import py_tf_eager_policy\n",
        "from tf_agents.policies import random_tf_policy\n",
        "from tf_agents.replay_buffers import reverb_replay_buffer\n",
        "from tf_agents.replay_buffers import reverb_utils\n",
        "from tf_agents.trajectories import trajectory\n",
        "from tf_agents.specs import tensor_spec\n",
        "from tf_agents.utils import common\n",
        "from tf_agents.drivers import dynamic_episode_driver"
      ],
      "metadata": {
        "id": "CrXHLuPapl3w"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_iterations = 50000 # @param {type:\"integer\"}\n",
        "\n",
        "initial_collect_steps = 100  # @param {type:\"integer\"}\n",
        "collect_steps_per_iteration =   1# @param {type:\"integer\"}\n",
        "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
        "\n",
        "batch_size = 64  # @param {type:\"integer\"}\n",
        "learning_rate = 1e-3  # @param {type:\"number\"}\n",
        "log_interval = 200  # @param {type:\"integer\"}\n",
        "\n",
        "num_eval_episodes = 5  # @param {type:\"integer\"}\n",
        "eval_interval = 5000  # @param {type:\"integer\"}"
      ],
      "metadata": {
        "id": "7w-GunLQ5ABu"
      },
      "execution_count": 279,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Uq0N14CpynD",
        "outputId": "37e0737a-16b8-469b-ab17-16b48eca3e10"
      },
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/eurusd_hour.csv')"
      ],
      "metadata": {
        "id": "pfzNpbHkp3qC"
      },
      "execution_count": 261,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bid_open = df['BO'].to_numpy()\n",
        "bid_close = df['BC'].to_numpy()\n",
        "rel_change = (bid_open - bid_close) * 1000\n",
        "input_df = pd.DataFrame()\n",
        "\n",
        "cumulative_arr = np.cumsum(rel_change)\n",
        "rsi = ta.rsi(df['BC'], 14)\n",
        "stdev = ta.stdev(df['BC'], 14)\n",
        "mad = ta.sma(df['BC'], 14) - df['BC']\n",
        "mad = pd.DataFrame(mad,columns=[\"mad\"])\n",
        "relc_df = pd.DataFrame(rel_change,columns=[\"rel_change\"])\n",
        "\n",
        "concatenated_df = pd.concat([rsi, stdev, mad,relc_df], axis=1)\n",
        "concatenated_df = concatenated_df.dropna(axis=0)\n",
        "\n",
        "changenp = concatenated_df.pop(\"rel_change\")\n",
        "changenp = changenp.to_numpy()\n",
        "changenp = changenp.astype('float32')\n",
        "\n",
        "concatenated_df = concatenated_df.to_numpy()\n",
        "concatenated_df = concatenated_df.astype('float32')\n",
        "\n",
        "print(changenp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0RypUj8qBnD",
        "outputId": "bd77bbf1-e9a8-4b00-a282-51fa3eb21d95"
      },
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2.53 -1.9   1.15 ...  0.39 -0.06 -0.15]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CardGameEnv(py_environment.PyEnvironment):\n",
        "    def __init__(self):\n",
        "        self._action_spec = array_spec.BoundedArraySpec(\n",
        "            shape=(), dtype=np.int32, minimum=0, maximum=2, name='action')\n",
        "        self._observation_spec = array_spec.BoundedArraySpec(\n",
        "            shape=(3,), dtype=np.float32, name='observation')\n",
        "        self._state = concatenated_df[0]\n",
        "        self._episode_ended = False\n",
        "        self._count = 0\n",
        "        self._Net_Profit = 0\n",
        "    def action_spec(self):\n",
        "        return self._action_spec\n",
        "\n",
        "    def observation_spec(self):\n",
        "        return self._observation_spec\n",
        "\n",
        "    def _reset(self):\n",
        "        self._Net_Profit = 0\n",
        "        self._count = 0\n",
        "        self._state = concatenated_df[0]\n",
        "        self._episode_ended = False\n",
        "        return ts.restart(np.array(self._state, dtype=np.float32))\n",
        "\n",
        "    def _step(self, action):\n",
        "        if self._episode_ended:\n",
        "            # The last action ended the episode. Ignore the current action and start\n",
        "            # a new episode.\n",
        "            return self.reset()\n",
        "        self._state = concatenated_df[self._count]\n",
        "        value = changenp[self._count]\n",
        "        # Make sure episodes don't go on forever.\n",
        "        if action == 1:\n",
        "            self._Net_Profit += value\n",
        "        elif action == 0:\n",
        "            self._Net_Profit -= value\n",
        "        else:\n",
        "            self._Net_Profit += 0\n",
        "\n",
        "\n",
        "        if self._count > 1000:\n",
        "            self._episode_ended = True\n",
        "        self._count += 1\n",
        "\n",
        "        if self._episode_ended:\n",
        "            reward = self._Net_Profit\n",
        "            return ts.termination(np.array(self._state, dtype=np.float32), reward=0.0)\n",
        "        else:\n",
        "            if (action == 1 and value > 0) or (action == 0 and value < 0):\n",
        "                reward = abs(value)\n",
        "            else:\n",
        "                reward = abs(value)*-1\n",
        "            return ts.transition(np.array(self._state, dtype=np.float32), reward=reward,discount=.5)"
      ],
      "metadata": {
        "id": "RZVaeHV1zJUU"
      },
      "execution_count": 301,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "environment = CardGameEnv()\n",
        "utils.validate_py_environment(environment, episodes=2)"
      ],
      "metadata": {
        "id": "ywoU4Vbg0Ikm"
      },
      "execution_count": 302,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_py_env = environment\n",
        "eval_py_env = environment"
      ],
      "metadata": {
        "id": "iHnHCIBwtWQr"
      },
      "execution_count": 303,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = tf_py_environment.TFPyEnvironment(environment)\n",
        "train_env = tf_py_environment.TFPyEnvironment(train_py_env)\n",
        "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)"
      ],
      "metadata": {
        "id": "qScxnevc6gaC"
      },
      "execution_count": 304,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fc_layer_params = (100, 50)\n",
        "action_tensor_spec = tensor_spec.from_spec(train_env.action_spec())\n",
        "num_actions = action_tensor_spec.maximum - action_tensor_spec.minimum + 1\n",
        "\n",
        "# Define a helper function to create Dense layers configured with the right\n",
        "# activation and kernel initializer.\n",
        "def dense_layer(num_units):\n",
        "  return tf.keras.layers.Dense(\n",
        "      num_units,\n",
        "      activation=tf.keras.activations.relu,\n",
        "      kernel_initializer=tf.keras.initializers.VarianceScaling(\n",
        "          scale=2.0, mode='fan_in', distribution='truncated_normal'))\n",
        "\n",
        "# QNetwork consists of a sequence of Dense layers followed by a dense layer\n",
        "# with `num_actions` units to generate one q_value per available action as\n",
        "# its output.\n",
        "dense_layers = [dense_layer(num_units) for num_units in fc_layer_params]\n",
        "q_values_layer = tf.keras.layers.Dense(\n",
        "    num_actions,\n",
        "    activation=None,\n",
        "    kernel_initializer=tf.keras.initializers.RandomUniform(\n",
        "        minval=-0.03, maxval=0.03),\n",
        "    bias_initializer=tf.keras.initializers.Constant(-0.2))\n",
        "q_net = sequential.Sequential(dense_layers + [q_values_layer])"
      ],
      "metadata": {
        "id": "cljkUmFmwTKG"
      },
      "execution_count": 305,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=.001)\n",
        "\n",
        "train_step_counter = tf.Variable(0)\n",
        "\n",
        "agent = dqn_agent.DqnAgent(\n",
        "    train_env.time_step_spec(),\n",
        "    train_env.action_spec(),\n",
        "    q_network=q_net,\n",
        "    optimizer=optimizer,\n",
        "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
        "    train_step_counter=train_step_counter)\n",
        "\n",
        "agent.initialize()"
      ],
      "metadata": {
        "id": "k0vvr_-M4Fq3"
      },
      "execution_count": 306,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_policy = agent.policy\n",
        "collect_policy = agent.collect_policy\n",
        "random_policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(),\n",
        "                                                train_env.action_spec())"
      ],
      "metadata": {
        "id": "OKPlqeMb4Vl3"
      },
      "execution_count": 307,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_step = train_env.reset()\n",
        "random_policy.action(time_step)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmuTtNu94oFm",
        "outputId": "db22e4cf-9b36-4834-f2be-9ea515bd1fad"
      },
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([2], dtype=int32)>, state=(), info=())"
            ]
          },
          "metadata": {},
          "execution_count": 308
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_avg_return(environment, policy, num_episodes=10):\n",
        "\n",
        "  total_return = 0.0\n",
        "  for _ in range(num_episodes):\n",
        "\n",
        "    time_step = environment.reset()\n",
        "    episode_return = 0.0\n",
        "\n",
        "    while not time_step.is_last():\n",
        "      action_step = policy.action(time_step)\n",
        "      time_step = environment.step(action_step.action)\n",
        "      episode_return += time_step.reward\n",
        "    total_return += episode_return\n",
        "\n",
        "  avg_return = total_return / num_episodes\n",
        "  return avg_return.numpy()[0]"
      ],
      "metadata": {
        "id": "tMXlJOyf40uf"
      },
      "execution_count": 309,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table_name = 'uniform_table'\n",
        "replay_buffer_signature = tensor_spec.from_spec(\n",
        "      agent.collect_data_spec)\n",
        "replay_buffer_signature = tensor_spec.add_outer_dim(\n",
        "    replay_buffer_signature)\n",
        "\n",
        "table = reverb.Table(\n",
        "    table_name,\n",
        "    max_size=replay_buffer_max_length,\n",
        "    sampler=reverb.selectors.Uniform(),\n",
        "    remover=reverb.selectors.Fifo(),\n",
        "    rate_limiter=reverb.rate_limiters.MinSize(1),\n",
        "    signature=replay_buffer_signature)\n",
        "\n",
        "reverb_server = reverb.Server([table])\n",
        "\n",
        "replay_buffer = reverb_replay_buffer.ReverbReplayBuffer(\n",
        "    agent.collect_data_spec,\n",
        "    table_name=table_name,\n",
        "    sequence_length=2,\n",
        "    local_server=reverb_server)\n",
        "\n",
        "rb_observer = reverb_utils.ReverbAddTrajectoryObserver(\n",
        "  replay_buffer.py_client,\n",
        "  table_name,\n",
        "  sequence_length=2)"
      ],
      "metadata": {
        "id": "45JoIL8A44S1"
      },
      "execution_count": 310,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.collect_data_spec\n",
        "#agent.collect_data_spec._fields"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8NYdAw_5oNO",
        "outputId": "c08851b3-c69a-4b1e-f921-ad1ecc7fdaba"
      },
      "execution_count": 311,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Trajectory(\n",
              "{'action': BoundedTensorSpec(shape=(), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array(2, dtype=int32)),\n",
              " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
              " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
              " 'observation': BoundedTensorSpec(shape=(3,), dtype=tf.float32, name='observation', minimum=array(-3.4028235e+38, dtype=float32), maximum=array(3.4028235e+38, dtype=float32)),\n",
              " 'policy_info': (),\n",
              " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
              " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
            ]
          },
          "metadata": {},
          "execution_count": 311
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "py_driver.PyDriver(\n",
        "    environment,\n",
        "    py_tf_eager_policy.PyTFEagerPolicy(\n",
        "      random_policy, use_tf_function=True),\n",
        "    [rb_observer],\n",
        "    max_steps=initial_collect_steps).run(train_py_env.reset())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwK2BJvB56Jq",
        "outputId": "4a8537de-e0fa-40d3-ea66-7090254882d5"
      },
      "execution_count": 312,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TimeStep(\n",
              " {'discount': array(0.5, dtype=float32),\n",
              "  'observation': array([2.0399723e+01, 5.4546255e-03, 7.0278570e-03], dtype=float32),\n",
              "  'reward': array(-0.5, dtype=float32),\n",
              "  'step_type': array(1, dtype=int32)}),\n",
              " ())"
            ]
          },
          "metadata": {},
          "execution_count": 312
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = replay_buffer.as_dataset(\n",
        "    num_parallel_calls=3,\n",
        "    sample_batch_size=batch_size,\n",
        "    num_steps=2).prefetch(3)\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rvwo7ORjCtE6",
        "outputId": "a72917a6-92e0-4d65-e769-c87e7d8c569c"
      },
      "execution_count": 313,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(Trajectory(\n",
              "{'action': TensorSpec(shape=(64, 2), dtype=tf.int32, name=None),\n",
              " 'discount': TensorSpec(shape=(64, 2), dtype=tf.float32, name=None),\n",
              " 'next_step_type': TensorSpec(shape=(64, 2), dtype=tf.int32, name=None),\n",
              " 'observation': TensorSpec(shape=(64, 2, 3), dtype=tf.float32, name=None),\n",
              " 'policy_info': (),\n",
              " 'reward': TensorSpec(shape=(64, 2), dtype=tf.float32, name=None),\n",
              " 'step_type': TensorSpec(shape=(64, 2), dtype=tf.int32, name=None)}), SampleInfo(key=TensorSpec(shape=(64, 2), dtype=tf.uint64, name=None), probability=TensorSpec(shape=(64, 2), dtype=tf.float64, name=None), table_size=TensorSpec(shape=(64, 2), dtype=tf.int64, name=None), priority=TensorSpec(shape=(64, 2), dtype=tf.float64, name=None), times_sampled=TensorSpec(shape=(64, 2), dtype=tf.int32, name=None)))>"
            ]
          },
          "metadata": {},
          "execution_count": 313
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iterator = iter(dataset)\n",
        "print(iterator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pk6hriyCy0b",
        "outputId": "ff907fbb-0027-44af-c3dc-89ed4de1dd9c"
      },
      "execution_count": 314,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7ff75fa735e0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
        "agent.train = common.function(agent.train)\n",
        "\n",
        "# Reset the train step.\n",
        "agent.train_step_counter.assign(0)\n",
        "\n",
        "# Evaluate the agent's policy once before training.\n",
        "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
        "returns = [avg_return]\n",
        "\n",
        "# Reset the environment.\n",
        "time_step = train_py_env.reset()\n",
        "\n",
        "# Create a driver to collect experience.\n",
        "collect_driver = py_driver.PyDriver(\n",
        "    environment,\n",
        "    py_tf_eager_policy.PyTFEagerPolicy(\n",
        "      agent.collect_policy, use_tf_function=True),\n",
        "    [rb_observer],\n",
        "    max_steps=collect_steps_per_iteration)"
      ],
      "metadata": {
        "id": "wnTu1HuFC3Af"
      },
      "execution_count": 315,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for _ in range(num_iterations):\n",
        "\n",
        "  # Collect a few steps and save to the replay buffer.\n",
        "  time_step, _ = collect_driver.run(time_step)\n",
        "\n",
        "  # Sample a batch of data from the buffer and update the agent's network.\n",
        "  experience, unused_info = next(iterator)\n",
        "  train_loss = agent.train(experience).loss\n",
        "\n",
        "  step = agent.train_step_counter.numpy()\n",
        "\n",
        "  if step % log_interval == 0:\n",
        "    print('step = {0}: loss = {1}'.format(step, train_loss))\n",
        "\n",
        "  if step % eval_interval == 0:\n",
        "    avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
        "    print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
        "    returns.append(avg_return)"
      ],
      "metadata": {
        "id": "ol65IXzMw6Pc",
        "outputId": "c99127e2-c921-41b5-c9c2-223f4a3ffc24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 200: loss = 3.0791420936584473\n",
            "step = 400: loss = 1.160176396369934\n",
            "step = 600: loss = 2.3029041290283203\n",
            "step = 800: loss = 2.5895116329193115\n",
            "step = 1000: loss = 1.1612972021102905\n",
            "step = 1200: loss = 2.1772994995117188\n",
            "step = 1400: loss = 2.749412775039673\n",
            "step = 1600: loss = 2.2867252826690674\n",
            "step = 1800: loss = 2.4964005947113037\n",
            "step = 2000: loss = 1.0819507837295532\n",
            "step = 2200: loss = 3.5516626834869385\n",
            "step = 2400: loss = 1.163866639137268\n",
            "step = 2600: loss = 1.696120023727417\n",
            "step = 2800: loss = 1.4413623809814453\n",
            "step = 3000: loss = 2.105550765991211\n",
            "step = 3200: loss = 1.3172398805618286\n",
            "step = 3400: loss = 2.3115787506103516\n",
            "step = 3600: loss = 1.7966012954711914\n",
            "step = 3800: loss = 2.0063867568969727\n",
            "step = 4000: loss = 2.176321506500244\n",
            "step = 4200: loss = 1.318572759628296\n",
            "step = 4400: loss = 3.09590744972229\n",
            "step = 4600: loss = 0.8567436933517456\n",
            "step = 4800: loss = 3.4898838996887207\n",
            "step = 5000: loss = 1.1134374141693115\n",
            "step = 5000: Average Return = 71.79997253417969\n",
            "step = 5200: loss = 1.7667531967163086\n",
            "step = 5400: loss = 2.587550640106201\n",
            "step = 5600: loss = 2.4058942794799805\n",
            "step = 5800: loss = 2.3284237384796143\n",
            "step = 6000: loss = 1.0180954933166504\n",
            "step = 6200: loss = 1.8390662670135498\n",
            "step = 6400: loss = 2.181203842163086\n",
            "step = 6600: loss = 1.5469255447387695\n",
            "step = 6800: loss = 1.1633083820343018\n",
            "step = 7000: loss = 2.0139434337615967\n",
            "step = 7200: loss = 1.2576614618301392\n",
            "step = 7400: loss = 3.4847607612609863\n",
            "step = 7600: loss = 2.271700143814087\n",
            "step = 7800: loss = 0.9467070698738098\n",
            "step = 8000: loss = 1.5253716707229614\n",
            "step = 8200: loss = 1.7372963428497314\n",
            "step = 8400: loss = 2.8098556995391846\n",
            "step = 8600: loss = 2.947047233581543\n",
            "step = 8800: loss = 1.279154658317566\n",
            "step = 9000: loss = 1.8681824207305908\n",
            "step = 9200: loss = 1.2141075134277344\n",
            "step = 9400: loss = 1.2926416397094727\n",
            "step = 9600: loss = 2.3796188831329346\n",
            "step = 9800: loss = 1.312602162361145\n",
            "step = 10000: loss = 1.0619430541992188\n",
            "step = 10000: Average Return = 71.79997253417969\n",
            "step = 10200: loss = 1.5303186178207397\n",
            "step = 10400: loss = 2.0259175300598145\n",
            "step = 10600: loss = 1.2144815921783447\n",
            "step = 10800: loss = 2.2319748401641846\n",
            "step = 11000: loss = 1.0936408042907715\n",
            "step = 11200: loss = 2.8115289211273193\n",
            "step = 11400: loss = 0.9362521171569824\n",
            "step = 11600: loss = 1.590754508972168\n",
            "step = 11800: loss = 1.7826350927352905\n",
            "step = 12000: loss = 2.3118515014648438\n",
            "step = 12200: loss = 1.767723560333252\n",
            "step = 12400: loss = 1.4909478425979614\n",
            "step = 12600: loss = 2.411421775817871\n",
            "step = 12800: loss = 1.9111905097961426\n",
            "step = 13000: loss = 1.788610816001892\n",
            "step = 13200: loss = 1.6231086254119873\n",
            "step = 13400: loss = 2.0536231994628906\n",
            "step = 13600: loss = 0.9598315954208374\n",
            "step = 13800: loss = 1.1938145160675049\n",
            "step = 14000: loss = 0.8151946067810059\n",
            "step = 14200: loss = 1.1819961071014404\n",
            "step = 14400: loss = 1.2748713493347168\n",
            "step = 14600: loss = 1.2056275606155396\n",
            "step = 14800: loss = 0.9426349401473999\n",
            "step = 15000: loss = 2.3916287422180176\n",
            "step = 15000: Average Return = 71.79997253417969\n",
            "step = 15200: loss = 1.3698194026947021\n",
            "step = 15400: loss = 1.1201438903808594\n",
            "step = 15600: loss = 2.174837589263916\n",
            "step = 15800: loss = 1.8367506265640259\n",
            "step = 16000: loss = 1.9514341354370117\n",
            "step = 16200: loss = 3.2864177227020264\n",
            "step = 16400: loss = 1.0596237182617188\n",
            "step = 16600: loss = 0.7066478729248047\n",
            "step = 16800: loss = 2.8752546310424805\n",
            "step = 17000: loss = 1.8108267784118652\n",
            "step = 17200: loss = 0.7059215307235718\n",
            "step = 17400: loss = 1.1959418058395386\n",
            "step = 17600: loss = 1.6080145835876465\n",
            "step = 17800: loss = 0.9205915927886963\n",
            "step = 18000: loss = 2.095737934112549\n",
            "step = 18200: loss = 1.6024081707000732\n",
            "step = 18400: loss = 1.299149513244629\n",
            "step = 18600: loss = 1.797741413116455\n",
            "step = 18800: loss = 1.0008000135421753\n",
            "step = 19000: loss = 1.3989250659942627\n",
            "step = 19200: loss = 1.9701168537139893\n",
            "step = 19400: loss = 0.8825188875198364\n",
            "step = 19600: loss = 1.469681978225708\n",
            "step = 19800: loss = 1.2384499311447144\n",
            "step = 20000: loss = 2.5118184089660645\n",
            "step = 20000: Average Return = 71.79997253417969\n",
            "step = 20200: loss = 1.3819360733032227\n",
            "step = 20400: loss = 1.1887009143829346\n",
            "step = 20600: loss = 1.0046041011810303\n",
            "step = 20800: loss = 2.0930848121643066\n",
            "step = 21000: loss = 2.2609670162200928\n",
            "step = 21200: loss = 1.1904544830322266\n",
            "step = 21400: loss = 1.255386233329773\n",
            "step = 21600: loss = 1.7700135707855225\n",
            "step = 21800: loss = 2.4727702140808105\n",
            "step = 22000: loss = 0.8829867839813232\n",
            "step = 22200: loss = 1.4594652652740479\n",
            "step = 22400: loss = 1.6719167232513428\n",
            "step = 22600: loss = 1.352693796157837\n",
            "step = 22800: loss = 2.433443307876587\n",
            "step = 23000: loss = 3.876849412918091\n",
            "step = 23200: loss = 1.4078667163848877\n",
            "step = 23400: loss = 1.4896183013916016\n",
            "step = 23600: loss = 0.891823947429657\n",
            "step = 23800: loss = 1.231398582458496\n",
            "step = 24000: loss = 3.283991813659668\n",
            "step = 24200: loss = 3.018768787384033\n",
            "step = 24400: loss = 2.369654655456543\n",
            "step = 24600: loss = 1.832169532775879\n",
            "step = 24800: loss = 1.7109733819961548\n",
            "step = 25000: loss = 1.6728541851043701\n",
            "step = 25000: Average Return = 71.79997253417969\n",
            "step = 25200: loss = 1.1102343797683716\n",
            "step = 25400: loss = 2.0951004028320312\n",
            "step = 25600: loss = 0.7162668108940125\n",
            "step = 25800: loss = 2.603513240814209\n",
            "step = 26000: loss = 0.9733723402023315\n",
            "step = 26200: loss = 2.197133779525757\n",
            "step = 26400: loss = 1.0689927339553833\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}