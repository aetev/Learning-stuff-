{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aetev/Learning-stuff-/blob/main/WGAN-GP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-g36b6KfZQeH",
        "outputId": "03984b48-fc78-4337-c88b-38309c0704f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.10/dist-packages (0.21.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (23.1)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (2.13.3)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.0.post2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.0)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.3.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.56.4)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch<1.7,>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.5)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.7.1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.5)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa) (23.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa) (2.27.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_addons\n",
        "#!pip install pydub\n",
        "!pip install librosa"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "kq4KEMDwylHv",
        "outputId": "c561625f-4dfd-4d33-d481-5f6d3be071ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UiZf7YAawUu",
        "outputId": "88fca3e1-8c6b-48e4-d860-5736e327b4fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow_addons as tfa\n",
        "import os\n",
        "from IPython.display import Audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KZA4iSHlpHeW"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "def downsample_array(arr, factor, axis):\n",
        "    return arr.take(np.arange(0, arr.shape[axis], factor), axis)\n",
        "\n",
        "def create_sliding_window(array, window_size, stride):\n",
        "    num_windows = (len(array) - window_size) // stride + 1\n",
        "    sliding_windows = np.lib.stride_tricks.sliding_window_view(array, (window_size,))\n",
        "\n",
        "    return sliding_windows[::stride]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PwZorlMxq2Rx"
      },
      "outputs": [],
      "source": [
        "reduction = 12\n",
        "wav_file = '/content/drive/MyDrive/bass samples/NBKoanbandstuff.wav'\n",
        "audio, sr = librosa.load(wav_file, sr=None)\n",
        "audio_dev = np.std(audio)\n",
        "audio = audio/audio_dev\n",
        "result_array = create_sliding_window(audio,44100,100)\n",
        "result_array = np.expand_dims(result_array, axis=2)\n",
        "result_array = downsample_array(result_array,reduction,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "ZIzKgHj1sIvX",
        "outputId": "cfb075e1-4037-450e-a12a-66f34e7f1c44"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ],
            "text/html": [
              "\n",
              "                <audio  controls=\"controls\" >\n",
              "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "\n",
        "\n",
        "audio_data = result_array[100].ravel()\n",
        "# Play the audio within the Jupyter Notebook\n",
        "Audio(data=audio_data, rate=sr/reduction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XZfCdyC7S_D",
        "outputId": "e5ac907d-e770-4c00-b945-b728bf89b812"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3675, 1)\n"
          ]
        }
      ],
      "source": [
        "#x_train = noise\n",
        "y_train = result_array\n",
        "print(y_train[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MUFnmA-82FDv"
      },
      "outputs": [],
      "source": [
        "class ResNetBlock(layers.Layer):\n",
        "    def __init__(self, filters,kernel_size=3, strides=1,dilation_rate=1):\n",
        "        super(ResNetBlock, self).__init__()\n",
        "        self.conv1 = layers.Conv1D(filters, kernel_size, strides=strides,dilation_rate=dilation_rate, padding='same')\n",
        "        self.bn1 = layers.BatchNormalization()\n",
        "        self.conv2 = layers.Conv1D(filters, kernel_size, padding='same')\n",
        "        self.bn2 = layers.BatchNormalization()\n",
        "\n",
        "        if strides != 1:\n",
        "            self.residual = layers.Conv1D(filters, 1, strides=strides)\n",
        "        else:\n",
        "            self.residual = lambda x: x\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.bn1(x, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x, training=training)\n",
        "\n",
        "        r = self.residual(inputs)\n",
        "\n",
        "        x += r\n",
        "        return tf.nn.relu(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNetBlockup(layers.Layer):\n",
        "    def __init__(self, filters, kernel_size=3, strides=1, dilation_rate=1):\n",
        "        super(ResNetBlockup, self).__init__()\n",
        "        self.conv1 = layers.Conv1DTranspose(filters, kernel_size, strides=strides, dilation_rate=dilation_rate, padding='same')\n",
        "        self.bn1 = layers.BatchNormalization()\n",
        "        self.conv2 = layers.Conv1DTranspose(filters, kernel_size, padding='same')\n",
        "        self.bn2 = layers.BatchNormalization()\n",
        "\n",
        "        if strides != 1:\n",
        "            self.residual = layers.Conv1DTranspose(filters, 1, strides=strides)\n",
        "        else:\n",
        "            self.residual = lambda x: x\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.bn1(x, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x, training=training)\n",
        "\n",
        "        r = self.residual(inputs)\n",
        "\n",
        "        x += r\n",
        "        return tf.nn.relu(x)"
      ],
      "metadata": {
        "id": "qBopciVs0FBC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gh2ORgUybdzt",
        "outputId": "b3c88a15-7f48-47f8-ba8e-13f2372a84aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None, 1)]         0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, None, 1)          4         \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " res_net_block (ResNetBlock)  (None, None, 64)         17280     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, None, 64)          0         \n",
            "                                                                 \n",
            " res_net_block_1 (ResNetBloc  (None, None, 64)         33408     \n",
            " k)                                                              \n",
            "                                                                 \n",
            " res_net_block_2 (ResNetBloc  (None, None, 64)         33408     \n",
            " k)                                                              \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, None, 64)          0         \n",
            "                                                                 \n",
            " res_net_block_3 (ResNetBloc  (None, None, 64)         33408     \n",
            " k)                                                              \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, None, 64)          0         \n",
            "                                                                 \n",
            " res_net_block_4 (ResNetBloc  (None, None, 64)         33408     \n",
            " k)                                                              \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, None, 64)          0         \n",
            "                                                                 \n",
            " res_net_block_5 (ResNetBloc  (None, None, 64)         33408     \n",
            " k)                                                              \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, None, 64)          0         \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 64)               0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 184,389\n",
            "Trainable params: 182,851\n",
            "Non-trainable params: 1,538\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def build_discriminator():\n",
        "    input_series = layers.Input(shape=(None,1))\n",
        "\n",
        "    x = layers.BatchNormalization()(input_series)\n",
        "\n",
        "    # Convolutional layers\n",
        "    x = ResNetBlock(64,4,1,1)(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = ResNetBlock(64,4,1,2)(x)\n",
        "\n",
        "\n",
        "    x = ResNetBlock(64,4,1,4)(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = ResNetBlock(64,4,1,8)(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = ResNetBlock(64,4,1,12)(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = ResNetBlock(64,4,1,24)(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "\n",
        "\n",
        "    # Global pooling\n",
        "    pooled_output = layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "    # Dense layer\n",
        "    dense_output = layers.Dense(64, activation='relu')(pooled_output)\n",
        "\n",
        "    # Dense layer\n",
        "    dense_output = layers.Dense(1, activation='linear')(pooled_output)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=input_series, outputs=dense_output)\n",
        "    return model\n",
        "\n",
        "discriminator = build_discriminator()\n",
        "discriminator.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q_-l7f8eC-i",
        "outputId": "999bad35-ec0a-4714-cc8e-10454b73b946"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, None, 1)]         0         \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, None, 1)          4         \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " res_net_block_6 (ResNetBloc  (None, None, 64)         17280     \n",
            " k)                                                              \n",
            "                                                                 \n",
            " res_net_block_7 (ResNetBloc  (None, None, 64)         33408     \n",
            " k)                                                              \n",
            "                                                                 \n",
            " res_net_block_8 (ResNetBloc  (None, None, 64)         33408     \n",
            " k)                                                              \n",
            "                                                                 \n",
            " res_net_block_9 (ResNetBloc  (None, None, 64)         33408     \n",
            " k)                                                              \n",
            "                                                                 \n",
            " res_net_block_10 (ResNetBlo  (None, None, 64)         33408     \n",
            " ck)                                                             \n",
            "                                                                 \n",
            " res_net_block_11 (ResNetBlo  (None, None, 64)         33408     \n",
            " ck)                                                             \n",
            "                                                                 \n",
            " conv1d_24 (Conv1D)          (None, None, 1)           65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 184,389\n",
            "Trainable params: 182,851\n",
            "Non-trainable params: 1,538\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def build_generator():\n",
        "    input_series = layers.Input(shape=(None,1))\n",
        "\n",
        "    x = layers.BatchNormalization()(input_series)\n",
        "\n",
        "    x = ResNetBlock(64,4,strides=1,dilation_rate=1)(x)\n",
        "\n",
        "    x = ResNetBlock(64,4,strides=1,dilation_rate=2)(x)\n",
        "\n",
        "    x = ResNetBlock(64,4,strides=1,dilation_rate=4)(x)\n",
        "\n",
        "    x = ResNetBlock(64,4,strides=1,dilation_rate=6)(x)\n",
        "\n",
        "    x = ResNetBlock(64,4,strides=1,dilation_rate=12)(x)\n",
        "\n",
        "    x = ResNetBlock(64,4,strides=1,dilation_rate=24)(x)\n",
        "\n",
        "    x = layers.Conv1D(1,1)(x)\n",
        "\n",
        "\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=input_series, outputs=x)\n",
        "    return model\n",
        "\n",
        "generator = build_generator()\n",
        "generator.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "aFFOfuDfbpD9"
      },
      "outputs": [],
      "source": [
        "# Compile models\n",
        "generator_optimizer = tf.keras.optimizers.Adam(0.0004)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(0.0004)\n",
        "\n",
        "#generator_optimizer = tf.keras.optimizers.experimental.SGD(1e-4)\n",
        "#discriminator_optimizer = tf.keras.optimizers.experimental.SGD(1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_penalty(real, fake, discriminator):\n",
        "    batch_size = real.shape[0]\n",
        "    epsilon = tf.random.uniform([batch_size, 1, 1], 0.0, 1.0)\n",
        "    interpolated = epsilon * real + (1 - epsilon) * fake\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(interpolated)\n",
        "        pred = discriminator(interpolated, training=True)\n",
        "\n",
        "    gradients = tape.gradient(pred, [interpolated])[0]\n",
        "    norm = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis=[1, 2]))\n",
        "    gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
        "\n",
        "    return gp"
      ],
      "metadata": {
        "id": "DpBCjazdvotg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "T3PtShxlbn9c"
      },
      "outputs": [],
      "source": [
        "def discriminator_loss(real_output, fake_output, gradient_penalty):\n",
        "    return tf.reduce_mean(fake_output) - tf.reduce_mean(real_output) + gradient_penalty\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return -tf.reduce_mean(fake_output)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clip_discriminator_weights(discriminator):\n",
        "    for l in discriminator.layers:\n",
        "        weights = l.get_weights()\n",
        "        weights = [tf.clip_by_value(w, -0.01, 0.01) for w in weights]\n",
        "        l.set_weights(weights)"
      ],
      "metadata": {
        "id": "a8RtXmHLZHWu"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "vAoSvqXLsQHq"
      },
      "outputs": [],
      "source": [
        "def print_img(generator_model):\n",
        "    # Generate and save sample images\n",
        "    noise = tf.random.normal([10, 100])\n",
        "    sampled_labels = tf.constant([[i % 10] for i in range(10)], dtype=tf.int32)\n",
        "    generated_images = generator_model.predict([noise, sampled_labels])\n",
        "    fig, axs = plt.subplots(1, 10, figsize=(10, 10))\n",
        "    for i in range(10):\n",
        "        axs[i].imshow(generated_images[i], cmap=\"gray\")\n",
        "        axs[i].axis(\"off\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAqGbZU0Z5yl",
        "outputId": "e0d5d88e-72db-48df-9c5f-d299dd423187"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "(1, 10000, 1)\n"
          ]
        }
      ],
      "source": [
        "noise = tf.random.normal(shape=(1,10000,1))\n",
        "\n",
        "test = generator.predict(noise)\n",
        "print(test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wp5mnkMVVgPV",
        "outputId": "bdd629cb-03a7-462b-ff31-3239aaa226cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "disc_loss 0.484564185 gen_loss -0.471388817\n",
            "disc_loss 0.148690462 gen_loss -0.726761937\n",
            "disc_loss -0.0074070096 gen_loss -0.952836692\n",
            "disc_loss -0.118462086 gen_loss -1.30932975\n",
            "disc_loss -0.0877890587 gen_loss -1.69683862\n",
            "disc_loss -0.184310317 gen_loss -1.97225308\n",
            "disc_loss -0.107052982 gen_loss -2.16077805\n",
            "disc_loss -0.23757112 gen_loss -2.29412985\n",
            "disc_loss -0.218940973 gen_loss -2.48343921\n",
            "disc_loss -0.493789554 gen_loss -2.4641366\n",
            "disc_loss -0.582155943 gen_loss -2.44511199\n",
            "disc_loss -0.801891923 gen_loss -2.36041\n",
            "disc_loss -1.10971749 gen_loss -2.2431705\n",
            "disc_loss -1.236238 gen_loss -2.38271976\n",
            "disc_loss -1.39141726 gen_loss -2.299299\n",
            "disc_loss -1.54254031 gen_loss -2.31800795\n",
            "disc_loss -1.71450353 gen_loss -2.30476499\n",
            "disc_loss -1.86034942 gen_loss -2.44656301\n",
            "disc_loss -2.02116513 gen_loss -2.44130826\n",
            "disc_loss -2.07382321 gen_loss -2.32121658\n",
            "disc_loss -2.10767174 gen_loss -2.63949013\n",
            "disc_loss -2.20857906 gen_loss -2.63222384\n",
            "disc_loss -2.14267349 gen_loss -2.80276537\n",
            "disc_loss -2.25339 gen_loss -2.95180082\n",
            "disc_loss -2.28730822 gen_loss -3.07453275\n",
            "disc_loss -2.21887565 gen_loss -3.30231476\n",
            "disc_loss -2.44420385 gen_loss -3.34084702\n",
            "disc_loss -2.2444644 gen_loss -3.44838452\n",
            "disc_loss -2.4647491 gen_loss -3.67155194\n",
            "disc_loss -2.34566736 gen_loss -3.47680044\n",
            "disc_loss -2.42484283 gen_loss -3.50228953\n",
            "disc_loss -2.4487493 gen_loss -3.45007849\n",
            "disc_loss -2.46769476 gen_loss -3.31676531\n",
            "disc_loss -2.42134571 gen_loss -3.1341188\n",
            "disc_loss -2.67502356 gen_loss -3.14602232\n",
            "disc_loss -2.40599632 gen_loss -2.77044678\n",
            "disc_loss -2.37314844 gen_loss -2.98517\n",
            "disc_loss -2.3438158 gen_loss -2.83790898\n",
            "disc_loss -2.22221422 gen_loss -2.71970773\n",
            "disc_loss -2.53071976 gen_loss -2.72006416\n",
            "disc_loss -2.70860767 gen_loss -1.9758774\n",
            "disc_loss -2.51198435 gen_loss -3.27975321\n",
            "disc_loss -2.72306871 gen_loss -1.04992318\n",
            "disc_loss -1.94059753 gen_loss -2.17134881\n",
            "disc_loss -1.41362596 gen_loss -6.07637167\n",
            "disc_loss -0.944677711 gen_loss -5.86408186\n",
            "disc_loss -1.0410701 gen_loss -4.65840435\n",
            "disc_loss -2.00494862 gen_loss -1.78886628\n",
            "disc_loss -1.41859007 gen_loss -1.0431329\n",
            "disc_loss -2.81606388 gen_loss -3.35481453\n",
            "disc_loss -2.85894 gen_loss -4.59162807\n",
            "disc_loss -3.36182451 gen_loss -2.35731983\n",
            "disc_loss -3.33392715 gen_loss -0.995020092\n",
            "disc_loss -3.49842954 gen_loss -2.04265285\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#@tf.function\n",
        "def train_step(target_audios):\n",
        "\n",
        "\n",
        "  for i in range(2):\n",
        "\n",
        "      # Get the shape of the target_audios tensor\n",
        "      shape = tf.shape(target_audios)\n",
        "\n",
        "\n",
        "      # Generate noise using tf.random.normal()\n",
        "      noise = tf.random.normal((shape))\n",
        "      generated_audio = generator(noise, training=True)\n",
        "      with tf.GradientTape() as disc_tape:\n",
        "\n",
        "          real_output = discriminator(target_audios, training=True)\n",
        "          fake_output = discriminator(generated_audio, training=True)\n",
        "          gp = gradient_penalty(target_audios, generated_audio, discriminator)\n",
        "          disc_loss = discriminator_loss(real_output, fake_output, gp)\n",
        "\n",
        "      gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "      discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "      #clip_discriminator_weights(discriminator)\n",
        "\n",
        "      if i ==0:\n",
        "          weights = discriminator.get_weights()\n",
        "\n",
        "\n",
        "  with tf.GradientTape() as gen_tape:\n",
        "    noise = tf.random.normal(shape=(target_audios.shape))\n",
        "    generated_audio = generator(noise, training=True)\n",
        "    fake_output = discriminator(generated_audio, training=True)\n",
        "    gen_loss = generator_loss(fake_output)\n",
        "\n",
        "  gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "  generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "  discriminator.set_weights(weights)\n",
        "\n",
        "\n",
        "  tf.print(\"disc_loss\",disc_loss,'gen_loss',gen_loss)\n",
        "\n",
        "\n",
        "def train(generator, discriminator\n",
        "          , epochs, batch_size):\n",
        "    for epoch in range(epochs):\n",
        "        for batch in range(len(y_train) // batch_size):\n",
        "            #images = x_train[batch * batch_size: (batch+1) * batch_size]\n",
        "            target_audios = y_train[batch * batch_size: (batch+1) * batch_size]\n",
        "\n",
        "            train_step(target_audios)\n",
        "\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "            test = generator.predict(noise)\n",
        "            audio_data = test.ravel()\n",
        "            # Play the audio within the Jupyter Notebook\n",
        "            Audio(data=audio_data, rate=sr/reduction)\n",
        "\n",
        "\n",
        "# Train the GAN\n",
        "EPOCHS = 2000000\n",
        "BATCH_SIZE = 10\n",
        "num_unrolling_steps = 20  # Set the desired number of unrolling steps\n",
        "train(generator, discriminator, EPOCHS, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrmv1Zri-jjc"
      },
      "outputs": [],
      "source": [
        "test = generator.predict(noise)\n",
        "audio_data = test.ravel()\n",
        "# Play the audio within the Jupyter Notebook\n",
        "Audio(data=audio_data, rate=sr/reduction)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Overview of Colaboratory Features",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}