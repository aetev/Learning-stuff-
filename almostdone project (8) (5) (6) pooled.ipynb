{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24a80f3e-976e-4464-b561-68a3d9692512",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "24a80f3e-976e-4464-b561-68a3d9692512",
        "outputId": "4891b29d-3353-4875-d9e6-8ea8d1fd96eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.8/site-packages (2.13.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (3.7.0)\n",
            "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.65.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (4.21.7)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from tensorflow) (65.4.1)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (4.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (2.13.1)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.23.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.32.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.28.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->tensorflow) (3.0.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (4.11.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (1.26.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2022.9.24)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (3.9.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d491617-afea-4020-ac0a-36d19e1c70af",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "6d491617-afea-4020-ac0a-36d19e1c70af",
        "outputId": "a5fd294b-be7d-41c6-802e-e469377715aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
            "Collecting scipy>=1.6.0 (from scikit-learn)\n",
            "  Downloading scipy-1.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
            "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading scikit_learn-1.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.1/41.1 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
            "Successfully installed joblib-1.4.2 scikit-learn-1.5.1 scipy-1.14.0 threadpoolctl-3.5.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n",
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "eabe3f39-6ba5-4165-9519-8c64882a1172",
      "metadata": {
        "id": "eabe3f39-6ba5-4165-9519-8c64882a1172"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Lambda, Layer, Input, Dense, Concatenate\n",
        "from tensorflow.keras.layers import Flatten, Conv1D, Reshape, GlobalAveragePooling2D,LSTM, BatchNormalization\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "atFR6pBI-Nyl",
        "outputId": "8b51ad6d-56b1-465d-e600-89d6a8e1f4f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "atFR6pBI-Nyl",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "fc4b4813-ac14-4b5b-a41a-8c14bf3ce7fc",
      "metadata": {
        "id": "fc4b4813-ac14-4b5b-a41a-8c14bf3ce7fc"
      },
      "outputs": [],
      "source": [
        "# Set TensorFlow to use only the CPU\n",
        "tf.config.set_visible_devices([], 'GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "9af48050-f477-4338-ac0b-f2e2792a808b",
      "metadata": {
        "id": "9af48050-f477-4338-ac0b-f2e2792a808b",
        "outputId": "c69a5be3-d66f-4f75-9b4f-461b02b9dbff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPUs detected.\n"
          ]
        }
      ],
      "source": [
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    print(\"GPUs detected:\")\n",
        "    for gpu in gpus:\n",
        "        print(f\"- {gpu}\")\n",
        "else:\n",
        "    print(\"No GPUs detected.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "28d61721-a19b-4a5c-8779-bb4fd674d04c",
      "metadata": {
        "id": "28d61721-a19b-4a5c-8779-bb4fd674d04c"
      },
      "outputs": [],
      "source": [
        "def get_csrf_token(session):\n",
        "    \"\"\"Fetches the CSRF token from the login page.\"\"\"\n",
        "    login_url = \"https://www.heartharena.com/login\"\n",
        "    response = session.get(login_url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    csrf_token = soup.find(\"input\", {\"name\": \"_csrf_token\"})[\"value\"]\n",
        "    return csrf_token\n",
        "\n",
        "def login(username, password):\n",
        "    \"\"\"Logs in to the HearthArena website.\"\"\"\n",
        "    url = \"https://www.heartharena.com/login_check\"\n",
        "    session = requests.Session()\n",
        "\n",
        "    # Get CSRF token\n",
        "    csrf_token = get_csrf_token(session)\n",
        "\n",
        "    # Prepare payload\n",
        "    payload = {\n",
        "        \"_username\": username,\n",
        "        \"_password\": password,\n",
        "        \"_csrf_token\": csrf_token,\n",
        "        \"_remember_me\": \"on\"  # Optional, based on whether you want to stay logged in\n",
        "    }\n",
        "\n",
        "    # Submit the login form\n",
        "    response = session.post(url, data=payload)\n",
        "\n",
        "    # Check if login was successful\n",
        "    if response.status_code == 200:\n",
        "        print(\"Login successful!\")\n",
        "    else:\n",
        "        print(\"Login failed.\")\n",
        "\n",
        "    return session\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "764ade49-5152-4383-bf42-ce4ee47d88eb",
      "metadata": {
        "id": "764ade49-5152-4383-bf42-ce4ee47d88eb"
      },
      "outputs": [],
      "source": [
        "def getRuns(arenaURL,session):\n",
        "    # Initialize an empty list to store the links\n",
        "    response = session.get(arenaURL)\n",
        "    links = []\n",
        "    end = BeautifulSoup(response.text, 'html')\n",
        "    runs = end.find('tbody')\n",
        "    # Find all 'a' tags within 'tr' elements and filter for those with 'href' attribute starting with '/arena-run/'\n",
        "    for link in runs.find_all('tr'):\n",
        "        anchor_tags = link.find_all('a')\n",
        "        for tag in anchor_tags:\n",
        "            href = tag.get('href')\n",
        "            if href and href.startswith('/arena-run/'):\n",
        "                links.append('https://www.heartharena.com'+href)\n",
        "    links = list(set(links))\n",
        "    return links"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "d44502dc-fc7f-4434-89b5-f5938582a6c1",
      "metadata": {
        "id": "d44502dc-fc7f-4434-89b5-f5938582a6c1"
      },
      "outputs": [],
      "source": [
        "def getStatsFromRun(url):\n",
        "    page = requests.get(url)\n",
        "    soup = BeautifulSoup(page.text, 'html')\n",
        "    nameExtract = soup.select('h1.class')[0].text.strip()\n",
        "    parts = nameExtract.split('/')\n",
        "\n",
        "    wins = 0\n",
        "    deckList = 0\n",
        "    champ = \"\"\n",
        "    hasData = len(soup.find_all('span', class_='wins'))\n",
        "    print(hasData)\n",
        "    if hasData == 1:\n",
        "        champ = parts[0].strip()\n",
        "        wins = int(soup.find_all('span', class_='wins')[0].text)\n",
        "        arenaDeck = soup.find_all('ul', class_=\"deckList\")[0]\n",
        "        cardNames = arenaDeck.find_all('span', class_='name')\n",
        "        cardAmount = arenaDeck.find_all('span', class_='quantity')\n",
        "        # Extract and convert numeric values and names\n",
        "        namesList = [(name.text.strip()) for name in cardNames]\n",
        "        amountList = [int(amount.text.strip()) for amount in cardAmount]\n",
        "\n",
        "        # Initialize an empty list to hold the repeated names\n",
        "        deckList = []\n",
        "\n",
        "        # Iterate through the names and amounts simultaneously\n",
        "        for name, amount in zip(namesList, amountList):\n",
        "            # Repeat the name 'amount' times and extend the repeated_names list\n",
        "            deckList.extend([name] * amount)\n",
        "\n",
        "    return champ, wins/12, deckList, hasData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "4a704ecb-12ea-4f1a-b1ba-6a23b7f6cc60",
      "metadata": {
        "id": "4a704ecb-12ea-4f1a-b1ba-6a23b7f6cc60"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "fc0d79aa-007a-4932-86cb-d21ba245395a",
      "metadata": {
        "id": "fc0d79aa-007a-4932-86cb-d21ba245395a"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Path to the JSON file\n",
        "#file_path = 'my_dict.json'\n",
        "file_path = 'drive/MyDrive/deck_pred/my_dict (1).json'\n",
        "# Load JSON file and convert it to a dictionary\n",
        "with open(file_path, 'r') as file:\n",
        "    encodedDeck = json.load(file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "e2f2e938-1376-4d49-bbc5-b5e63bb00414",
      "metadata": {
        "id": "e2f2e938-1376-4d49-bbc5-b5e63bb00414"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def encodeDeck(deck):\n",
        "    stats_list = []\n",
        "    desc_list = []\n",
        "    for name in deck:\n",
        "        if name in encodedDeck:\n",
        "            data = encodedDeck[name]\n",
        "            stats = data[0]\n",
        "            desc = data[1]\n",
        "            stats_list.append(stats)\n",
        "            desc_list.append(desc)\n",
        "\n",
        "\n",
        "    return [stats_list, desc_list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "4121a502-e035-4789-aa4d-b3c4bb391072",
      "metadata": {
        "id": "4121a502-e035-4789-aa4d-b3c4bb391072"
      },
      "outputs": [],
      "source": [
        "classes = ['Death Knight','Demon Hunter','Druid','Hunter','Mage','Paladin','Preist','Rogue','Shaman','Warlock','Warrior']\n",
        "\n",
        "# Initialize an empty dictionary to hold the encoding\n",
        "encoded_classes = {}\n",
        "\n",
        "# Iterate over each class name\n",
        "for name in classes:\n",
        "    # Check if the name is already in the dictionary\n",
        "    if name not in encoded_classes:\n",
        "        # If not, add it with a unique integer\n",
        "        encoded_classes[name] = len(encoded_classes) + 1\n",
        "\n",
        "\n",
        "\n",
        "def encodeClass(classData):\n",
        "    empty_list1 = [0] * len(encoded_classes)\n",
        "    empty_list2 = [0] * len(encoded_classes)\n",
        "    separated_names = classData.split(' + ')\n",
        "    empty_list1[encoded_classes.get(separated_names[0])-1]+=1\n",
        "    empty_list2[encoded_classes.get(separated_names[1])-1]+=1\n",
        "    return empty_list1+empty_list2\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "66192f17-7844-40c5-9625-f7980b3317ec",
      "metadata": {
        "scrolled": true,
        "id": "66192f17-7844-40c5-9625-f7980b3317ec"
      },
      "outputs": [],
      "source": [
        "def scrapeArenaData(linksList):\n",
        "    # Initialize an empty list to store the outputs\n",
        "    outputs = []\n",
        "\n",
        "        # Iterate through linksList\n",
        "    for link in linksList:\n",
        "        # Call getStatsFromRun for each link and append the result to outputs\n",
        "\n",
        "        output = getStatsFromRun(link)\n",
        "        outputs.append(output)\n",
        "\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "17a6bcda-5c4b-4afb-8cbe-94c9ba2c0ece",
      "metadata": {
        "scrolled": true,
        "id": "17a6bcda-5c4b-4afb-8cbe-94c9ba2c0ece"
      },
      "outputs": [],
      "source": [
        "def getTrainingData(arenaData):\n",
        "    winRateList = []\n",
        "    DeckList = []\n",
        "    classList = []\n",
        "    descList = []\n",
        "\n",
        "    for run in arenaData:\n",
        "        print(run[3])\n",
        "        if run[3] == 1:\n",
        "            classEncoded = encodeClass(run[0])\n",
        "\n",
        "            winRate = run[1]\n",
        "            deckEncoded = encodeDeck(run[2])\n",
        "\n",
        "            classList.append(classEncoded)\n",
        "            DeckList.append(deckEncoded[0])\n",
        "            descList.append(deckEncoded[1])\n",
        "            winRateList.append(winRate)\n",
        "\n",
        "\n",
        "    return [classList,DeckList,descList], winRateList\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "20062441-624e-4a53-950c-68d54dcc254d",
      "metadata": {
        "id": "20062441-624e-4a53-950c-68d54dcc254d",
        "outputId": "a9bf6058-235f-44da-e79e-55002e40acc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Login successful!\n"
          ]
        }
      ],
      "source": [
        "session = login(\"mcbrideslade@gmail.com\", \"U$!*3YFvJS2@Dvd4\")\n",
        "arenaUrl = 'https://www.heartharena.com/my-arenas'\n",
        "linksList = getRuns(arenaUrl,session)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "14df24d6-99ca-4c15-b00a-43a5eaeaf4d1",
      "metadata": {
        "id": "14df24d6-99ca-4c15-b00a-43a5eaeaf4d1",
        "outputId": "a1642643-5b1d-4284-f1df-3cd28f04db1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "arenaData = scrapeArenaData(linksList)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "84a0bee8-4e87-4b20-b319-e4b06f0d2d1d",
      "metadata": {
        "tags": [],
        "id": "84a0bee8-4e87-4b20-b319-e4b06f0d2d1d",
        "outputId": "3fecc8b4-91d1-4fb3-97a4-4fef38ac1b4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "trainingdata, winratedata = getTrainingData(arenaData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "981faa78-e55d-4e4a-b34d-886ecf3a0857",
      "metadata": {
        "id": "981faa78-e55d-4e4a-b34d-886ecf3a0857",
        "outputId": "59799759-f7fb-41d2-a8eb-99b0f12f47c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25, 22)\n",
            "(25, 30, 5)\n",
            "(25, 30, 30, 300)\n"
          ]
        }
      ],
      "source": [
        "inputdata1 = trainingdata[0]\n",
        "inputdata2 = trainingdata[1]\n",
        "inputdata3 = trainingdata[2]\n",
        "\n",
        "inputdatanp1 = np.array(inputdata1, dtype=np.float32)\n",
        "inputdatanp2 = np.array(inputdata2, dtype=np.float32)\n",
        "inputdatanp3 = np.array(inputdata3, dtype=np.float32)\n",
        "\n",
        "winratedatanp = np.array(winratedata, dtype=np.float32)\n",
        "print(inputdatanp1.shape)\n",
        "print(inputdatanp2.shape)\n",
        "print(inputdatanp3.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "4a535215-4221-45e2-9865-390fabfc6eb0",
      "metadata": {
        "id": "4a535215-4221-45e2-9865-390fabfc6eb0"
      },
      "outputs": [],
      "source": [
        "# Define the custom DeepSetLayer with Dropout\n",
        "class DeepSetLayer(layers.Layer):\n",
        "    def __init__(self, output_dim, phi_units=[12, 12], rho_units=[12, 12], dropout_rate=0.2):\n",
        "        super(DeepSetLayer, self).__init__()\n",
        "        self.phi_layers = []\n",
        "        for units in phi_units:\n",
        "            self.phi_layers.append(layers.Dense(units, activation='gelu'))\n",
        "            self.phi_layers.append(layers.Dropout(dropout_rate))\n",
        "\n",
        "        self.rho_layers = []\n",
        "        for units in rho_units:\n",
        "            self.rho_layers.append(layers.Dense(units, activation='gelu'))\n",
        "            self.rho_layers.append(layers.Dropout(dropout_rate))\n",
        "\n",
        "        self.output_layer = layers.Dense(output_dim)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        # Apply the transformation function Φ to each element\n",
        "        x = inputs\n",
        "        for layer in self.phi_layers:\n",
        "            if isinstance(layer, layers.Dropout):\n",
        "                x = layer(x, training=training)\n",
        "            else:\n",
        "                x = layer(x)\n",
        "\n",
        "        # Aggregate the transformed elements (averaging)\n",
        "        #x = tf.reduce_mean(x, axis=1)\n",
        "        x = tf.reduce_max(x, axis=1)\n",
        "\n",
        "        # Apply the aggregation function ρ\n",
        "        for layer in self.rho_layers:\n",
        "            if isinstance(layer, layers.Dropout):\n",
        "                x = layer(x, training=training)\n",
        "            else:\n",
        "                x = layer(x)\n",
        "\n",
        "        # Output layer\n",
        "        output = self.output_layer(x)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "a6b3cc29-53bc-4857-88ca-57ec035b1413",
      "metadata": {
        "id": "a6b3cc29-53bc-4857-88ca-57ec035b1413"
      },
      "outputs": [],
      "source": [
        "class MaskingLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(MaskingLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        super(MaskingLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        stats_input, words_input = inputs\n",
        "\n",
        "        # Generate a binary mask\n",
        "        batch_size = tf.shape(stats_input)[0]\n",
        "        num_cards = tf.shape(stats_input)[1]\n",
        "\n",
        "        # Randomly choose cards to mask\n",
        "        mask = tf.random.uniform(shape=(batch_size, num_cards), minval=0, maxval=2, dtype=tf.int32)\n",
        "\n",
        "        # Ensure the same mask is used for both inputs\n",
        "        mask = tf.cast(mask, dtype=tf.float32)\n",
        "\n",
        "        # Apply mask to both inputs\n",
        "        masked_stats = stats_input * mask[:, :, tf.newaxis]\n",
        "        masked_words = words_input * mask[:, :, tf.newaxis, tf.newaxis]\n",
        "\n",
        "        return masked_stats, masked_words\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2391022a-9051-4aea-b2bf-4b8beddd3fbd",
      "metadata": {
        "id": "2391022a-9051-4aea-b2bf-4b8beddd3fbd"
      },
      "outputs": [],
      "source": [
        "class CardProcessingLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(CardProcessingLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "\n",
        "        self.lstm_1 = tf.keras.layers.LSTM(20,return_sequences=False)\n",
        "\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "\n",
        "        lstm_1 = tf.map_fn(lambda x: self.lstm_1(x), inputs, dtype=tf.float32)\n",
        "\n",
        "        return lstm_1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " pooled_outputs = tf.reduce_mean(inputs, axis=1)"
      ],
      "metadata": {
        "id": "-snKw_EJ8VCT",
        "outputId": "a0ca8252-5c84-40d2-efeb-041fbd6056ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "id": "-snKw_EJ8VCT",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'inputs' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-a71d42793a9d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpooled_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomCardSampler(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(RandomCardSampler, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Determine the maximum number of samples allowed\n",
        "        num_cards = tf.shape(inputs)[0]\n",
        "        num_samples = tf.random.uniform(shape=(), minval=1, maxval=num_cards + 1, dtype=tf.int32)\n",
        "\n",
        "        # Generate unique indices for sampling\n",
        "        unique_indices = tf.range(num_samples)\n",
        "\n",
        "        # Randomly shuffle the unique indices\n",
        "        shuffled_indices = tf.random.shuffle(unique_indices)\n",
        "\n",
        "        # Gather the sampled cards using the shuffled indices\n",
        "        sampled_cards = tf.gather(inputs, shuffled_indices[:num_samples])\n",
        "\n",
        "        output = tf.reduce_mean(sampled_cards,axis=0)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "LnR66a4O9Vr8"
      },
      "id": "LnR66a4O9Vr8",
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_floats = tf.random.normal(shape=(30, 5))\n",
        "RandomCardSampler()(random_floats)"
      ],
      "metadata": {
        "id": "mX4UEeTPBSTq",
        "outputId": "839f5c3a-eac8-453d-a772-f59596c2685d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "mX4UEeTPBSTq",
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
              "array([ 0.50313574,  0.24969801, -0.05865746, -0.35291946,  0.38410187],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.random.uniform(shape=(30,), minval=1, maxval = 31, dtype=tf.int32))"
      ],
      "metadata": {
        "id": "FRgWfNhT92Fx",
        "outputId": "23deb8f6-bbaf-4b19-af13-4e513f8895fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "FRgWfNhT92Fx",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[ 3 11 20 26 25 19  5 16 27 25  9  2  3  2 22  6  5 16  8  6  5 11 30  3\n",
            " 17  4 12 16 23 10], shape=(30,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df4463af-d241-4d4f-b753-19227bdc143c",
      "metadata": {
        "tags": [],
        "id": "df4463af-d241-4d4f-b753-19227bdc143c"
      },
      "outputs": [],
      "source": [
        "# Define the inputs\n",
        "Class = tf.keras.Input(shape=(22,), name='Class')\n",
        "Deck_stats = tf.keras.Input(shape=(None, 5), name='Deck_stats')\n",
        "Card_desc = tf.keras.Input(shape=(None, 30, 300), name='Card_desc')\n",
        "\n",
        "Deck_stats_rem, Card_desc_rem = RandomCardSelector()([Deck_stats, Card_desc])\n",
        "\n",
        "\n",
        "\n",
        "# Apply 1D Convolution\n",
        "conv1d = CardProcessingLayer()(Card_desc_rem)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create the network for input_1\n",
        "x1 = Dropout(.5)(Class)\n",
        "\n",
        "x2 = DeepSetLayer(output_dim=20)(Deck_stats_rem)\n",
        "\n",
        "x2 = BatchNormalization()(x2)\n",
        "\n",
        "x3 = DeepSetLayer(output_dim=20)(conv1d)\n",
        "\n",
        "x3 = BatchNormalization()(x3)\n",
        "\n",
        "# Concatenate the outputs of the two networks\n",
        "concatenated = layers.concatenate([x1, x2, x3])\n",
        "\n",
        "x4 = layers.Dense(50, activation='gelu')(concatenated)\n",
        "\n",
        "x4 = Dropout(.2)(x4)\n",
        "\n",
        "# Add an output layer\n",
        "output = layers.Dense(1)(x4)\n",
        "\n",
        "# Define the model\n",
        "model = Model(inputs=[Class, Deck_stats, Card_desc], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mae', metrics=['mae'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5935b2f-02fc-4839-9b0f-82ad1a8090f7",
      "metadata": {
        "tags": [],
        "id": "c5935b2f-02fc-4839-9b0f-82ad1a8090f7"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "model.fit([inputdatanp1,inputdatanp2, inputdatanp3], winratedatanp, epochs=500, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d316ae4-7231-4d65-a2a3-72270c2a23f7",
      "metadata": {
        "id": "8d316ae4-7231-4d65-a2a3-72270c2a23f7"
      },
      "outputs": [],
      "source": [
        "prediction = model.predict([inputdatanp1,inputdatanp2, inputdatanp3])\n",
        "flattened_list = [item for sublist in prediction for item in sublist]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "656a8ebb-bbd8-4c15-bd58-95aa4dffc1e3",
      "metadata": {
        "id": "656a8ebb-bbd8-4c15-bd58-95aa4dffc1e3"
      },
      "outputs": [],
      "source": [
        "list1 = winratedatanp\n",
        "list2 = flattened_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0612ac49-1b25-46c3-b4f0-c6b3478aeee8",
      "metadata": {
        "id": "0612ac49-1b25-46c3-b4f0-c6b3478aeee8"
      },
      "outputs": [],
      "source": [
        "# Step 4: Combine arrays\n",
        "combined_array = np.vstack([list1, list2])\n",
        "# Extract the first row (keys)\n",
        "first_row = combined_array[0]\n",
        "\n",
        "# Sort the combined_array based on the first row\n",
        "sorted_combined_array = np.array(sorted(zip(first_row, *combined_array[1:]), key=lambda x: x[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7944bfcd-32f4-48fe-bcd2-13b5938537ed",
      "metadata": {
        "id": "7944bfcd-32f4-48fe-bcd2-13b5938537ed"
      },
      "outputs": [],
      "source": [
        "# Separate the two columns into lists\n",
        "column_1 = sorted_combined_array[:, 0].tolist()\n",
        "column_2 = sorted_combined_array[:, 1].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84b05316-e7f7-4c1e-a77d-c0fe31733322",
      "metadata": {
        "id": "84b05316-e7f7-4c1e-a77d-c0fe31733322"
      },
      "outputs": [],
      "source": [
        "# Plotting\n",
        "plt.plot(list1, label='List 1', color='blue')\n",
        "plt.plot(list2, label='List 2', color='red')\n",
        "\n",
        "# Customization\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Value')\n",
        "plt.title('Two Lists Overlay')\n",
        "plt.legend()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bcc0aaa-00f5-4443-b6a2-b3fa7958b84f",
      "metadata": {
        "id": "4bcc0aaa-00f5-4443-b6a2-b3fa7958b84f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0rc1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}