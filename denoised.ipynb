{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aetev/Learning-stuff-/blob/main/denoised.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "2370Z9yrygMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import detrend\n",
        "from scipy.signal import find_peaks,butter, filtfilt\n",
        "from scipy.fft import fft, ifft\n",
        "from scipy.optimize import curve_fit\n",
        "from scipy.fftpack import rfft, irfft, fftfreq, fft, rfftfreq\n",
        "import pywt\n",
        "from scipy.ndimage import gaussian_filter1d\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import Dense,Dropout, LSTM, Bidirectional\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "WdAXBSQwyyZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define functions**"
      ],
      "metadata": {
        "id": "zp8skWb9K0du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_largest_value_array(Data, columns):\n",
        "    # Subset the data frame to only include the specified columns\n",
        "    sub_data = Data[columns]\n",
        "\n",
        "    # Use the apply() function with the max() function to find the maximum value in each row of the subsetted data frame\n",
        "    max_values = sub_data.apply(max, axis=1)\n",
        "\n",
        "    # Create a new array that takes the maximum value from step 2 for each row of the original data frame\n",
        "    max_array = np.array(max_values)\n",
        "    \n",
        "    return max_array\n",
        "  \n",
        "def get_smallest_value_array(Data, columns):\n",
        "    # Subset the data frame to only include the specified columns\n",
        "    sub_data = Data[columns]\n",
        "\n",
        "    # Use the min() function to find the minimum value in each row of the subsetted data frame\n",
        "    min_values = sub_data.min(axis=1)\n",
        "\n",
        "    # Create a new array that takes the minimum value from step 2 for each row of the original data frame\n",
        "    min_array = np.array(min_values)\n",
        "    \n",
        "    return min_array\n",
        "\n",
        "def get_array_bo_greater_than_bc(Data):\n",
        "    # Use np.where() to compare the \"BO\" and \"BC\" columns, return 1 if \"BO\" < \"BC\", and 0 otherwise\n",
        "    result_array = np.where(Data[\"BO\"] < Data[\"BC\"], 1, 0)\n",
        "    \n",
        "    return result_array\n",
        "\n",
        "def rolling_std(data, window_size):\n",
        "    std_values = []\n",
        "    \n",
        "    for i in range(len(data) - window_size + 1):\n",
        "        window = data[i:i+window_size]\n",
        "        std = np.std(window)\n",
        "        std_values.append(std)\n",
        "    \n",
        "    return std_values\n",
        "\n",
        "def perform_fft(data, sample_rate):\n",
        "    n = len(data)\n",
        "    t = 1.0 / sample_rate\n",
        "\n",
        "    # Perform FFT\n",
        "    yf = np.fft.fft(data)\n",
        "    freq = np.fft.fftfreq(n, t)[:n//2]\n",
        "    amplitude = 2.0/n * np.abs(yf[:n//2])\n",
        "\n",
        "    return freq, amplitude\n",
        "\n",
        "def transform_scientific_notation(array):\n",
        "    transformed_array = []\n",
        "    \n",
        "    for notation in array:\n",
        "        value = float(notation)\n",
        "        transformed_array.append(value)\n",
        "    \n",
        "    return transformed_array\n",
        "\n",
        "def cycles_to_frequency(sample_rate, samples_per_cycle):\n",
        "    period = samples_per_cycle / sample_rate  # Calculate the period\n",
        "    frequency = 1 / period  # Calculate the frequency\n",
        "    return frequency\n",
        "\n",
        "def remove_cyclical_component(values, times, cycle):\n",
        "    stdev_array = ta.stdev(values, 100)\n",
        "    stdev_array = stdev_array.fillna(np.mean(stdev_array))\n",
        "    \n",
        "    scaled_val = values / stdev_array\n",
        "    \n",
        "    # Convert time to cyclical representation using sine and cosine\n",
        "    time_sin = np.sin(2 * np.pi * times / cycle)\n",
        "    time_cos = np.cos(2 * np.pi * times / cycle)\n",
        "    \n",
        "    # Combine sine and cosine representations\n",
        "    time_features = np.column_stack((time_sin, time_cos))\n",
        "    \n",
        "    # Fit a regression model to the detrended values using cyclical time features\n",
        "    regression_model = np.linalg.lstsq(time_features, scaled_val, rcond=None)[0]\n",
        "    cyclical_component = np.dot(time_features, regression_model)\n",
        "    \n",
        "    # Remove the scaled cyclical component from the original values\n",
        "    decycled_signal = (scaled_val - cyclical_component) * stdev_array\n",
        "    \n",
        "    return decycled_signal\n",
        "\n",
        "\n",
        "\n",
        "def sine_func(t, amplitude, frequency, phase):\n",
        "    return amplitude * np.sin(2 * np.pi * frequency * t + phase)\n",
        "\n",
        "def fit_sine_wave_to_data(t, data, initial_guess):\n",
        "    popt, pcov = curve_fit(sine_func, t, data, p0=initial_guess)\n",
        "    amplitude, frequency, phase = popt\n",
        "    fitted_data = sine_func(t, amplitude, frequency, phase)\n",
        "    return fitted_data\n",
        "\n",
        "def cumulative_sum(array):\n",
        "    cum_sum = []\n",
        "    current_sum = 0\n",
        "    for element in array:\n",
        "        current_sum += element\n",
        "        cum_sum.append(current_sum)\n",
        "    return cum_sum\n",
        "\n",
        "def fit_sin(tt, yy):\n",
        "    '''Fit sin to the input time sequence, and return fitting parameters \"amp\", \"omega\", \"phase\", \"offset\", \"freq\", \"period\" and \"fitfunc\"'''\n",
        "    tt = np.array(tt)\n",
        "    yy = np.array(yy)\n",
        "    ff = np.fft.fftfreq(len(tt), (tt[1]-tt[0]))   # assume uniform spacing\n",
        "    Fyy = abs(np.fft.fft(yy))\n",
        "    guess_freq = abs(ff[np.argmax(Fyy[1:])+1])   # excluding the zero frequency \"peak\", which is related to offset\n",
        "    guess_amp = np.std(yy) * 2.**0.5\n",
        "    guess_offset = np.mean(yy)\n",
        "    guess = np.array([guess_amp, 2.*np.pi*guess_freq, 0., guess_offset])\n",
        "\n",
        "    def sinfunc(t, A, w, p, c):  return A * np.sin(w*t + p) + c\n",
        "    popt, pcov = curve_fit(sinfunc, tt, yy, p0=guess)\n",
        "    A, w, p, c = popt\n",
        "    f = w/(2.*np.pi)\n",
        "    fitfunc = lambda t: A * np.sin(w*t + p) + c\n",
        "    return {\"amp\": A, \"omega\": w, \"phase\": p, \"offset\": c, \"freq\": f, \"period\": 1./f, \"fitfunc\": fitfunc, \"maxcov\": numpy.max(pcov), \"rawres\": (guess,popt,pcov)}\n",
        "\n",
        "def perform_dwt(array, wavelet='db1', level=1):\n",
        "    # Perform DWT\n",
        "    coeffs = pywt.wavedec(array, wavelet, level=level)\n",
        "\n",
        "    # Extract approximation coefficients\n",
        "    approx_coeffs = coeffs[0]\n",
        "\n",
        "    # Reconstruct smoothed result\n",
        "    smoothed_result = pywt.waverec([approx_coeffs], wavelet)\n",
        "\n",
        "    return smoothed_result\n",
        "\n",
        "def filter_signal(signal, threshold=1e8):\n",
        "    fourier = rfft(signal)\n",
        "    frequencies = rfftfreq(signal.size, d=20e-3/signal.size)\n",
        "    fourier[frequencies > threshold] = 0\n",
        "    return irfft(fourier)\n",
        "\n",
        "def highpass_filter(data, cutoff_freq, sampling_freq, order=5):\n",
        "    # Calculate the Nyquist frequency.\n",
        "    nyquist_freq = 0.5 * sampling_freq\n",
        "    # Calculate the normalized cutoff frequency.\n",
        "    normalized_cutoff_freq = cutoff_freq / nyquist_freq\n",
        "    # Create a Butterworth filter.\n",
        "    b, a = butter(order, normalized_cutoff_freq, btype='high', analog=False)\n",
        "    # Apply the filter to the data.\n",
        "    filtered_data = filtfilt(b, a, data)\n",
        "    # Return the filtered data.\n",
        "    return filtered_data\n",
        "\n",
        "# Function to convert DataFrame into sliding windows\n",
        "def create_sliding_window(data, window_size):\n",
        "    windows = []\n",
        "    for i in range(len(data) - window_size + 1):\n",
        "        window = data.iloc[i:i + window_size]\n",
        "        windows.append(window.values)\n",
        "    return np.array(windows)"
      ],
      "metadata": {
        "id": "DJ9JHcD-hbEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Data**"
      ],
      "metadata": {
        "id": "nyKLo8j9986v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Data = pd.read_csv('/content/drive/MyDrive/eurusd_hour.csv')\n",
        "Data['Date'] = pd.to_datetime(Data['Date'])\n",
        "Data['Time'] = pd.to_datetime(Data['Time'])\n",
        "print(Data)"
      ],
      "metadata": {
        "id": "vKH7LWXjy7fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extract time information**"
      ],
      "metadata": {
        "id": "3-TkkeCc9yWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Date = pd.DataFrame()\n",
        "\n",
        "Date['day'] = Data['Date'].dt.day\n",
        "Date['month'] = Data['Date'].dt.month\n",
        "Date['weekday'] = Data['Date'].dt.weekday\n",
        "Date['hour_of_day'] = Data['Time'].dt.hour\n",
        "\n",
        "print(Date)"
      ],
      "metadata": {
        "id": "EFY_8-AP0FAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Candle stick and other chart info**"
      ],
      "metadata": {
        "id": "4HqfCY9rTs9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Shape = pd.DataFrame()\n",
        "\n",
        "abs_diff_array = np.abs(Data['BH'] - Data['BL'])\n",
        "\n",
        "updown_array = get_array_bo_greater_than_bc(Data)\n",
        "\n",
        "max_array = get_largest_value_array(Data,[\"BC\", \"BO\"])\n",
        "min_array = get_smallest_value_array(Data,[\"BC\", \"BO\"])\n",
        "\n",
        "tp_array = (Data['BH']-min_array)/abs_diff_array\n",
        "bp_array = (Data['BH']-max_array)/abs_diff_array\n",
        "\n",
        "RelChange = Data['BC'] - Data['BO']\n",
        "\n",
        "Shape[\"Direction\"] = updown_array\n",
        "Shape[\"Bottom_Point\"] = bp_array\n",
        "Shape[\"Top_Point\"] = tp_array\n",
        "Shape[\"Relative_Change\"] = RelChange\n",
        "Shape[\"Size\"] = abs_diff_array\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(Shape)"
      ],
      "metadata": {
        "id": "0A0q2FME9xnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "times = Date[\"hour_of_day\"]\n",
        "values = Shape[\"Size\"]\n",
        "#values = Shape[\"Relative_Change\"]\n",
        "values = np.abs(values)\n",
        "\n",
        "plt.plot(values)\n",
        "\n",
        "plt.xlim(70000,80200)\n"
      ],
      "metadata": {
        "id": "Xf-sv9AWkdyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "values = np.array(values)\n",
        "values = values-np.mean(values)\n",
        "\n",
        "\n",
        "\n",
        "# Apply a high-pass filter to the data.\n",
        "cutoff_freq = 5  # Hz\n",
        "sampling_freq = 1000  # Hz\n",
        "filtered_data = highpass_filter(values, cutoff_freq, sampling_freq)\n",
        "\n",
        "\n",
        "threshold = .8\n",
        "y_fft = fft(filtered_data)\n",
        "y_soft = pywt.threshold(y_fft, value=threshold, mode='soft')\n",
        "y_denoised = ifft(y_soft)\n",
        "\n",
        "plt.plot(filtered_data)\n",
        "plt.plot(y_denoised)\n",
        "\n",
        "\n",
        "plt.xlim(60000,60300)\n",
        "plt.ylim(-.002,.005)\n"
      ],
      "metadata": {
        "id": "auXhGiLkyvYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = y_denoised\n",
        "\n",
        "sample_rate = len(data) # Assuming unit time interval between data points\n",
        "\n",
        "meanrmv = data - np.mean(data)\n",
        "\n",
        "freq, amplitude = perform_fft(data, sample_rate)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Plotting\n",
        "plt.plot(freq, amplitude)\n",
        "plt.xlabel('Frequency')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.title('FFT Analysis with Significant Spikes')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9wTWicb_48j8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "55usbQQU52x2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a MinMaxScaler object\n",
        "scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
        "pt = PowerTransformer(method='yeo-johnson')\n",
        "\n",
        "\n",
        "y_denoised = np.array(y_denoised)\n",
        "y_denoised = np.real(y_denoised).astype(float)\n",
        "\n",
        "y_denoised = pd.DataFrame(y_denoised, columns=[\"Target\"])\n",
        "new = pd.concat([Date, Shape, y_denoised], axis=1)\n",
        "new.dropna(axis=0,inplace=True) # Note that we need to call the method with parentheses to apply the changes\n",
        "new = new.reset_index(drop=True)\n",
        "\n",
        "\n",
        "# Scale all columns and assign them back to the DataFrame\n",
        "new[new.columns] = scaler.fit_transform(new[new.columns])\n",
        "\n",
        "target = new.pop(\"Target\")\n",
        "\n",
        "df_transformed = pt.fit_transform(new)\n",
        "\n",
        "# Convert the transformed data to a new DataFrame\n",
        "df_transformed = pd.DataFrame(df_transformed, columns=new.columns)\n",
        "\n",
        "\n",
        "print(target)\n",
        "print(df_transformed)"
      ],
      "metadata": {
        "id": "0qwc9CEMOlDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameters\n",
        "window_size = 4\n",
        "\n",
        "# Convert input and target DataFrames to sliding windows\n",
        "input_data = create_sliding_window(df_transformed, window_size)\n",
        "target_data = create_sliding_window(target, window_size)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(input_data, target_data, test_size=0.2,shuffle=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "LaKdVVzPEEpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg = l2(.01)\n",
        "\n",
        "# create a sequential model\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(LSTM(20,return_sequences=True))\n",
        "model.add(Dropout(.2))\n",
        "model.add(LSTM(20,return_sequences=True))\n",
        "model.add(Dropout(.2))\n",
        "model.add(LSTM(10,return_sequences=False))\n",
        "model.add(Dropout(.2))\n",
        "model.add(Dense(30,activation='gelu'))\n",
        "model.add(Dropout(.2))\n",
        "model.add(Dense(10,activation='gelu'))\n",
        "model.add(Dropout(.2))\n",
        "model.add(Dense(1,activation='linear'))\n",
        "\n",
        "# compile the model with categorical crossentropy loss and Adam optimizer\n",
        "model.compile(loss='mse', optimizer='adam',metrics='MeanAbsoluteError')"
      ],
      "metadata": {
        "id": "XYfn6rFQ3oX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train,y_train,epochs=10,batch_size=32,validation_data=(X_test,y_test))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])"
      ],
      "metadata": {
        "id": "7rgx0N_xJaHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "ZJJhshKqUJ0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#y_pred = y_pred.reset_index(drop=True)\n",
        "#y_test = y_test.reset_index(drop=True)\n",
        "# Plot the predictions\n",
        "test = np.array(y_test)\n",
        "df = pd.DataFrame(test)\n",
        "column_names = ['Column1', 'Column2', 'Column3', 'Column4']\n",
        "\n",
        "df.columns = column_names\n",
        "xstart = 2000\n",
        "xadd = 300\n",
        "\n",
        "plt.plot(df[\"Column4\"])\n",
        "plt.plot(y_pred)\n",
        "plt.xlim(xstart,xstart+xadd)\n",
        "plt.show()\n",
        "print(df)"
      ],
      "metadata": {
        "id": "fTUDbabLVYQk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}