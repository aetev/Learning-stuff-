{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-UiZf7YAawUu"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yn4y2vCkggU1"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load MNIST dataset\n",
    "(x_train, y_train), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize the images to [-1, 1]\n",
    "x_train = (x_train.astype(\"float32\") - 127.5) / 127.5\n",
    "#y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "\n",
    "print(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L8aOQOKGba2s",
    "outputId": "fab0013b-7f54-4761-c7cd-b2a2562e222f"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def build_generator():\n",
    "    noise_shape = (28,28,1)\n",
    "    noise = layers.Input(shape=noise_shape)\n",
    "    input_digit = layers.Input(shape=(1,), dtype=\"int32\")\n",
    "    digit_embedding = layers.Embedding(10, 28*28)(input_digit)\n",
    "    digit_embedding = layers.Reshape((28, 28, 1))(digit_embedding)\n",
    "\n",
    "\n",
    "    #noise = layers.Reshape((28, 28, 1))(noise)\n",
    "\n",
    "    x = layers.Concatenate()([noise, digit_embedding])\n",
    "    skip = layers.Conv2D(256, kernel_size=2, strides=2, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(256, kernel_size=2, strides=2, padding='same', activation='relu')(skip)\n",
    "    x = layers.Conv2DTranspose(64, 5, strides=2, padding=\"same\", activation=\"relu\")(x)\n",
    "    con = layers.Concatenate()([x, skip])\n",
    "    x = layers.Conv2DTranspose(1, 5, strides=2, padding=\"same\", activation=\"tanh\")(con)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=[noise, input_digit], outputs=x)\n",
    "    return model\n",
    "\n",
    "generator = build_generator()\n",
    "generator.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gh2ORgUybdzt",
    "outputId": "0c729822-30bf-4e8a-fbf8-4d598ba2fc27"
   },
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    input_image = layers.Input(shape=(28, 28, 1))\n",
    "    digit_input = layers.Input(shape=(1,), dtype=\"int32\")\n",
    "    #digit_embedding = layers.Embedding(10,10)(digit_input)\n",
    "    #digit_embedding = layers.Flatten()(digit_embedding)\n",
    "\n",
    "    digit_embedding_2d = layers.Embedding(10, 28*28)(digit_input)\n",
    "    digit_emb_skip = layers.Embedding(10, 10)(digit_input)\n",
    "    digit_embedding_2d = layers.Reshape((28, 28, 1))(digit_embedding_2d)\n",
    "\n",
    "    merged_input = layers.Concatenate()([input_image, digit_embedding_2d])\n",
    "\n",
    "    x = layers.Conv2D(12, 5, strides=2, padding=\"same\", activation=\"relu\")(merged_input)\n",
    "    x = Dropout(0.3)(x)  # Add dropout layer with a dropout rate of 0.3\n",
    "    x = layers.Conv2D(32, 5, strides=2, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)  # Add dropout layer with a dropout rate of 0.3\n",
    "    x = layers.Conv2D(64, 5, strides=2, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)  # Add dropout layer with a dropout rate of 0.3\n",
    "    x = layers.Flatten()(x)\n",
    "\n",
    "    x = layers.Dense(20)(x)\n",
    "    x = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=[input_image, digit_input], outputs=x)\n",
    "    return model\n",
    "\n",
    "discriminator = build_discriminator()\n",
    "discriminator.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AJslCMmLbhHU",
    "outputId": "f96d86f8-be40-44b3-bf09-a67005eccb57"
   },
   "outputs": [],
   "source": [
    "# Define the GAN model\n",
    "def build_gan(generator, discriminator):\n",
    "    noise_shape = (28,28,1)\n",
    "    digit_shape = (1,)\n",
    "    noise = layers.Input(shape=noise_shape)\n",
    "    digit = layers.Input(shape=digit_shape)\n",
    "\n",
    "    generated_image = generator([noise, digit])\n",
    "\n",
    "    discriminator_output = discriminator([generated_image, digit])\n",
    "    model = tf.keras.models.Model(inputs=[noise, digit], outputs=discriminator_output)\n",
    "    return model\n",
    "\n",
    "gan = build_gan(generator, discriminator)\n",
    "gan.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aFFOfuDfbpD9"
   },
   "outputs": [],
   "source": [
    "# Compile models\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T3PtShxlbn9c"
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = tf.keras.losses.BinaryCrossentropy()(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = tf.keras.losses.BinaryCrossentropy()(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return tf.keras.losses.BinaryCrossentropy()(tf.ones_like(fake_output), fake_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 616
    },
    "id": "_fzE9nBnbuk0",
    "outputId": "acacb416-4d57-4dbc-e144-950539b858ae",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s\n",
    "\n",
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    batch_size = images.shape[0]\n",
    "    noise = tf.random.normal([batch_size, 28,28,1])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator([noise, labels], training=True)\n",
    "\n",
    "        real_output = discriminator([images, labels], training=True)\n",
    "        fake_output = discriminator([generated_images, labels], training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "# Training loop\n",
    "def train(generator, discriminator, gan, epochs, batch_size):\n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(len(x_train) // batch_size):\n",
    "            images = x_train[batch * batch_size: (batch+1) * batch_size]\n",
    "            labels = y_train[batch * batch_size: (batch+1) * batch_size]\n",
    "\n",
    "            train_step(images, labels)\n",
    "\n",
    "        # Output training progress\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "            # Generate and save sample images\n",
    "            noise = tf.random.normal([10, 28,28,1])\n",
    "            sampled_labels = tf.constant([[i % 10] for i in range(10)], dtype=tf.int32)\n",
    "            generated_images = generator.predict([noise, sampled_labels])\n",
    "            generated_images = (generated_images * 0.5) + 0.5  # Rescale images from [-1, 1] to [0, 1]\n",
    "            fig, axs = plt.subplots(1, 10, figsize=(10, 10))\n",
    "            for i in range(10):\n",
    "                axs[i].imshow(generated_images[i], cmap=\"gray\")\n",
    "                axs[i].axis(\"off\")\n",
    "            plt.show()\n",
    "\n",
    "# Train the GAN\n",
    "EPOCHS = 20000\n",
    "BATCH_SIZE = 64\n",
    "train(generator, discriminator, gan, EPOCHS, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Overview of Colaboratory Features",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
