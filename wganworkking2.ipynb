{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aetev/Learning-stuff-/blob/main/wganworkking2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xI7rEeMMgDQI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qgyl_WtbgO5k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62f90ccb-f9e5-463a-836c-91ddaeb1dddc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 4s 0us/step\n"
          ]
        }
      ],
      "source": [
        "#(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "kik7wQ1qgOV-"
      },
      "outputs": [],
      "source": [
        "def make_generator_model():\n",
        "\n",
        "    input_noise = layers.Input(shape=(100,))\n",
        "    input_digit = layers.Input(shape=(1,))\n",
        "    digit = layers.Embedding(10, 10)(input_digit)\n",
        "    digit = layers.Flatten()(digit)\n",
        "\n",
        "    x = layers.concatenate([input_noise, digit])\n",
        "\n",
        "    x = layers.Dense(8*8*64,activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.Reshape((8, 8, 64))(x)\n",
        "\n",
        "\n",
        "    x = layers.Conv2DTranspose(64,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv2DTranspose(64,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv2D(3,3,1,padding='same',activation='sigmoid')(x)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=(input_noise,input_digit), outputs=x)\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "\n",
        "def make_discriminator_model():\n",
        "    input_img = layers.Input(shape=(32,32,3))\n",
        "    input_digit = layers.Input(shape=(1,))\n",
        "    digit = layers.Embedding(10, 5)(input_digit)\n",
        "    digit = layers.Flatten()(digit)\n",
        "\n",
        "    x = layers.Conv2D(64, 5, 2, padding='same', activation='LeakyReLU', kernel_regularizer=tf.keras.regularizers.l2(0.01))(input_img)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv2D(64, 3, 2, padding='same', activation='LeakyReLU', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv2D(64, 3, 2, padding='same', activation='LeakyReLU', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv2D(64, 3, 2, padding='same', activation='LeakyReLU', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "    x = layers.Flatten()(x)\n",
        "\n",
        "    x = layers.concatenate([x, digit])\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Dense(128, activation='LeakyReLU', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    dense_output = layers.Dense(64, activation='LeakyReLU', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    dense_output = layers.Dense(1, activation=None, kernel_regularizer=tf.keras.regularizers.l2(0.01))(dense_output)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=(input_img, input_digit), outputs=dense_output)\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "qzdSabqdVu_H"
      },
      "outputs": [],
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lS0DF8rjhHdY",
        "outputId": "1ce80bbd-8e7e-4b51-ac15-659b90de617e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_12 (InputLayer)       [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " embedding_5 (Embedding)     (None, 1, 10)                100       ['input_12[0][0]']            \n",
            "                                                                                                  \n",
            " input_11 (InputLayer)       [(None, 100)]                0         []                            \n",
            "                                                                                                  \n",
            " flatten_8 (Flatten)         (None, 10)                   0         ['embedding_5[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate  (None, 110)                  0         ['input_11[0][0]',            \n",
            " )                                                                   'flatten_8[0][0]']           \n",
            "                                                                                                  \n",
            " dense_11 (Dense)            (None, 4096)                 454656    ['concatenate_5[0][0]']       \n",
            "                                                                                                  \n",
            " reshape_2 (Reshape)         (None, 8, 8, 64)             0         ['dense_11[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_transpose_4 (Conv2D  (None, 16, 16, 64)           36928     ['reshape_2[0][0]']           \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " batch_normalization_22 (Ba  (None, 16, 16, 64)           256       ['conv2d_transpose_4[0][0]']  \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_5 (Conv2D  (None, 32, 32, 64)           36928     ['batch_normalization_22[0][0]\n",
            " Transpose)                                                         ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_23 (Ba  (None, 32, 32, 64)           256       ['conv2d_transpose_5[0][0]']  \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 32, 32, 3)            1731      ['batch_normalization_23[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 530855 (2.03 MB)\n",
            "Trainable params: 530599 (2.02 MB)\n",
            "Non-trainable params: 256 (1.00 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "generator = make_generator_model()\n",
        "generator_optimizer = tf.keras.optimizers.Adam(0.0004)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "GJxNxRSHkWfl"
      },
      "outputs": [],
      "source": [
        "discriminatorW = make_discriminator_model()\n",
        "discriminatorW_optimizer = tf.keras.optimizers.Adam(0.0004)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "6cDVGo73jfqZ"
      },
      "outputs": [],
      "source": [
        "discriminatorU = make_discriminator_model()\n",
        "discriminatorU_optimizer = tf.keras.optimizers.Adam(0.0004)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "DYQpIZyEgSlN"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "@tf.function\n",
        "def discriminator_lossW(real_output, fake_output):\n",
        "    real_loss = tf.reduce_mean(real_output)\n",
        "    fake_loss = tf.reduce_mean(fake_output)\n",
        "    total_loss = fake_loss - real_loss\n",
        "    return total_loss\n",
        "\n",
        "@tf.function\n",
        "def generator_lossW(fake_output):\n",
        "    return -tf.reduce_mean(fake_output)\n",
        "\n",
        "@tf.function\n",
        "def gradient_penalty(real_images, fake_images,digits):\n",
        "    alpha = tf.random.uniform([BATCH_SIZE, 1, 1, 1], 0., 1.)\n",
        "    real_images, fake_images = tf.cast(real_images, tf.float32), tf.cast(fake_images, tf.float32)\n",
        "    interpolated_images = alpha * real_images + ((1 - alpha) * fake_images)\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(interpolated_images)\n",
        "        pred = discriminatorW((interpolated_images,digits), training=True)\n",
        "    gradients = tape.gradient(pred, [interpolated_images])[0]\n",
        "    norm = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis=[1, 2, 3]))\n",
        "    gp = tf.reduce_mean((norm - 1.)**2)\n",
        "    return gp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def r1_regularizer(real_images,digit):\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(real_images)\n",
        "        output = discriminatorU((real_images,digit))\n",
        "    gradients = tape.gradient(output, real_images)\n",
        "    r1_reg = tf.reduce_sum(tf.square(gradients))\n",
        "    return r1_reg"
      ],
      "metadata": {
        "id": "YKXS0vax1Kz5"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "4rgSqI2sf1sT"
      },
      "outputs": [],
      "source": [
        "\n",
        "@tf.function\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "lambda_r1 = .01\n",
        "@tf.function\n",
        "def discriminator_loss(real_output, fake_output, real_images, digit):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    r1_reg = r1_regularizer(real_images,digit)\n",
        "    real_loss = tf.cast(real_loss, tf.float32)\n",
        "    fake_loss = tf.cast(fake_loss, tf.float32)\n",
        "    r1_reg = tf.cast(r1_reg, tf.float32)\n",
        "    total_loss = real_loss + fake_loss + lambda_r1 * r1_reg\n",
        "    total_loss = real_loss + fake_loss + lambda_r1 * r1_reg  # Add the regularization term\n",
        "    return total_loss\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def generator_loss(fake_output):\n",
        "    return -tf.reduce_mean(fake_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilj-woz7fSum"
      },
      "outputs": [],
      "source": [
        "NOISE_DIM = 100\n",
        "\n",
        "@tf.function\n",
        "def train_step(real_images,digits):\n",
        "    with tf.GradientTape() as disc_tape, tf.GradientTape() as gen_tape:\n",
        "        # Generate random noise\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "\n",
        "        # Generate fake images with the generator\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        # Discriminator loss calculation\n",
        "        real_output = discriminatorU((real_images,digits), training=True)\n",
        "        fake_output = discriminatorU((generated_images,digits), training=True)\n",
        "        d_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "        # Generator loss calculation\n",
        "        g_loss = generator_loss(fake_output)\n",
        "\n",
        "    # Update generator and discriminator variables\n",
        "    gradients_of_discriminator = disc_tape.gradient(d_loss, discriminatorU.trainable_variables)\n",
        "    gradients_of_generator = gen_tape.gradient(g_loss, generator.trainable_variables)\n",
        "    discriminatorU_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminatorU.trainable_variables))\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    tf.print(\"disc_loss\",d_loss,'gen_loss',g_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "8AuOxPdvp1hu"
      },
      "outputs": [],
      "source": [
        "NOISE_DIM = 100\n",
        "threshold = 0.5\n",
        "#@tf.function\n",
        "def train_step(real_images,digits):\n",
        "\n",
        "    for i in range(5):\n",
        "      with tf.GradientTape() as disc_tape:\n",
        "        # Generate random noise\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "\n",
        "        # Generate fake images with the generator\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        # Discriminator loss calculation\n",
        "        real_output = discriminatorU((real_images,digits), training=True)\n",
        "        fake_output = discriminatorU((generated_images,digits), training=True)\n",
        "        d_loss = discriminator_loss(real_output, fake_output,real_images,digits)\n",
        "\n",
        "\n",
        "      gradients_of_discriminator = disc_tape.gradient(d_loss, discriminatorU.trainable_variables)\n",
        "      discriminatorU_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminatorU.trainable_variables))\n",
        "\n",
        "      if i == 0:\n",
        "        weights = discriminatorU.get_weights()\n",
        "\n",
        "    with tf.GradientTape() as gen_tape:\n",
        "      # Generate random noise\n",
        "      noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "\n",
        "      # Generate fake images with the generator\n",
        "      generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "      fake_output = discriminatorU((generated_images,digits), training=True)\n",
        "\n",
        "       # Generator loss calculation\n",
        "      g_loss = generator_loss(fake_output)\n",
        "\n",
        "    # Update generator and discriminator variables\n",
        "\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(g_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    discriminatorU.set_weights(weights)\n",
        "\n",
        "    tf.print(\"disc_loss\",d_loss,'gen_loss',g_loss)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cP3-wZztEeaE"
      },
      "outputs": [],
      "source": [
        "NOISE_DIM = 100\n",
        "GP_WEIGHT = 10\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def train_step(images,digits):\n",
        "\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tapeW:\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        real_outputW = discriminatorW((images,digits), training=True)\n",
        "        fake_outputW = discriminatorW((generated_images,digits), training=True)\n",
        "\n",
        "        disc_lossW = discriminator_lossW(real_outputW, fake_outputW)\n",
        "\n",
        "        gen_lossW = generator_lossW(fake_outputW)\n",
        "        gen_loss = gen_lossW\n",
        "\n",
        "        gp = gradient_penalty(images, generated_images, digits)\n",
        "        disc_lossW += gp * GP_WEIGHT\n",
        "\n",
        "\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    gradients_of_discriminatorW = disc_tapeW.gradient(disc_lossW, discriminatorW.trainable_variables)\n",
        "    discriminatorW_optimizer.apply_gradients(zip(gradients_of_discriminatorW, discriminatorW.trainable_variables))\n",
        "\n",
        "\n",
        "    tf.print(\"disc_lossW\",disc_lossW,'gen_lossW',gen_lossW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Sx_KbIfjiogE"
      },
      "outputs": [],
      "source": [
        "def train(dataset,y_train, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    for batch in range(len(dataset) // BATCH_SIZE):\n",
        "\n",
        "            target_images = dataset[batch * BATCH_SIZE: (batch+1) * BATCH_SIZE]\n",
        "            digits = y_train[batch * BATCH_SIZE: (batch+1) * BATCH_SIZE]\n",
        "\n",
        "            train_step(target_images,digits)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      print(epoch)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWp_3RkPg248",
        "outputId": "fa499d02-beb4-44b8-f64e-71bfcbd7fb49",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "disc_loss 0.435698688 gen_loss 1.79958606\n",
            "disc_loss 0.425983608 gen_loss 1.85611105\n",
            "disc_loss 0.404671192 gen_loss 1.98147273\n",
            "disc_loss 0.397090107 gen_loss 1.84919643\n",
            "disc_loss 0.3754448 gen_loss 1.84705353\n",
            "disc_loss 0.380596787 gen_loss 1.8832705\n",
            "disc_loss 0.368771404 gen_loss 1.81464314\n",
            "disc_loss 0.382821053 gen_loss 1.77248514\n",
            "disc_loss 0.36073941 gen_loss 1.95466411\n",
            "disc_loss 0.353122622 gen_loss 1.82483232\n",
            "disc_loss 0.35014832 gen_loss 1.83985853\n",
            "disc_loss 0.372128844 gen_loss 1.82326293\n",
            "disc_loss 0.362340301 gen_loss 1.92467833\n",
            "disc_loss 0.368025064 gen_loss 1.93732095\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 100\n",
        "x_train2 = np.expand_dims(x_train, axis=-1)\n",
        "x_train2 = (x_train2 - np.min(x_train2)) / (np.max(x_train2) - np.min(x_train2))\n",
        "train(x_train2,y_train, EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "9vPp5AiDkrAF",
        "outputId": "8fc339f6-e17a-4589-cfbd-a0dee2d60574",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n",
            "tf.Tensor([2], shape=(1,), dtype=int32)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "noise = tf.random.normal(shape=(1,100))\n",
        "random_number = tf.random.uniform(shape=[1,], minval=0, maxval=10, dtype=tf.int32)\n",
        "test = generator.predict((noise,random_number))\n",
        "print(random_number)\n",
        "plt.imshow(test.squeeze())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_r4IEg2iBLvP"
      },
      "outputs": [],
      "source": [
        "NOISE_DIM = 100\n",
        "GP_WEIGHT = 10\n",
        "\n",
        "\n",
        "#@tf.function\n",
        "def train_step(images,digits):\n",
        "\n",
        "\n",
        "    for i in range(3):\n",
        "      with tf.GradientTape() as disc_tapeU:\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        real_outputU = discriminatorU((images,digits), training=True)\n",
        "        fake_outputU = discriminatorU((generated_images,digits), training=True)\n",
        "        disc_lossU = cross_entropy(tf.ones_like(real_outputU), real_outputU)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      gradients_of_discriminatorU = disc_tapeU.gradient(disc_lossU, discriminatorU.trainable_variables)\n",
        "      discriminatorU_optimizer.apply_gradients(zip(gradients_of_discriminatorU, discriminatorU.trainable_variables))\n",
        "      if i == 0:\n",
        "        weights = discriminatorU.get_weights()\n",
        "\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tapeW:\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        real_outputW = discriminatorW((images,digits), training=True)\n",
        "        fake_outputW = discriminatorW((generated_images,digits), training=True)\n",
        "        real_outputU = discriminatorU((images,digits), training=True)\n",
        "        fake_outputU = discriminatorU((generated_images,digits), training=True)\n",
        "        disc_lossW = discriminator_lossW(real_outputW, fake_outputW)\n",
        "\n",
        "\n",
        "        gen_lossU = cross_entropy(tf.ones_like(fake_outputU), fake_outputU)\n",
        "        gen_lossW = generator_lossW(fake_outputW)\n",
        "        gen_loss = gen_lossU#+gen_lossW\n",
        "\n",
        "        gp = gradient_penalty(images, generated_images, digits)\n",
        "        disc_lossW += gp * GP_WEIGHT\n",
        "\n",
        "\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    gradients_of_discriminatorW = disc_tapeW.gradient(disc_lossW, discriminatorW.trainable_variables)\n",
        "    discriminatorW_optimizer.apply_gradients(zip(gradients_of_discriminatorW, discriminatorW.trainable_variables))\n",
        "\n",
        "    discriminatorU.set_weights(weights)\n",
        "\n",
        "    tf.print(\"disc_lossW\",disc_lossW,'disc_lossU',disc_lossU,'gen_lossU',gen_lossU,'gen_lossW',gen_lossW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhuRFc0ro5T_"
      },
      "outputs": [],
      "source": [
        "print(np.min(x_train2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojIuJFIAybro"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}