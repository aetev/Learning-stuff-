{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aetev/Learning-stuff-/blob/main/wganworkking2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xI7rEeMMgDQI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgyl_WtbgO5k",
        "outputId": "e5e117b0-abc2-4a8e-be40-4eb41c9226d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 10s 0us/step\n"
          ]
        }
      ],
      "source": [
        "#(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kik7wQ1qgOV-"
      },
      "outputs": [],
      "source": [
        "def make_generator_model():\n",
        "\n",
        "    input_noise = layers.Input(shape=(100,))\n",
        "    input_digit = layers.Input(shape=(1,))\n",
        "    digit = layers.Embedding(10, 10)(input_digit)\n",
        "    digit = layers.Flatten()(digit)\n",
        "\n",
        "    x = layers.concatenate([input_noise, digit])\n",
        "\n",
        "    x = layers.Dense(8*8*24,activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.Reshape((8, 8, 24))(x)\n",
        "\n",
        "\n",
        "    x = layers.Conv2DTranspose(64,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv2DTranspose(64,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv2D(3,3,1,padding='same',activation='sigmoid')(x)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=(input_noise,input_digit), outputs=x)\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "\n",
        "def make_discriminator_model():\n",
        "    input_img = layers.Input(shape=(32,32,3))\n",
        "\n",
        "    input_digit = layers.Input(shape=(1,))\n",
        "    digit = layers.Embedding(10, 5)(input_digit)\n",
        "    digit = layers.Flatten()(digit)\n",
        "\n",
        "\n",
        "\n",
        "    x = layers.Conv2D(64,5,2,padding='same',activation='LeakyReLU')(input_img)\n",
        "\n",
        "\n",
        "    x = layers.Conv2D(64,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "\n",
        "    x = layers.Conv2D(64,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "\n",
        "    x = layers.Conv2D(64,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "\n",
        "    x = layers.concatenate([x, digit])\n",
        "\n",
        "    x = layers.Dense(128, activation='LeakyReLU')(x)\n",
        "\n",
        "    dense_output = layers.Dense(64, activation='LeakyReLU')(x)\n",
        "\n",
        "\n",
        "    dense_output = layers.Dense(1, activation=None)(dense_output)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=(input_img,input_digit), outputs=dense_output)\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qzdSabqdVu_H"
      },
      "outputs": [],
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lS0DF8rjhHdY",
        "outputId": "17cac126-3531-47f5-ade7-9689d743bedc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, 1, 10)                100       ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)        [(None, 100)]                0         []                            \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 10)                   0         ['embedding[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 110)                  0         ['input_1[0][0]',             \n",
            "                                                                     'flatten[0][0]']             \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 1536)                 170496    ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " reshape (Reshape)           (None, 8, 8, 24)             0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTr  (None, 16, 16, 64)           13888     ['reshape[0][0]']             \n",
            " anspose)                                                                                         \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 16, 16, 64)           256       ['conv2d_transpose[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2D  (None, 32, 32, 64)           36928     ['batch_normalization[0][0]'] \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 32, 32, 64)           256       ['conv2d_transpose_1[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 32, 32, 3)            1731      ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 223655 (873.65 KB)\n",
            "Trainable params: 223399 (872.65 KB)\n",
            "Non-trainable params: 256 (1.00 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "generator = make_generator_model()\n",
        "generator_optimizer = tf.keras.optimizers.Adam(0.0002)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GJxNxRSHkWfl"
      },
      "outputs": [],
      "source": [
        "discriminatorW = make_discriminator_model()\n",
        "discriminatorW_optimizer = tf.keras.optimizers.Adam(0.0004)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6cDVGo73jfqZ"
      },
      "outputs": [],
      "source": [
        "discriminatorU = make_discriminator_model()\n",
        "discriminatorU_optimizer = tf.keras.optimizers.Adam(0.0004)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DYQpIZyEgSlN"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "@tf.function\n",
        "def discriminator_lossW(real_output, fake_output):\n",
        "    real_loss = tf.reduce_mean(real_output)\n",
        "    fake_loss = tf.reduce_mean(fake_output)\n",
        "    total_loss = fake_loss - real_loss\n",
        "    return total_loss\n",
        "\n",
        "@tf.function\n",
        "def generator_lossW(fake_output):\n",
        "    return -tf.reduce_mean(fake_output)\n",
        "\n",
        "@tf.function\n",
        "def gradient_penalty(real_images, fake_images,digits):\n",
        "    alpha = tf.random.uniform([BATCH_SIZE, 1, 1, 1], 0., 1.)\n",
        "    real_images, fake_images = tf.cast(real_images, tf.float32), tf.cast(fake_images, tf.float32)\n",
        "    interpolated_images = alpha * real_images + ((1 - alpha) * fake_images)\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(interpolated_images)\n",
        "        pred = discriminatorW((interpolated_images,digits), training=True)\n",
        "    gradients = tape.gradient(pred, [interpolated_images])[0]\n",
        "    norm = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis=[1, 2, 3]))\n",
        "    gp = tf.reduce_mean((norm - 1.)**2)\n",
        "    return gp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4rgSqI2sf1sT"
      },
      "outputs": [],
      "source": [
        "\n",
        "@tf.function\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "@tf.function\n",
        "def generator_loss(fake_output):\n",
        "    return -tf.reduce_mean(fake_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilj-woz7fSum"
      },
      "outputs": [],
      "source": [
        "NOISE_DIM = 100\n",
        "\n",
        "@tf.function\n",
        "def train_step(real_images,digits):\n",
        "    with tf.GradientTape() as disc_tape, tf.GradientTape() as gen_tape:\n",
        "        # Generate random noise\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "\n",
        "        # Generate fake images with the generator\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        # Discriminator loss calculation\n",
        "        real_output = discriminatorU((real_images,digits), training=True)\n",
        "        fake_output = discriminatorU((generated_images,digits), training=True)\n",
        "        d_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "        # Generator loss calculation\n",
        "        g_loss = generator_loss(fake_output)\n",
        "\n",
        "    # Update generator and discriminator variables\n",
        "    gradients_of_discriminator = disc_tape.gradient(d_loss, discriminatorU.trainable_variables)\n",
        "    gradients_of_generator = gen_tape.gradient(g_loss, generator.trainable_variables)\n",
        "    discriminatorU_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminatorU.trainable_variables))\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    tf.print(\"disc_loss\",d_loss,'gen_loss',g_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "8AuOxPdvp1hu"
      },
      "outputs": [],
      "source": [
        "NOISE_DIM = 100\n",
        "threshold = 0.5\n",
        "#@tf.function\n",
        "def train_step(real_images,digits):\n",
        "\n",
        "    for i in range(5):\n",
        "      with tf.GradientTape() as disc_tape:\n",
        "        # Generate random noise\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "\n",
        "        # Generate fake images with the generator\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        # Discriminator loss calculation\n",
        "        real_output = discriminatorU((real_images,digits), training=True)\n",
        "        fake_output = discriminatorU((generated_images,digits), training=True)\n",
        "        d_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "\n",
        "      gradients_of_discriminator = disc_tape.gradient(d_loss, discriminatorU.trainable_variables)\n",
        "      discriminatorU_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminatorU.trainable_variables))\n",
        "\n",
        "      if i == 0:\n",
        "        weights = discriminatorU.get_weights()\n",
        "\n",
        "    with tf.GradientTape() as gen_tape:\n",
        "      # Generate random noise\n",
        "      noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "\n",
        "      # Generate fake images with the generator\n",
        "      generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "      fake_output = discriminatorU((generated_images,digits), training=True)\n",
        "\n",
        "       # Generator loss calculation\n",
        "      g_loss = generator_loss(fake_output)\n",
        "\n",
        "    # Update generator and discriminator variables\n",
        "\n",
        "    modi = .000001\n",
        "\n",
        "    mult = abs(min(d_loss,1)-.5)*2\n",
        "\n",
        "    nudge = modi*mult\n",
        "\n",
        "    if d_loss > threshold:\n",
        "      new_lr = generator_optimizer.learning_rate-nudge\n",
        "    else:\n",
        "      new_lr = generator_optimizer.learning_rate+nudge\n",
        "\n",
        "    generator_optimizer.learning_rate.assign(new_lr)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(g_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    discriminatorU.set_weights(weights)\n",
        "\n",
        "    tf.print(\"disc_loss\",d_loss,'gen_loss',g_loss,'LR',generator_optimizer.learning_rate)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cP3-wZztEeaE"
      },
      "outputs": [],
      "source": [
        "NOISE_DIM = 100\n",
        "GP_WEIGHT = 10\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def train_step(images,digits):\n",
        "\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tapeW:\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        real_outputW = discriminatorW((images,digits), training=True)\n",
        "        fake_outputW = discriminatorW((generated_images,digits), training=True)\n",
        "\n",
        "        disc_lossW = discriminator_lossW(real_outputW, fake_outputW)\n",
        "\n",
        "        gen_lossW = generator_lossW(fake_outputW)\n",
        "        gen_loss = gen_lossW\n",
        "\n",
        "        gp = gradient_penalty(images, generated_images, digits)\n",
        "        disc_lossW += gp * GP_WEIGHT\n",
        "\n",
        "\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    gradients_of_discriminatorW = disc_tapeW.gradient(disc_lossW, discriminatorW.trainable_variables)\n",
        "    discriminatorW_optimizer.apply_gradients(zip(gradients_of_discriminatorW, discriminatorW.trainable_variables))\n",
        "\n",
        "\n",
        "    tf.print(\"disc_lossW\",disc_lossW,'gen_lossW',gen_lossW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Sx_KbIfjiogE"
      },
      "outputs": [],
      "source": [
        "def train(dataset,y_train, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    for batch in range(len(dataset) // BATCH_SIZE):\n",
        "\n",
        "            target_images = dataset[batch * BATCH_SIZE: (batch+1) * BATCH_SIZE]\n",
        "            digits = y_train[batch * BATCH_SIZE: (batch+1) * BATCH_SIZE]\n",
        "\n",
        "            train_step(target_images,digits)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      print(epoch)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = 1\n",
        "modi = .000001\n",
        "\n",
        "\n",
        "mult = abs(min(loss,1)-.5)*2\n",
        "nudge = modi*mult\n",
        "\n",
        "print(nudge)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vN5GmsyfuiNd",
        "outputId": "82b63bd4-eec8-436f-b50b-1741c725d3e4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWp_3RkPg248",
        "outputId": "95d97606-81fe-4589-ed71-b878d8bf59d0",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "disc_loss 0.708725095 gen_loss 1.90411174 LR 0.000100583071\n",
            "disc_loss 0.612347841 gen_loss 0.907178223 LR 0.000100358375\n",
            "disc_loss 0.575429 gen_loss 1.95501232 LR 0.000100207515\n",
            "disc_loss 0.530647337 gen_loss 0.728970349 LR 0.000100146222\n",
            "disc_loss 0.736583471 gen_loss 2.04342675 LR 9.96730523e-05\n",
            "disc_loss 0.537256956 gen_loss 0.845323682 LR 9.95985392e-05\n",
            "disc_loss 0.794878244 gen_loss 1.74586523 LR 9.90087792e-05\n",
            "disc_loss 0.576463103 gen_loss 0.919083834 LR 9.88558531e-05\n",
            "disc_loss 0.539568484 gen_loss 1.58973849 LR 9.87767125e-05\n",
            "disc_loss 0.550500154 gen_loss 0.872136712 LR 9.8675715e-05\n",
            "disc_loss 0.421801805 gen_loss 1.28859222 LR 9.88321117e-05\n",
            "disc_loss 0.453748882 gen_loss 1.40062153 LR 9.89246109e-05\n",
            "disc_loss 0.532259226 gen_loss 1.56792426 LR 9.8860095e-05\n",
            "disc_loss 0.618623376 gen_loss 1.56178951 LR 9.86228479e-05\n",
            "disc_loss 0.404509723 gen_loss 1.74313426 LR 9.88138272e-05\n",
            "disc_loss 0.570229053 gen_loss 1.38511586 LR 9.86733721e-05\n",
            "disc_loss 0.488717645 gen_loss 1.93294096 LR 9.86959349e-05\n",
            "disc_loss 0.510427415 gen_loss 0.797478914 LR 9.8675082e-05\n",
            "disc_loss 0.696807802 gen_loss 1.97665882 LR 9.82814672e-05\n",
            "disc_loss 0.621859372 gen_loss 1.70384836 LR 9.80377517e-05\n",
            "disc_loss 0.721467853 gen_loss 1.08612931 LR 9.75948133e-05\n",
            "disc_loss 1.12485433 gen_loss 1.99552393 LR 9.65948129e-05\n",
            "disc_loss 0.848051667 gen_loss 2.3038671 LR 9.58987075e-05\n",
            "disc_loss 0.918376327 gen_loss 1.66406143 LR 9.50619578e-05\n",
            "disc_loss 0.774435282 gen_loss 1.19118023 LR 9.45130887e-05\n",
            "disc_loss 0.832802474 gen_loss 1.4222796 LR 9.38474841e-05\n",
            "disc_loss 0.673811078 gen_loss 1.82683325 LR 9.34998607e-05\n",
            "disc_loss 0.687498 gen_loss 1.84418273 LR 9.31248651e-05\n",
            "disc_loss 0.732734859 gen_loss 1.47932565 LR 9.2659393e-05\n",
            "disc_loss 0.643956721 gen_loss 1.12042105 LR 9.23714761e-05\n",
            "disc_loss 0.764211118 gen_loss 1.76216626 LR 9.18430524e-05\n",
            "disc_loss 0.589606762 gen_loss 1.72173023 LR 9.16638382e-05\n",
            "disc_loss 0.671015263 gen_loss 0.89394486 LR 9.132181e-05\n",
            "disc_loss 0.553542376 gen_loss 1.14650631 LR 9.12147225e-05\n",
            "disc_loss 0.685493827 gen_loss 1.85101748 LR 9.0843736e-05\n",
            "disc_loss 0.580744386 gen_loss 1.81586063 LR 9.06822461e-05\n",
            "disc_loss 0.697799683 gen_loss 0.566958606 LR 9.0286645e-05\n",
            "disc_loss 0.716183603 gen_loss 1.62805796 LR 8.98542785e-05\n",
            "disc_loss 0.95031029 gen_loss 2.03859186 LR 8.89536605e-05\n",
            "disc_loss 0.74260664 gen_loss 2.23211694 LR 8.84684487e-05\n",
            "disc_loss 0.784335494 gen_loss 1.85597038 LR 8.78997744e-05\n",
            "disc_loss 0.510021448 gen_loss 1.23397803 LR 8.78797291e-05\n",
            "disc_loss 0.629621446 gen_loss 1.47420585 LR 8.76204867e-05\n",
            "disc_loss 0.481236368 gen_loss 1.85127234 LR 8.76580161e-05\n",
            "disc_loss 0.601890206 gen_loss 1.7027688 LR 8.74542384e-05\n",
            "disc_loss 0.477844626 gen_loss 1.14525366 LR 8.7498549e-05\n",
            "disc_loss 0.6925807 gen_loss 1.99127305 LR 8.71133889e-05\n",
            "disc_loss 0.463635623 gen_loss 2.26241446 LR 8.71861193e-05\n",
            "disc_loss 0.434173584 gen_loss 1.34993672 LR 8.73177705e-05\n",
            "disc_loss 0.438980371 gen_loss 2.29182887 LR 8.74398102e-05\n",
            "disc_loss 0.443185389 gen_loss 0.927419066 LR 8.75534388e-05\n",
            "disc_loss 0.533479214 gen_loss 2.15548515 LR 8.74864782e-05\n",
            "disc_loss 0.956846595 gen_loss 2.83421278 LR 8.65727852e-05\n",
            "disc_loss 0.484923422 gen_loss 0.353270113 LR 8.66029368e-05\n",
            "disc_loss 0.820737 gen_loss 2.20551467 LR 8.59614593e-05\n",
            "disc_loss 0.449137419 gen_loss 2.55672455 LR 8.60631844e-05\n",
            "disc_loss 0.783056736 gen_loss 0.96276629 LR 8.54970713e-05\n",
            "disc_loss 0.524389505 gen_loss 1.05485749 LR 8.54482932e-05\n",
            "disc_loss 0.494801074 gen_loss 1.878654 LR 8.54586906e-05\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 100\n",
        "x_train2 = np.expand_dims(x_train, axis=-1)\n",
        "x_train2 = (x_train2 - np.min(x_train2)) / (np.max(x_train2) - np.min(x_train2))\n",
        "train(x_train2,y_train, EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "9vPp5AiDkrAF",
        "outputId": "3c959456-7e4f-43b7-8f0b-afabe51f7683",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n",
            "tf.Tensor([3], shape=(1,), dtype=int32)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "noise = tf.random.normal(shape=(1,100))\n",
        "random_number = tf.random.uniform(shape=[1,], minval=0, maxval=10, dtype=tf.int32)\n",
        "test = generator.predict((noise,random_number))\n",
        "print(random_number)\n",
        "plt.imshow(test.squeeze())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_r4IEg2iBLvP"
      },
      "outputs": [],
      "source": [
        "NOISE_DIM = 100\n",
        "GP_WEIGHT = 10\n",
        "\n",
        "\n",
        "#@tf.function\n",
        "def train_step(images,digits):\n",
        "\n",
        "\n",
        "    for i in range(3):\n",
        "      with tf.GradientTape() as disc_tapeU:\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        real_outputU = discriminatorU((images,digits), training=True)\n",
        "        fake_outputU = discriminatorU((generated_images,digits), training=True)\n",
        "        disc_lossU = cross_entropy(tf.ones_like(real_outputU), real_outputU)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      gradients_of_discriminatorU = disc_tapeU.gradient(disc_lossU, discriminatorU.trainable_variables)\n",
        "      discriminatorU_optimizer.apply_gradients(zip(gradients_of_discriminatorU, discriminatorU.trainable_variables))\n",
        "      if i == 0:\n",
        "        weights = discriminatorU.get_weights()\n",
        "\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tapeW:\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        real_outputW = discriminatorW((images,digits), training=True)\n",
        "        fake_outputW = discriminatorW((generated_images,digits), training=True)\n",
        "        real_outputU = discriminatorU((images,digits), training=True)\n",
        "        fake_outputU = discriminatorU((generated_images,digits), training=True)\n",
        "        disc_lossW = discriminator_lossW(real_outputW, fake_outputW)\n",
        "\n",
        "\n",
        "        gen_lossU = cross_entropy(tf.ones_like(fake_outputU), fake_outputU)\n",
        "        gen_lossW = generator_lossW(fake_outputW)\n",
        "        gen_loss = gen_lossU#+gen_lossW\n",
        "\n",
        "        gp = gradient_penalty(images, generated_images, digits)\n",
        "        disc_lossW += gp * GP_WEIGHT\n",
        "\n",
        "\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    gradients_of_discriminatorW = disc_tapeW.gradient(disc_lossW, discriminatorW.trainable_variables)\n",
        "    discriminatorW_optimizer.apply_gradients(zip(gradients_of_discriminatorW, discriminatorW.trainable_variables))\n",
        "\n",
        "    discriminatorU.set_weights(weights)\n",
        "\n",
        "    tf.print(\"disc_lossW\",disc_lossW,'disc_lossU',disc_lossU,'gen_lossU',gen_lossU,'gen_lossW',gen_lossW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhuRFc0ro5T_"
      },
      "outputs": [],
      "source": [
        "print(np.min(x_train2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojIuJFIAybro"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}