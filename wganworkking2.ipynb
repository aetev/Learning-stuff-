{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aetev/Learning-stuff-/blob/main/wganworkking2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xI7rEeMMgDQI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgyl_WtbgO5k",
        "outputId": "cfc559aa-e307-469d-bbb8-426f5112eceb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 4s 0us/step\n"
          ]
        }
      ],
      "source": [
        "#(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kik7wQ1qgOV-"
      },
      "outputs": [],
      "source": [
        "def make_generator_model():\n",
        "\n",
        "    input_noise = layers.Input(shape=(100,))\n",
        "    input_digit = layers.Input(shape=(1,))\n",
        "    digit = layers.Embedding(10, 10)(input_digit)\n",
        "    digit = layers.Flatten()(digit)\n",
        "\n",
        "    x = layers.concatenate([input_noise, digit])\n",
        "\n",
        "    x = layers.Dense(8*8*24,activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.Reshape((8, 8, 24))(x)\n",
        "\n",
        "\n",
        "    x = layers.Conv2DTranspose(64,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv2DTranspose(64,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv2D(3,3,1,padding='same',activation='sigmoid')(x)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=(input_noise,input_digit), outputs=x)\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "\n",
        "def make_discriminator_model():\n",
        "    input_img = layers.Input(shape=(32,32,3))\n",
        "\n",
        "    input_digit = layers.Input(shape=(1,))\n",
        "    digit = layers.Embedding(10, 5)(input_digit)\n",
        "    digit = layers.Flatten()(digit)\n",
        "\n",
        "\n",
        "\n",
        "    x = layers.Conv2D(64,5,2,padding='same',activation='LeakyReLU')(input_img)\n",
        "\n",
        "\n",
        "    x = layers.Conv2D(64,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "\n",
        "    x = layers.Conv2D(64,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "\n",
        "    x = layers.Conv2D(64,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "\n",
        "    x = layers.concatenate([x, digit])\n",
        "\n",
        "    x = layers.Dense(128, activation='LeakyReLU')(x)\n",
        "\n",
        "    dense_output = layers.Dense(64, activation='LeakyReLU')(x)\n",
        "\n",
        "\n",
        "    dense_output = layers.Dense(1, activation=None)(dense_output)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=(input_img,input_digit), outputs=dense_output)\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qzdSabqdVu_H"
      },
      "outputs": [],
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lS0DF8rjhHdY",
        "outputId": "e3b58a00-1683-49b7-9b9f-83a1774bdba9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_8 (InputLayer)        [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)     (None, 1, 10)                100       ['input_8[0][0]']             \n",
            "                                                                                                  \n",
            " input_7 (InputLayer)        [(None, 100)]                0         []                            \n",
            "                                                                                                  \n",
            " flatten_5 (Flatten)         (None, 10)                   0         ['embedding_3[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate  (None, 110)                  0         ['input_7[0][0]',             \n",
            " )                                                                   'flatten_5[0][0]']           \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, 1536)                 170496    ['concatenate_3[0][0]']       \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)         (None, 8, 8, 24)             0         ['dense_7[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2D  (None, 16, 16, 64)           13888     ['reshape_1[0][0]']           \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 16, 16, 64)           256       ['conv2d_transpose_2[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2D  (None, 32, 32, 64)           36928     ['batch_normalization_2[0][0]'\n",
            " Transpose)                                                         ]                             \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 32, 32, 64)           256       ['conv2d_transpose_3[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 32, 32, 3)            1731      ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 223655 (873.65 KB)\n",
            "Trainable params: 223399 (872.65 KB)\n",
            "Non-trainable params: 256 (1.00 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "generator = make_generator_model()\n",
        "generator_optimizer = tf.keras.optimizers.Adam(0.0002)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "GJxNxRSHkWfl"
      },
      "outputs": [],
      "source": [
        "discriminatorW = make_discriminator_model()\n",
        "discriminatorW_optimizer = tf.keras.optimizers.Adam(0.0004)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "6cDVGo73jfqZ"
      },
      "outputs": [],
      "source": [
        "discriminatorU = make_discriminator_model()\n",
        "discriminatorU_optimizer = tf.keras.optimizers.Adam(0.0004)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "DYQpIZyEgSlN"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "@tf.function\n",
        "def discriminator_lossW(real_output, fake_output):\n",
        "    real_loss = tf.reduce_mean(real_output)\n",
        "    fake_loss = tf.reduce_mean(fake_output)\n",
        "    total_loss = fake_loss - real_loss\n",
        "    return total_loss\n",
        "\n",
        "@tf.function\n",
        "def generator_lossW(fake_output):\n",
        "    return -tf.reduce_mean(fake_output)\n",
        "\n",
        "@tf.function\n",
        "def gradient_penalty(real_images, fake_images,digits):\n",
        "    alpha = tf.random.uniform([BATCH_SIZE, 1, 1, 1], 0., 1.)\n",
        "    real_images, fake_images = tf.cast(real_images, tf.float32), tf.cast(fake_images, tf.float32)\n",
        "    interpolated_images = alpha * real_images + ((1 - alpha) * fake_images)\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(interpolated_images)\n",
        "        pred = discriminatorW((interpolated_images,digits), training=True)\n",
        "    gradients = tape.gradient(pred, [interpolated_images])[0]\n",
        "    norm = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis=[1, 2, 3]))\n",
        "    gp = tf.reduce_mean((norm - 1.)**2)\n",
        "    return gp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "4rgSqI2sf1sT"
      },
      "outputs": [],
      "source": [
        "\n",
        "@tf.function\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "@tf.function\n",
        "def generator_loss(fake_output):\n",
        "    return -tf.reduce_mean(fake_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilj-woz7fSum"
      },
      "outputs": [],
      "source": [
        "NOISE_DIM = 100\n",
        "\n",
        "@tf.function\n",
        "def train_step(real_images,digits):\n",
        "    with tf.GradientTape() as disc_tape, tf.GradientTape() as gen_tape:\n",
        "        # Generate random noise\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "\n",
        "        # Generate fake images with the generator\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        # Discriminator loss calculation\n",
        "        real_output = discriminatorU((real_images,digits), training=True)\n",
        "        fake_output = discriminatorU((generated_images,digits), training=True)\n",
        "        d_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "        # Generator loss calculation\n",
        "        g_loss = generator_loss(fake_output)\n",
        "\n",
        "    # Update generator and discriminator variables\n",
        "    gradients_of_discriminator = disc_tape.gradient(d_loss, discriminatorU.trainable_variables)\n",
        "    gradients_of_generator = gen_tape.gradient(g_loss, generator.trainable_variables)\n",
        "    discriminatorU_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminatorU.trainable_variables))\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    tf.print(\"disc_loss\",d_loss,'gen_loss',g_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "8AuOxPdvp1hu"
      },
      "outputs": [],
      "source": [
        "NOISE_DIM = 100\n",
        "threshold = 0.5\n",
        "#@tf.function\n",
        "def train_step(real_images,digits):\n",
        "\n",
        "    for i in range(5):\n",
        "      with tf.GradientTape() as disc_tape:\n",
        "        # Generate random noise\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "\n",
        "        # Generate fake images with the generator\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        # Discriminator loss calculation\n",
        "        real_output = discriminatorU((real_images,digits), training=True)\n",
        "        fake_output = discriminatorU((generated_images,digits), training=True)\n",
        "        d_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "\n",
        "      gradients_of_discriminator = disc_tape.gradient(d_loss, discriminatorU.trainable_variables)\n",
        "      discriminatorU_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminatorU.trainable_variables))\n",
        "\n",
        "      if i == 0:\n",
        "        weights = discriminatorU.get_weights()\n",
        "\n",
        "    with tf.GradientTape() as gen_tape:\n",
        "      # Generate random noise\n",
        "      noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "\n",
        "      # Generate fake images with the generator\n",
        "      generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "      fake_output = discriminatorU((generated_images,digits), training=True)\n",
        "\n",
        "       # Generator loss calculation\n",
        "      g_loss = generator_loss(fake_output)\n",
        "\n",
        "    # Update generator and discriminator variables\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(g_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    discriminatorU.set_weights(weights)\n",
        "\n",
        "    tf.print(\"disc_loss\",d_loss,'gen_loss',g_loss,'LR',generator_optimizer.learning_rate)\n",
        "\n",
        "    if d_loss > threshold:\n",
        "      new_lr = generator_optimizer.learning_rate-.000001\n",
        "    else:\n",
        "      new_lr = generator_optimizer.learning_rate+.000001\n",
        "\n",
        "    generator_optimizer.learning_rate.assign(new_lr)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cP3-wZztEeaE"
      },
      "outputs": [],
      "source": [
        "NOISE_DIM = 100\n",
        "GP_WEIGHT = 10\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def train_step(images,digits):\n",
        "\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tapeW:\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        real_outputW = discriminatorW((images,digits), training=True)\n",
        "        fake_outputW = discriminatorW((generated_images,digits), training=True)\n",
        "\n",
        "        disc_lossW = discriminator_lossW(real_outputW, fake_outputW)\n",
        "\n",
        "        gen_lossW = generator_lossW(fake_outputW)\n",
        "        gen_loss = gen_lossW\n",
        "\n",
        "        gp = gradient_penalty(images, generated_images, digits)\n",
        "        disc_lossW += gp * GP_WEIGHT\n",
        "\n",
        "\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    gradients_of_discriminatorW = disc_tapeW.gradient(disc_lossW, discriminatorW.trainable_variables)\n",
        "    discriminatorW_optimizer.apply_gradients(zip(gradients_of_discriminatorW, discriminatorW.trainable_variables))\n",
        "\n",
        "\n",
        "    tf.print(\"disc_lossW\",disc_lossW,'gen_lossW',gen_lossW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "Sx_KbIfjiogE"
      },
      "outputs": [],
      "source": [
        "def train(dataset,y_train, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    for batch in range(len(dataset) // BATCH_SIZE):\n",
        "\n",
        "            target_images = dataset[batch * BATCH_SIZE: (batch+1) * BATCH_SIZE]\n",
        "            digits = y_train[batch * BATCH_SIZE: (batch+1) * BATCH_SIZE]\n",
        "\n",
        "            train_step(target_images,digits)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      print(epoch)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWp_3RkPg248",
        "outputId": "29f82070-819f-46ee-91cd-149c62a7f2f6",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "disc_loss 0.292803705 gen_loss 2.63397527 LR 5.29999525e-05\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 100\n",
        "x_train2 = np.expand_dims(x_train, axis=-1)\n",
        "x_train2 = (x_train2 - np.min(x_train2)) / (np.max(x_train2) - np.min(x_train2))\n",
        "train(x_train2,y_train, EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "9vPp5AiDkrAF",
        "outputId": "802d973e-738a-4670-e0a9-dd30dbb163de",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n",
            "tf.Tensor([5], shape=(1,), dtype=int32)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAyGklEQVR4nO3de3Cb9Zkv8K8sS/JNlnyXFV9w4lwIiQ24JHihIZA0l57hQMnZgbazG7oMDKxhFrLdttlpobC7Y5bOtLSdNPyxLNmeaaBlp4GBLVAIxBxKnDaGEK5u7DixHVu+xZZs2bq/5w+KW0NCniex87Od72dGM7H1zePfq/d99ViW9MhmWZYFIiKi8yzN9AKIiOjCxAZERERGsAEREZERbEBERGQEGxARERnBBkREREawARERkRFsQEREZES66QV8WiqVQk9PD9xuN2w2m+nlEBGRkmVZGB0dhd/vR1ra6R/nzLoG1NPTg/LyctPLICKic9TV1YWysrLTXj9jDWjHjh34wQ9+gEAggNraWvz0pz/FqlWrzvj/3G43AGDT+mvgSJctz57ZL16XPWIXZwFgFAlxduTYuKp2ICmvHU1kqWovcMmz+Q6HqraVJV83AFRWrBRnvWXdqtqhaIY4mxvV/cW5OyWvXZipO5UKstyqfHxYfpt3d4VUtVOOEXE2Mjiqqr2gQH67hHN1t6HDSoqz7f26iWP2uFOVj6XliLMRa1hVOzTaJ86GQ7pj3Erki7O1l3nE2Xg8gRf+53eT9+enMyMN6Je//CW2bduGxx57DKtXr8ajjz6KjRs3orW1FcXFxZ/7fz/5s5sjPR0Oh7ABOeRNxZ7UNSAH5Aduul2389MUT8GlpXTrtiviDk0YQCpddzI7FQ3O5dIdkk7FIeyydPvHkZq5dWe4dHdwaU752jW3NwCkhOcZACTTdceKS3Fuxp3aBiT/E316ekpVO93SrSWVJs+nW9pzWXE/obwPshT3K9L74790pqdRZuRFCD/84Q9x++234xvf+AaWL1+Oxx57DFlZWfjP//zPmfhxREQ0B017A4rFYmhpacH69ev//EPS0rB+/Xrs37//M/loNIpQKDTlQkRE89+0N6DBwUEkk0mUlJRM+X5JSQkCgcBn8o2NjfB4PJMXvgCBiOjCYPx9QNu3b0cwGJy8dHV1mV4SERGdB9P+IoTCwkLY7Xb09U195UZfXx98Pt9n8i6XCy6X4iVbREQ0L0z7IyCn04m6ujrs3bt38nupVAp79+5FfX39dP84IiKao2bkZdjbtm3D1q1b8YUvfAGrVq3Co48+inA4jG984xsz8eOIiGgOmpEGdPPNN2NgYAD3338/AoEALr30Urz44oufeWECERFduGyWZeneVTjDQqEQPB4Prt94tfyNT5Z8SkCsIKhajyMhfzf8RHZYVRtvytfSYdNNH3CXF4mzYzHduq/L1P0ikZelmCiwoFBV+0il/HeoskhMVbu7W/6GzqraTFXt0RO60y6Rkj9PGms9pqo9ongT7fBH76tqZ/sqxdmiPFVphGwD4mwsrHvz59GoLp8zLn+ja2dK+VaTAvn5GbV0z6fbO6Li7OLMG8XZeCKKl5p3IBgMIjc397Q546+CIyKiCxMbEBERGcEGRERERrABERGREWxARERkBBsQEREZwQZERERGsAEREZERbEBERGQEGxARERkxI7PgpoMzMgRHQjYOI+r2iOuWjcqzABC15CNWLitcoardcVvfmUN/Uvn/OlW1B+zZ4uyWNZ/9mIzPMxhVjp0ZHBFn86t1vxMt65PXHvOVqWpftmxcnB08Jh83BADL/LpxRrHYB+Ls+zm607ogLB9pcyIWUdXOTx8SZ0srvKrao46F4qy7w6aqvWDBqCrviDnF2b6x04+mOZWCk/IxP9ggP+8BILNYvu9PZrwkziaiSaD5zDk+AiIiIiPYgIiIyAg2ICIiMoINiIiIjGADIiIiI9iAiIjICDYgIiIygg2IiIiMYAMiIiIj2ICIiMgINiAiIjJi1s6C6xqOIt0u64+pgHyWWfzyqGodq+KyeXQAMJDsUtVOPimfT5V5RYGqdqRjWJx9/03dbVK5QDfLaqgyT5w9OexQ1R5zy3+HShs5oas94hZnbQn57Q0AIbtuplrww4RiLYOq2vE0ee3FHt3cwOQCrzhbuWCJqnZtMCTOHr9CVRojQ+WqfMLZL84WdWbpai+3xNmJd7pVtfs98nMz/0RMnI3HZccUHwEREZERbEBERGQEGxARERnBBkREREawARERkRFsQEREZAQbEBERGcEGRERERrABERGREWxARERkxKwdxZMTlo/iOZ5oF9dNvisffwMAv/VdI87ac+SjQQDgeMZBcbayWTf+Znx5rTib7peP2ACAN9/SjZFZvXKFOPt+6zuq2mWF8rV/UBBX1Q6N9srD72aqavuPFqryFesWibN5fbqxQMGgfNxUSbJNVTvXXyrO5hWPqmoHcJE87CtR1c6KHlHlUy6/PFwcVtVuy/qCODs8pts/aXnysU3jzhxxNoE4gJYz/3xxRSIiomnEBkREREawARERkRFsQEREZAQbEBERGcEGRERERrABERGREWxARERkBBsQEREZwQZERERGsAEREZERs3YWXKTUjvR0WX8s9BbL6/br5phdXiyfB/bHEt0sq+Vd5eJsX7RbVXvRWFCcjcVXqmoX13aq8v3vjImz1Tm6OVknB+Sz/SxFFgCsd5Li7OK8IVXtQKlXle8IyW/DQvtFqtq2tA/E2VCRW1U7NJoQZ4Nt2arahXlRcTaWqZuluKhumSrf8XafOJvukK8bAIoU+2f8ct35M3g0Jc5W2OXzDmN22XxBPgIiIiIjpr0Bff/734fNZptyWbZM99sEERHNfzPyJ7hLLrkEr7zyyp9/SPqs/UsfEREZMiOdIT09HT6fbyZKExHRPDEjzwEdOXIEfr8fCxcuxNe//nV0dp7+SetoNIpQKDTlQkRE89+0N6DVq1dj165dePHFF7Fz5050dHTgi1/8IkZHT/0KscbGRng8nslLebn8lWFERDR3TXsD2rx5M/76r/8aNTU12LhxI37zm99gZGQEv/rVr06Z3759O4LB4OSlq6trupdERESz0Iy/OsDr9WLJkiVoazv1Z5W7XC64XK6ZXgYREc0yM/4+oLGxMbS3t6O0tHSmfxQREc0h096AvvnNb6KpqQnHjh3Dm2++ia985Suw2+346le/Ot0/ioiI5rBp/xNcd3c3vvrVr2JoaAhFRUW4+uqr0dzcjKKiIlWdVUVL4HI4RNmWDPlm1GbqRlVEunPEWe2oF9eik+LsX+XXqWpflV4rzpZtqlLVtrfr3lh88Ih8TInPfpmq9qAlH5WUn12hqm0b+p04687QvXozateNY7noA/mYp/FNuj9pF75libOHgl5V7atK88XZmDuuqu1Mk4+GyWgdUdVuSzuhyuedlB/jsULdsXL08Lg4Gz6p+0tTJBgQZx3VeeKsZZcdU9PegJ566qnpLklERPMQZ8EREZERbEBERGQEGxARERnBBkREREawARERkRFsQEREZAQbEBERGcEGRERERrABERGREWxARERkxIx/HMPZGsiz4HSmRNmLxxSzktJ1PXc847g4uzA6rKo9eMQvznoS8iwApK5RzOA6uVBVO9v9jiq/Yol81pzD06+qHdwvn6d3wBFU1V5UXi3ORtsHVLX9F8mO7U8cT8hPVW+rbIbiJya88mOryutV1V5Yc5E4Gx7XnZuWNybOHh23q2pjSHfXOOCYEGff6dDNvEtTrH0s8YGqdldcvp0TR+UzBpMJ2TbyERARERnBBkREREawARERkRFsQEREZAQbEBERGcEGRERERrABERGREWxARERkBBsQEREZwQZERERGzNpRPGUFV8Dlko1+CJ48Iq47EOlTrWOwq0CcjV3qVdVOS/jE2cz/oxvdcrRbPjajJqtVVTsW9Kry6SPycTlD2boxJR3Hx8TZ4tGPVLXdqxeJs1lLi1S1xyLy0S0AcMkq+bicjO5B3VoqSsTZVTmZqtoZ2fLzJ6tQPloHAGIRjzib+9G7qtqpIvltAgDhXPntsrgorKr9QiBDnE3FdOdPRlJeOx6R34bJRFKU4yMgIiIygg2IiIiMYAMiIiIj2ICIiMgINiAiIjKCDYiIiIxgAyIiIiPYgIiIyAg2ICIiMoINiIiIjGADIiIiI2btLLhKbwYyM2Rziv7Hktf1tOer1pGefUKcDTvlc5UAoNQdEWePv7pAVXtFhXzm3fD7VaraGTiuymd6HeJsuKdLVbuwVD4LzpGjuw2XpBaKsxMLFAchgKC/X5VPG5LP62svrlDVzurqFWfbKnXH+CJ3oTib781S1R6VjRsDAFj+UlXtiaBNlc/OrBRni5PyGXYA0FknP8a7DlerancEXhRnE+Py4yqV5Cw4IiKaxdiAiIjICDYgIiIygg2IiIiMYAMiIiIj2ICIiMgINiAiIjKCDYiIiIxgAyIiIiPYgIiIyAg2ICIiMmLWzoILJocRTbpE2dwlfnHd432HVevIL7hInHUsVgynArAiIK9dvFm+jQAw3pwtzjp8urlkJ1Llqnze6IA4u7LwUlXtFRdfIc72hzNVtXM88hlpvkBCVXsCurl03SWycwEA3K/1qGqfzJHPGhtq7lDVHr1MfrvUDtepaidyguJsFG5V7ZQ7rMq7U3Fxtu/EsKq2s3NcnM3skp9rAOAMeMXZBR75bZK0JSFZCR8BERGREeoG9Prrr+P666+H3++HzWbDM888M+V6y7Jw//33o7S0FJmZmVi/fj2OHDkyXeslIqJ5Qt2AwuEwamtrsWPHjlNe/8gjj+AnP/kJHnvsMRw4cADZ2dnYuHEjIhH5Rw8QEdH8p34OaPPmzdi8efMpr7MsC48++ii++93v4oYbbgAA/PznP0dJSQmeeeYZ3HLLLee2WiIimjem9Tmgjo4OBAIBrF+/fvJ7Ho8Hq1evxv79+0/5f6LRKEKh0JQLERHNf9PagAKBAACgpKRkyvdLSkomr/u0xsZGeDyeyUt5ue4VVkRENDcZfxXc9u3bEQwGJy9dXbqPZCYiorlpWhuQz+cDAPT19U35fl9f3+R1n+ZyuZCbmzvlQkRE89+0NqCqqir4fD7s3bt38nuhUAgHDhxAfX39dP4oIiKa49SvghsbG0NbW9vk1x0dHTh06BDy8/NRUVGBe++9F//6r/+KxYsXo6qqCt/73vfg9/tx4403Tue6iYhojlM3oIMHD+Laa6+d/Hrbtm0AgK1bt2LXrl341re+hXA4jDvuuAMjIyO4+uqr8eKLLyIjI0P1c+ITmbBbsv9TNiAfg5F/ke6R2O8zToiz14zpbs7Sa+Wv+AtOXK6qXblEPhYoaV+oql2doRv1Muy4RJydGNCNQPEkS84c+pMl+TFV7YRiDFO/9baqdjRZqsq3fvBHcTYUG1LVHhmSH7fFg7o/kbu65PtntGpEVRsRuzha6NaNYQpkye9TACCVKBNny5bqxja1x94SZ2PHdedPLCEf3XPsRIE4m7JSopy6Aa1duxaWZZ32epvNhoceeggPPfSQtjQREV1AjL8KjoiILkxsQEREZAQbEBERGcEGRERERrABERGREWxARERkBBsQEREZwQZERERGsAEREZERbEBERGSEehTP+WJV+mFlyuY3jY7KZ18N9rer1lGXHBNnF5euUNUuPymfH1VQJp/ZBAAZ2fIP9svOz1PVThuVz/cCAGdiWJxNVJx+zNOpBIN9Zw79SXaWbh5YNCqfX1hYsUpVOx6SzxgEgM2XyWcYPoujqtoXH5HPscv70iJVba9nsThb6rOpalu98t+fU85BVe2yuO4Yt8rla0mPXqOqverKCnG2K/F/VbU97xSJs0PLIuKsLZEC3jxzjo+AiIjICDYgIiIygg2IiIiMYAMiIiIj2ICIiMgINiAiIjKCDYiIiIxgAyIiIiPYgIiIyAg2ICIiMmLWjuLxjdmRmbTLskud4rq/sUdV6+jtlOfTm5tUtdsXZYmzzsHLVbUrl8TFWcf4RaraE5ZujIw3XT4CZ9ihG8WTZnnF2fY/9qpqe9NyxNnIEt2oJGdQN+plYkhev/KjHlVtjCbFUWdoQlXaacnHZMVydcd4Kv6yONt/zKGqPV4gv08BgIIO+Ugbn0v3e787US3OVmX/jap2f9kucTanR77vk6kkBtB9xhwfARERkRFsQEREZAQbEBERGcEGRERERrABERGREWxARERkBBsQEREZwQZERERGsAEREZERbEBERGQEGxARERkxa2fBhR0epByyWWm5kVFx3b866Vat43goIc72Ljiuqj3cLp97ljt0UFXbitaJs4P+farai4NlqvzEMvnvOc5YWFV7+GizONtpr1TVzht/TZz15lSparsy/6jKt7S3irOxtBFVbU+lfE5aeKxfVdsF+bGSDL6vqu0My8/lN6IxVe3r47rjsM+Sz47LyZfP3gOAI/3ymZHDQx2q2gPp8n3vXKqYBRcHcPTMOT4CIiIiI9iAiIjICDYgIiIygg2IiIiMYAMiIiIj2ICIiMgINiAiIjKCDYiIiIxgAyIiIiPYgIiIyIhZO4onP2MUWRmyMTjRmHzMRlbtkGod9qIMcTYZWKmq7UzvFGf/ONyuqj388rA4++W8v1HVLvvfcVU+kmMXZ0eOj6tqHz8iH2f0R7du/I3vLfnYmeFwl6p2WYFudE+uS36M90Xk46MA4J0J+f5cmK5bdyQsH08VHg6qaldmysflfPHYIlXt+F8Vq/LZYflteHRgQFW7r0O+P6Oxj1S1iyb6xNnQYI44axNOG+IjICIiMoINiIiIjFA3oNdffx3XX389/H4/bDYbnnnmmSnX33rrrbDZbFMumzZtmq71EhHRPKFuQOFwGLW1tdixY8dpM5s2bUJvb+/k5cknnzynRRIR0fyjfhHC5s2bsXnz5s/NuFwu+Hy+s14UERHNfzPyHNC+fftQXFyMpUuX4q677sLQ0OlfeRaNRhEKhaZciIho/pv2BrRp0yb8/Oc/x969e/Hv//7vaGpqwubNm5FMnvp1eY2NjfB4PJOX8vLy6V4SERHNQtP+PqBbbrll8t8rV65ETU0NFi1ahH379mHdunWfyW/fvh3btm2b/DoUCrEJERFdAGb8ZdgLFy5EYWEh2traTnm9y+VCbm7ulAsREc1/M96Auru7MTQ0hNLS0pn+UURENIeo/wQ3NjY25dFMR0cHDh06hPz8fOTn5+PBBx/Eli1b4PP50N7ejm9961uorq7Gxo0bp3XhREQ0t6kb0MGDB3HttddOfv3J8zdbt27Fzp07cfjwYfzXf/0XRkZG4Pf7sWHDBvzLv/wLXC6X6uekrBhSlmyGWI7fLa47cUw346l6eZY4W2rJ514BwO8iheLs0mL5NgLARLF8Flz+xfJ5UADQF7Gp8o7uPHE2lhhT1Q7nyefpJS35OgDgN4lWcTb/Vd3zlr6bdWux0uT5ZVVeXW37oDibH5PPAwOAYFmJOOvuzlbVPpaXEmdLVyxR1U4l5ec9AGT2ys/99oRulqJ3QD6TsCuqu0sfzVoozuYXnBRnE3EAH545p25Aa9euhWWdfgDkSy+9pC1JREQXIM6CIyIiI9iAiIjICDYgIiIygg2IiIiMYAMiIiIj2ICIiMgINiAiIjKCDYiIiIxgAyIiIiPYgIiIyIhp/zyg6TIcCSBiyxBlSxQzvvJrC1TriHfIPx6iepV8rhIAeI+0i7OHc3tVtWPd8mx8MF9Ve7RMPiMNABZmVIiz1oRuLXlZXxBn3x7Q3YY1TvkE955c+Uw6ABjteEeVz8xYIM5G/1dQVTuxX/57aHfl6T/d+FRckM+CO+6RzzwDgMiQfL5k4clDqtrDnnFVPpkpnx03dlh3G3YOy2c1dkYjqtrOpPxYyYzIz824cN4dHwEREZERbEBERGQEGxARERnBBkREREawARERkRFsQEREZAQbEBERGcEGRERERrABERGREWxARERkxKwdxROOnUTSLhu1kZUuH8VT0ZOtWodrSY4464RNVbv8hHxEze+7TqhqhwctcfbkgmOq2kmrVpUfTsnXfswaVtXuDPWIs9Uh3f7pWiYfxZPT7VbVnrBFVXnLLs/nfJBQ1fa45eOpAqMTqtoTdvkYmdi47jbsG5EfK12LBlS1C964TJUfWSgfrzNyLKSrPSYf85OVEVPVHhuT56OV8mwiLjsG+QiIiIiMYAMiIiIj2ICIiMgINiAiIjKCDYiIiIxgAyIiIiPYgIiIyAg2ICIiMoINiIiIjGADIiIiI9iAiIjIiFk7Cy5tJA9pkQxRtiDlFNe1XbFCtY5YRN6j48XymU0A0H9xvzibc1I+8wwAxvrlc5sql9arao++d1iV78tbLs72RHW1i1eUibPdzUlV7YXjmeLs4KIWVe2BAd1Mwt72EXE2b0J+mwBAeNmgOBtr1d1ldFR3i7PuCd1tklcsu38AACQvUdX+48rjqnz+AfmxFU3FVbVtQ/LbcKhAN09PMzsu1Sa/v0olZbcHHwEREZERbEBERGQEGxARERnBBkREREawARERkRFsQEREZAQbEBERGcEGRERERrABERGREWxARERkxKwdxZNVVonMTNkoFGdGvrius7BYtQ4/5Pl4oUNV25GyibNZKzeqao9dtF+cTfPrxvx4x12qvNOTEmdzey5V1T6aLq89UXhMVduZLh/14hxepKqdrBhQ5eNlYXHWbg/p1hKVj5FJFOuOcXfAL86WlBWoahd2yMflhLLfUdUuCpWr8n0Zw+LshCeqqj3cI7+fCA/JR+sAQLBXfi4v8MnvZ1OJOIB3z5jjIyAiIjJC1YAaGxtxxRVXwO12o7i4GDfeeCNaW1unZCKRCBoaGlBQUICcnBxs2bIFfX1907poIiKa+1QNqKmpCQ0NDWhubsbLL7+MeDyODRs2IBz+858H7rvvPjz33HN4+umn0dTUhJ6eHtx0003TvnAiIprbVM8Bvfjii1O+3rVrF4qLi9HS0oI1a9YgGAzi8ccfx+7du3HdddcBAJ544glcfPHFaG5uxpVXXjl9KyciojntnJ4DCgaDAID8/I+fnGppaUE8Hsf69esnM8uWLUNFRQX27z/1k+LRaBShUGjKhYiI5r+zbkCpVAr33nsvrrrqKqxY8fGHvAUCATidTni93inZkpISBAKBU9ZpbGyEx+OZvJSX6159QkREc9NZN6CGhga89957eOqpp85pAdu3b0cwGJy8dHV1nVM9IiKaG87qfUB33303nn/+ebz++usoK/vzx//6fD7EYjGMjIxMeRTU19cHn893yloulwsul+59JURENPepHgFZloW7774be/bswauvvoqqqqop19fV1cHhcGDv3r2T32ttbUVnZyfq6+unZ8VERDQvqB4BNTQ0YPfu3Xj22Wfhdrsnn9fxeDzIzMyEx+PBbbfdhm3btiE/Px+5ubm45557UF9fz1fAERHRFKoGtHPnTgDA2rVrp3z/iSeewK233goA+NGPfoS0tDRs2bIF0WgUGzduxM9+9rNpWSwREc0fqgZkWdYZMxkZGdixYwd27Nhx1osCAH80E1lpWaJsdolTXDevw6taR/jUT12dkndcvg4AsAdyxdnsgTZV7eGhanHW7ZfPPAOAIfuQKu8YkM+QWpAZVNXOS8sTZ3tKZLMFJwUS4uhYbr+qdKg7R5X3V1eIsydGj6lqpx+W13YW6I7DnBXyfe8KymeeAYD9EvmcOcdYkap2tPuEKt8VkM9THE1OqGpP4Jg4m5lWo6qdcI6IsyPycXdIJmXnDmfBERGREWxARERkBBsQEREZwQZERERGsAEREZERbEBERGQEGxARERnBBkREREawARERkRFsQEREZMRZfRzD+dA3GkVmXNYf007KP87huEs3YqMyQz4yZSA5qqqdGpLPtjhuV8wEAmDPjImz776mG62zau1KVX4wLB+vkzPmVtXuj8tv87Qx3e9bIxH5eJW+eImqdmfyHVV+tHdEnM1JykfrAEDUJz8ncj8cU9UuTsbF2fHqXlXtE+/Kj6sFlm4MU9+E7liJRU6Ks+OBcVXtk0N2cTZqe1tV22aXjTsDgEVF8lFJiYQNOHLmHB8BERGREWxARERkBBsQEREZwQZERERGsAEREZERbEBERGQEGxARERnBBkREREawARERkRFsQEREZAQbEBERGTFrZ8HZ7B7xnKLEuHwW3OJe+Yw0AOjPToiztsMjqtpDDkuc9Q7o1t09Lp8flbd8oaq2c0h+ewNAgbdUnB2u1/1OVNQWEGeTubp5YB1B+Sy4RI58ZiAAVFtLVfkvlq4WZ23FnaravW/L989Q/puq2sFx+fywrOO6uyNHXH6bDy0IqWpHsECVz0aXOGtlym8TABixyc+JzKRHVTs7Kj8nJobkc/0SyaQox0dARERkBBsQEREZwQZERERGsAEREZERbEBERGQEGxARERnBBkREREawARERkRFsQEREZAQbEBERGTFrR/Hkl+QiKytblJ2YCIvr7i0eV61j2ViBOBtYnFLVXj4mz76Q1I2/uSwmL96eXa6q7bfLRwgBQLRSPkaoOlGkqt29zCHOWphQ1e61y0fUXHRSngWARJl8VBIA5JRExVl/sW60Unn5UXH2rXdzVbWz+v4gznaWeVW1aydWirPhyy9T1XaFgqr86IIvi7OBo/KxPQDgu8wtzvZ+OKqqXXpFrThb0PKhOBuNRfGHD98+Y46PgIiIyAg2ICIiMoINiIiIjGADIiIiI9iAiIjICDYgIiIygg2IiIiMYAMiIiIj2ICIiMgINiAiIjKCDYiIiIyYtbPgErY4Era4KOtxZYrr1uXKZ7sBgC0un3tWm+lT1T46elKcrc+SZwGgzy+77QDg2uGIqnYqQzcLzh+vFGcnXPK5cQBQjDxx1t2fpaqdyisTZwfSdXMAL53QzY6L2J3ibOV4iap2e6JTnL2k5iJVbdtAnThbnH5EVTvUI58BWZvhVdXOtS1Q5Qdz5bMXW1OyGZefGMkJiLMLh5eoartsNnFWc9ZL71H4CIiIiIxQNaDGxkZcccUVcLvdKC4uxo033ojW1tYpmbVr18Jms0253HnnndO6aCIimvtUDaipqQkNDQ1obm7Gyy+/jHg8jg0bNiAcnvpQ+Pbbb0dvb+/k5ZFHHpnWRRMR0dyneg7oxRdfnPL1rl27UFxcjJaWFqxZs2by+1lZWfD5dM+HEBHRheWcngMKBj/+0Kb8/Pwp3//FL36BwsJCrFixAtu3b8f4+Ok/BC4ajSIUCk25EBHR/HfWr4JLpVK49957cdVVV2HFihWT3//a176GyspK+P1+HD58GN/+9rfR2tqKX//616es09jYiAcffPBsl0FERHPUWTeghoYGvPfee3jjjTemfP+OO+6Y/PfKlStRWlqKdevWob29HYsWLfpMne3bt2Pbtm2TX4dCIZSX6z4imoiI5p6zakB33303nn/+ebz++usoK/v890qsXr0aANDW1nbKBuRyueByuc5mGURENIepGpBlWbjnnnuwZ88e7Nu3D1VVVWf8P4cOHQIAlJbq3nhHRETzm6oBNTQ0YPfu3Xj22WfhdrsRCHz8Dl2Px4PMzEy0t7dj9+7d+PKXv4yCggIcPnwY9913H9asWYOampoZ2QAiIpqbVA1o586dAD5+s+lfeuKJJ3DrrbfC6XTilVdewaOPPopwOIzy8nJs2bIF3/3ud6dtwUREND+o/wT3ecrLy9HU1HROC/pEIjeGRJZweZZ8Hpjl183sGk/JZ6qNDo+qakdj8nwofFxVO+nxiLPHoJszV5Qtn0sGAAPefnE2GnOrag/HTv8S/0+7ulC375fa/OJs9oCqNGyRNlW+ekL+jokTBUdVtX0lDnG2q/fMf3b/S3lL5XPM3P3yYxYAKi5fLs6mlE8zjyeiqnzG+AlxNjdtQlU7NpQrzp7s083TQ5H8fAsXyefjRaOyaXCcBUdEREawARERkRFsQEREZAQbEBERGcEGRERERrABERGREWxARERkBBsQEREZwQZERERGsAEREZERZ/15QDPNg1xkIVuU9Q1kiutOuAtU60haw+Js/Lhu1EuJ4mMo4iUXqWoH/nBYnA1fKR/1AQBD+3WjeHxe+f7xJHVjSuKJ/DOH/qSlW/dpu8tq5OvOtdtVtQu9uuNwKEM+EiojXbc/x/uC4mxRru531pRNfrukF9epaofjg+Ks+6R83BAAjAT3qfJjriXibM/RXlXt5Jh8ZNfxyJiqdt5vRsTZtOU94mwsGpPVFFckIiKaRmxARERkBBsQEREZwQZERERGsAEREZERbEBERGQEGxARERnBBkREREawARERkRFsQEREZAQbEBERGTFrZ8E5ir1w5uSIskGffDMGR6OqdeSNyObRAUDKr7s5s+MD4uyEU74OAMi+eoU4OxjWzbCzWeOqfLjrhDh7PL9EVTtYLF+Lc0g3C66vXT6zq6JMN2ssapfPMQOAwowicTbdsqlqZ3vl2dCI7jYs9C8QZ7sTYVVte0h2/wAAlkM2m+wTcdsiVb6ru02cHf7wQ1Xt4wOK+6xFharaJ3JHxNkVrlpxNgrZmvkIiIiIjGADIiIiI9iAiIjICDYgIiIygg2IiIiMYAMiIiIj2ICIiMgINiAiIjKCDYiIiIxgAyIiIiNm7Sie6LAD9phTlM3Jk49BWRbXreMk5LUrS2Tr/URwtEqczR8fVtXODFSKs4suHVHVbusbVeWH4/nirPMPE6raX7isWJztsuv2j39Mns8cGVHVLrPXqPI2x0fibGREN9ImnpJvZ3aGS1U7NNAvztpO6vaPLSE/VoqS8uMEAMLhk6r8eHuPOBu3e1W1HXnykV39w7o7uIq4/D4o6pCPj4pGZaOP+AiIiIiMYAMiIiIj2ICIiMgINiAiIjKCDYiIiIxgAyIiIiPYgIiIyAg2ICIiMoINiIiIjGADIiIiI9iAiIjIiFk7C87KnICVaRdl3Sfc4roD+bKanyj2yvP2PF3tCpe8/7elMlW1y5JZ4uwJS7fu6jUZqvx7EfnsuOqYTVX7uFc+s6vSEVXVDtqyxdnSnBJVbWfaEVU+hUJxNj0ln18IALFwQJwdTCjXPShfS8y3QlXbMSSfS3cyp1VVO5pKqPK5E/L5e3FHr6p2Z5olzqbFdedyNCcozmaMymf12WJJUY6PgIiIyAhVA9q5cydqamqQm5uL3Nxc1NfX44UXXpi8PhKJoKGhAQUFBcjJycGWLVvQ19c37YsmIqK5T9WAysrK8PDDD6OlpQUHDx7EddddhxtuuAHvv/8+AOC+++7Dc889h6effhpNTU3o6enBTTfdNCMLJyKiuU31HND1118/5et/+7d/w86dO9Hc3IyysjI8/vjj2L17N6677joAwBNPPIGLL74Yzc3NuPLKK6dv1URENOed9XNAyWQSTz31FMLhMOrr69HS0oJ4PI7169dPZpYtW4aKigrs37//tHWi0ShCodCUCxERzX/qBvTuu+8iJycHLpcLd955J/bs2YPly5cjEAjA6XTC6/VOyZeUlCAQOP2rbBobG+HxeCYv5eXl6o0gIqK5R92Ali5dikOHDuHAgQO46667sHXrVnzwwQdnvYDt27cjGAxOXrq6us66FhERzR3q9wE5nU5UV1cDAOrq6vCHP/wBP/7xj3HzzTcjFothZGRkyqOgvr4++Hy+09ZzuVxwuXSfM09ERHPfOb8PKJVKIRqNoq6uDg6HA3v37p28rrW1FZ2dnaivrz/XH0NERPOM6hHQ9u3bsXnzZlRUVGB0dBS7d+/Gvn378NJLL8Hj8eC2227Dtm3bkJ+fj9zcXNxzzz2or6/nK+CIiOgzVA2ov78ff/u3f4ve3l54PB7U1NTgpZdewpe+9CUAwI9+9COkpaVhy5YtiEaj2LhxI372s5+d1cIigQjSsmRjJUI++fiWSLpujIzTlxJn40PyURUAYJXKRwgV9ur+Wmqrk7+aMHtQ98rDMbt83QCw4OS4OBup0Y3LKekaE2ftoWJV7cXVw/JwTHdcjcKrysez5dvpRlxVu88hP7ZO9pz+z+mnUjgkH1FkJWTjWybzxfLzviM4oqptD+hGQnmX1Imzx062qGpnt8qPw/yQfGwPAAzbJ8TZown5bRKPy45B1b3a448//rnXZ2RkYMeOHdixY4emLBERXYA4C46IiIxgAyIiIiPYgIiIyAg2ICIiMoINiIiIjGADIiIiI9iAiIjICDYgIiIygg2IiIiMUE/DnmmW9fEoiYmJsPj/hMPycTnR9IRqPWOj8pvIGtON77CPOuTrGIuoatsyRxW15WNeACAsm5A0aTws35c2SzeKB+Py0SNpE7rtdCrWjTTdGBkn5McsAMQtxW2Y0t2G4bh8HMv4uDwLAOEJ+Rgmy6kbIxMPy8+38XHd+WOf0J3LEzb5SRGN6EYlxeLy+yybcATOJ+Ipxf1bIiavm/h4HZ/cn5+OzTpT4jzr7u7mh9IREc0DXV1dKCsrO+31s64BpVIp9PT0wO12w2b7828hoVAI5eXl6OrqQm5ursEVzixu5/xxIWwjwO2cb6ZjOy3LwujoKPx+P9LSTv9Mz6z7E1xaWtrndszc3Nx5vfM/we2cPy6EbQS4nfPNuW6nx+M5Y4YvQiAiIiPYgIiIyIg504BcLhceeOABuFwu00uZUdzO+eNC2EaA2znfnM/tnHUvQiAiogvDnHkERERE8wsbEBERGcEGRERERrABERGREXOmAe3YsQMXXXQRMjIysHr1avz+9783vaRp9f3vfx82m23KZdmyZaaXdU5ef/11XH/99fD7/bDZbHjmmWemXG9ZFu6//36UlpYiMzMT69evx5EjR8ws9hycaTtvvfXWz+zbTZs2mVnsWWpsbMQVV1wBt9uN4uJi3HjjjWhtbZ2SiUQiaGhoQEFBAXJycrBlyxb09fUZWvHZkWzn2rVrP7M/77zzTkMrPjs7d+5ETU3N5JtN6+vr8cILL0xef7725ZxoQL/85S+xbds2PPDAA3jrrbdQW1uLjRs3or+/3/TSptUll1yC3t7eycsbb7xheknnJBwOo7a2Fjt27Djl9Y888gh+8pOf4LHHHsOBAweQnZ2NjRs3IhLRDY407UzbCQCbNm2asm+ffPLJ87jCc9fU1ISGhgY0Nzfj5ZdfRjwex4YNGxD+i4Gt9913H5577jk8/fTTaGpqQk9PD2666SaDq9aTbCcA3H777VP25yOPPGJoxWenrKwMDz/8MFpaWnDw4EFcd911uOGGG/D+++8DOI/70poDVq1aZTU0NEx+nUwmLb/fbzU2Nhpc1fR64IEHrNraWtPLmDEArD179kx+nUqlLJ/PZ/3gBz+Y/N7IyIjlcrmsJ5980sAKp8ent9OyLGvr1q3WDTfcYGQ9M6W/v98CYDU1NVmW9fG+czgc1tNPPz2Z+fDDDy0A1v79+00t85x9ejsty7KuueYa6x/+4R/MLWqG5OXlWf/xH/9xXvflrH8EFIvF0NLSgvXr109+Ly0tDevXr8f+/fsNrmz6HTlyBH6/HwsXLsTXv/51dHZ2ml7SjOno6EAgEJiyXz0eD1avXj3v9isA7Nu3D8XFxVi6dCnuuusuDA0NmV7SOQkGgwCA/Px8AEBLSwvi8fiU/bls2TJUVFTM6f356e38xC9+8QsUFhZixYoV2L59O8bH5R87Mdskk0k89dRTCIfDqK+vP6/7ctYNI/20wcFBJJNJlJSUTPl+SUkJPvroI0Ormn6rV6/Grl27sHTpUvT29uLBBx/EF7/4Rbz33ntwu92mlzftAoEAAJxyv35y3XyxadMm3HTTTaiqqkJ7ezv++Z//GZs3b8b+/fthtys/XGkWSKVSuPfee3HVVVdhxYoVAD7en06nE16vd0p2Lu/PU20nAHzta19DZWUl/H4/Dh8+jG9/+9tobW3Fr3/9a4Or1Xv33XdRX1+PSCSCnJwc7NmzB8uXL8ehQ4fO276c9Q3oQrF58+bJf9fU1GD16tWorKzEr371K9x2220GV0bn6pZbbpn898qVK1FTU4NFixZh3759WLduncGVnZ2Ghga89957c/45yjM53Xbecccdk/9euXIlSktLsW7dOrS3t2PRokXne5lnbenSpTh06BCCwSD++7//G1u3bkVTU9N5XcOs/xNcYWEh7Hb7Z16B0dfXB5/PZ2hVM8/r9WLJkiVoa2szvZQZ8cm+u9D2KwAsXLgQhYWFc3Lf3n333Xj++efx2muvTfnYFJ/Ph1gshpGRkSn5ubo/T7edp7J69WoAmHP70+l0orq6GnV1dWhsbERtbS1+/OMfn9d9OesbkNPpRF1dHfbu3Tv5vVQqhb1796K+vt7gymbW2NgY2tvbUVpaanopM6Kqqgo+n2/Kfg2FQjhw4MC83q/Ax5/6OzQ0NKf2rWVZuPvuu7Fnzx68+uqrqKqqmnJ9XV0dHA7HlP3Z2tqKzs7OObU/z7Sdp3Lo0CEAmFP781RSqRSi0ej53ZfT+pKGGfLUU09ZLpfL2rVrl/XBBx9Yd9xxh+X1eq1AIGB6adPmH//xH619+/ZZHR0d1u9+9ztr/fr1VmFhodXf3296aWdtdHTUevvtt623337bAmD98Ic/tN5++23r+PHjlmVZ1sMPP2x5vV7r2WeftQ4fPmzdcMMNVlVVlTUxMWF45Tqft52jo6PWN7/5TWv//v1WR0eH9corr1iXX365tXjxYisSiZheuthdd91leTwea9++fVZvb+/kZXx8fDJz5513WhUVFdarr75qHTx40Kqvr7fq6+sNrlrvTNvZ1tZmPfTQQ9bBgwetjo4O69lnn7UWLlxorVmzxvDKdb7zne9YTU1NVkdHh3X48GHrO9/5jmWz2azf/va3lmWdv305JxqQZVnWT3/6U6uiosJyOp3WqlWrrObmZtNLmlY333yzVVpaajmdTmvBggXWzTffbLW1tZle1jl57bXXLACfuWzdutWyrI9fiv29733PKikpsVwul7Vu3TqrtbXV7KLPwudt5/j4uLVhwwarqKjIcjgcVmVlpXX77bfPuV+eTrV9AKwnnnhiMjMxMWH9/d//vZWXl2dlZWVZX/nKV6ze3l5ziz4LZ9rOzs5Oa82aNVZ+fr7lcrms6upq65/+6Z+sYDBoduFKf/d3f2dVVlZaTqfTKioqstatWzfZfCzr/O1LfhwDEREZMeufAyIiovmJDYiIiIxgAyIiIiPYgIiIyAg2ICIiMoINiIiIjGADIiIiI9iAiIjICDYgIiIygg2IiIiMYAMiIiIj2ICIiMiI/w8WwY2fZJsD0wAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "noise = tf.random.normal(shape=(1,100))\n",
        "random_number = tf.random.uniform(shape=[1,], minval=0, maxval=10, dtype=tf.int32)\n",
        "test = generator.predict((noise,random_number))\n",
        "print(random_number)\n",
        "plt.imshow(test.squeeze())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_r4IEg2iBLvP"
      },
      "outputs": [],
      "source": [
        "NOISE_DIM = 100\n",
        "GP_WEIGHT = 10\n",
        "\n",
        "\n",
        "#@tf.function\n",
        "def train_step(images,digits):\n",
        "\n",
        "\n",
        "    for i in range(3):\n",
        "      with tf.GradientTape() as disc_tapeU:\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        real_outputU = discriminatorU((images,digits), training=True)\n",
        "        fake_outputU = discriminatorU((generated_images,digits), training=True)\n",
        "        disc_lossU = cross_entropy(tf.ones_like(real_outputU), real_outputU)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      gradients_of_discriminatorU = disc_tapeU.gradient(disc_lossU, discriminatorU.trainable_variables)\n",
        "      discriminatorU_optimizer.apply_gradients(zip(gradients_of_discriminatorU, discriminatorU.trainable_variables))\n",
        "      if i == 0:\n",
        "        weights = discriminatorU.get_weights()\n",
        "\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tapeW:\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        real_outputW = discriminatorW((images,digits), training=True)\n",
        "        fake_outputW = discriminatorW((generated_images,digits), training=True)\n",
        "        real_outputU = discriminatorU((images,digits), training=True)\n",
        "        fake_outputU = discriminatorU((generated_images,digits), training=True)\n",
        "        disc_lossW = discriminator_lossW(real_outputW, fake_outputW)\n",
        "\n",
        "\n",
        "        gen_lossU = cross_entropy(tf.ones_like(fake_outputU), fake_outputU)\n",
        "        gen_lossW = generator_lossW(fake_outputW)\n",
        "        gen_loss = gen_lossU#+gen_lossW\n",
        "\n",
        "        gp = gradient_penalty(images, generated_images, digits)\n",
        "        disc_lossW += gp * GP_WEIGHT\n",
        "\n",
        "\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    gradients_of_discriminatorW = disc_tapeW.gradient(disc_lossW, discriminatorW.trainable_variables)\n",
        "    discriminatorW_optimizer.apply_gradients(zip(gradients_of_discriminatorW, discriminatorW.trainable_variables))\n",
        "\n",
        "    discriminatorU.set_weights(weights)\n",
        "\n",
        "    tf.print(\"disc_lossW\",disc_lossW,'disc_lossU',disc_lossU,'gen_lossU',gen_lossU,'gen_lossW',gen_lossW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhuRFc0ro5T_"
      },
      "outputs": [],
      "source": [
        "print(np.min(x_train2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojIuJFIAybro"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}