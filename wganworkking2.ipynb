{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aetev/Learning-stuff-/blob/main/wganworkking2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xI7rEeMMgDQI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qgyl_WtbgO5k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62f90ccb-f9e5-463a-836c-91ddaeb1dddc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 4s 0us/step\n"
          ]
        }
      ],
      "source": [
        "#(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "kik7wQ1qgOV-"
      },
      "outputs": [],
      "source": [
        "def make_generator_model():\n",
        "\n",
        "    input_noise = layers.Input(shape=(100,))\n",
        "    input_digit = layers.Input(shape=(1,))\n",
        "    digit = layers.Embedding(10, 10)(input_digit)\n",
        "    digit = layers.Flatten()(digit)\n",
        "\n",
        "    x = layers.concatenate([input_noise, digit])\n",
        "\n",
        "    x = layers.Dense(8*8*64,activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.Reshape((8, 8, 64))(x)\n",
        "\n",
        "\n",
        "    x = layers.Conv2DTranspose(64,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv2DTranspose(64,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv2D(3,3,1,padding='same',activation='sigmoid')(x)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=(input_noise,input_digit), outputs=x)\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "\n",
        "def make_discriminator_model():\n",
        "    input_img = layers.Input(shape=(32,32,3))\n",
        "    input_digit = layers.Input(shape=(1,))\n",
        "    digit = layers.Embedding(10, 5)(input_digit)\n",
        "    digit = layers.Flatten()(digit)\n",
        "\n",
        "    x = layers.Conv2D(64, 5, 2, padding='same', activation='LeakyReLU', kernel_regularizer=tf.keras.regularizers.l2(0.01))(input_img)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv2D(64, 3, 2, padding='same', activation='LeakyReLU', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv2D(64, 3, 2, padding='same', activation='LeakyReLU', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv2D(64, 3, 2, padding='same', activation='LeakyReLU', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "    x = layers.Flatten()(x)\n",
        "\n",
        "    x = layers.concatenate([x, digit])\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Dense(128, activation='LeakyReLU', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    dense_output = layers.Dense(64, activation='LeakyReLU', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    dense_output = layers.Dense(1, activation=None, kernel_regularizer=tf.keras.regularizers.l2(0.01))(dense_output)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=(input_img, input_digit), outputs=dense_output)\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "qzdSabqdVu_H"
      },
      "outputs": [],
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lS0DF8rjhHdY",
        "outputId": "1ce80bbd-8e7e-4b51-ac15-659b90de617e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_12 (InputLayer)       [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " embedding_5 (Embedding)     (None, 1, 10)                100       ['input_12[0][0]']            \n",
            "                                                                                                  \n",
            " input_11 (InputLayer)       [(None, 100)]                0         []                            \n",
            "                                                                                                  \n",
            " flatten_8 (Flatten)         (None, 10)                   0         ['embedding_5[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate  (None, 110)                  0         ['input_11[0][0]',            \n",
            " )                                                                   'flatten_8[0][0]']           \n",
            "                                                                                                  \n",
            " dense_11 (Dense)            (None, 4096)                 454656    ['concatenate_5[0][0]']       \n",
            "                                                                                                  \n",
            " reshape_2 (Reshape)         (None, 8, 8, 64)             0         ['dense_11[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_transpose_4 (Conv2D  (None, 16, 16, 64)           36928     ['reshape_2[0][0]']           \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " batch_normalization_22 (Ba  (None, 16, 16, 64)           256       ['conv2d_transpose_4[0][0]']  \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_5 (Conv2D  (None, 32, 32, 64)           36928     ['batch_normalization_22[0][0]\n",
            " Transpose)                                                         ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_23 (Ba  (None, 32, 32, 64)           256       ['conv2d_transpose_5[0][0]']  \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 32, 32, 3)            1731      ['batch_normalization_23[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 530855 (2.03 MB)\n",
            "Trainable params: 530599 (2.02 MB)\n",
            "Non-trainable params: 256 (1.00 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "generator = make_generator_model()\n",
        "generator_optimizer = tf.keras.optimizers.Adam(0.0004)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "GJxNxRSHkWfl"
      },
      "outputs": [],
      "source": [
        "discriminatorW = make_discriminator_model()\n",
        "discriminatorW_optimizer = tf.keras.optimizers.Adam(0.0004)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "6cDVGo73jfqZ"
      },
      "outputs": [],
      "source": [
        "discriminatorU = make_discriminator_model()\n",
        "discriminatorU_optimizer = tf.keras.optimizers.Adam(0.0004)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "DYQpIZyEgSlN"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "@tf.function\n",
        "def discriminator_lossW(real_output, fake_output):\n",
        "    real_loss = tf.reduce_mean(real_output)\n",
        "    fake_loss = tf.reduce_mean(fake_output)\n",
        "    total_loss = fake_loss - real_loss\n",
        "    return total_loss\n",
        "\n",
        "@tf.function\n",
        "def generator_lossW(fake_output):\n",
        "    return -tf.reduce_mean(fake_output)\n",
        "\n",
        "@tf.function\n",
        "def gradient_penalty(real_images, fake_images,digits):\n",
        "    alpha = tf.random.uniform([BATCH_SIZE, 1, 1, 1], 0., 1.)\n",
        "    real_images, fake_images = tf.cast(real_images, tf.float32), tf.cast(fake_images, tf.float32)\n",
        "    interpolated_images = alpha * real_images + ((1 - alpha) * fake_images)\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(interpolated_images)\n",
        "        pred = discriminatorW((interpolated_images,digits), training=True)\n",
        "    gradients = tape.gradient(pred, [interpolated_images])[0]\n",
        "    norm = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis=[1, 2, 3]))\n",
        "    gp = tf.reduce_mean((norm - 1.)**2)\n",
        "    return gp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def r1_regularizer(real_images,digit):\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(real_images)\n",
        "        output = discriminatorU((real_images,digit))\n",
        "    gradients = tape.gradient(output, real_images)\n",
        "    r1_reg = tf.reduce_sum(tf.square(gradients))\n",
        "    return r1_reg"
      ],
      "metadata": {
        "id": "YKXS0vax1Kz5"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "4rgSqI2sf1sT"
      },
      "outputs": [],
      "source": [
        "\n",
        "@tf.function\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "lambda_r1 = .01\n",
        "@tf.function\n",
        "def discriminator_loss(real_output, fake_output, real_images, digit):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    r1_reg = r1_regularizer(real_images,digit)\n",
        "    real_loss = tf.cast(real_loss, tf.float32)\n",
        "    fake_loss = tf.cast(fake_loss, tf.float32)\n",
        "    r1_reg = tf.cast(r1_reg, tf.float32)\n",
        "    total_loss = real_loss + fake_loss + lambda_r1 * r1_reg\n",
        "    total_loss = real_loss + fake_loss + lambda_r1 * r1_reg  # Add the regularization term\n",
        "    return total_loss\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def generator_loss(fake_output):\n",
        "    return -tf.reduce_mean(fake_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilj-woz7fSum"
      },
      "outputs": [],
      "source": [
        "NOISE_DIM = 100\n",
        "\n",
        "@tf.function\n",
        "def train_step(real_images,digits):\n",
        "    with tf.GradientTape() as disc_tape, tf.GradientTape() as gen_tape:\n",
        "        # Generate random noise\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "\n",
        "        # Generate fake images with the generator\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        # Discriminator loss calculation\n",
        "        real_output = discriminatorU((real_images,digits), training=True)\n",
        "        fake_output = discriminatorU((generated_images,digits), training=True)\n",
        "        d_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "        # Generator loss calculation\n",
        "        g_loss = generator_loss(fake_output)\n",
        "\n",
        "    # Update generator and discriminator variables\n",
        "    gradients_of_discriminator = disc_tape.gradient(d_loss, discriminatorU.trainable_variables)\n",
        "    gradients_of_generator = gen_tape.gradient(g_loss, generator.trainable_variables)\n",
        "    discriminatorU_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminatorU.trainable_variables))\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    tf.print(\"disc_loss\",d_loss,'gen_loss',g_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "8AuOxPdvp1hu"
      },
      "outputs": [],
      "source": [
        "NOISE_DIM = 100\n",
        "threshold = 0.5\n",
        "#@tf.function\n",
        "def train_step(real_images,digits):\n",
        "\n",
        "    for i in range(5):\n",
        "      with tf.GradientTape() as disc_tape:\n",
        "        # Generate random noise\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "\n",
        "        # Generate fake images with the generator\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        # Discriminator loss calculation\n",
        "        real_output = discriminatorU((real_images,digits), training=True)\n",
        "        fake_output = discriminatorU((generated_images,digits), training=True)\n",
        "        d_loss = discriminator_loss(real_output, fake_output,real_images,digits)\n",
        "\n",
        "\n",
        "      gradients_of_discriminator = disc_tape.gradient(d_loss, discriminatorU.trainable_variables)\n",
        "      discriminatorU_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminatorU.trainable_variables))\n",
        "\n",
        "      if i == 0:\n",
        "        weights = discriminatorU.get_weights()\n",
        "\n",
        "    with tf.GradientTape() as gen_tape:\n",
        "      # Generate random noise\n",
        "      noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "\n",
        "      # Generate fake images with the generator\n",
        "      generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "      fake_output = discriminatorU((generated_images,digits), training=True)\n",
        "\n",
        "       # Generator loss calculation\n",
        "      g_loss = generator_loss(fake_output)\n",
        "\n",
        "    # Update generator and discriminator variables\n",
        "\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(g_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    discriminatorU.set_weights(weights)\n",
        "\n",
        "    tf.print(\"disc_loss\",d_loss,'gen_loss',g_loss)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cP3-wZztEeaE"
      },
      "outputs": [],
      "source": [
        "NOISE_DIM = 100\n",
        "GP_WEIGHT = 10\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def train_step(images,digits):\n",
        "\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tapeW:\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        real_outputW = discriminatorW((images,digits), training=True)\n",
        "        fake_outputW = discriminatorW((generated_images,digits), training=True)\n",
        "\n",
        "        disc_lossW = discriminator_lossW(real_outputW, fake_outputW)\n",
        "\n",
        "        gen_lossW = generator_lossW(fake_outputW)\n",
        "        gen_loss = gen_lossW\n",
        "\n",
        "        gp = gradient_penalty(images, generated_images, digits)\n",
        "        disc_lossW += gp * GP_WEIGHT\n",
        "\n",
        "\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    gradients_of_discriminatorW = disc_tapeW.gradient(disc_lossW, discriminatorW.trainable_variables)\n",
        "    discriminatorW_optimizer.apply_gradients(zip(gradients_of_discriminatorW, discriminatorW.trainable_variables))\n",
        "\n",
        "\n",
        "    tf.print(\"disc_lossW\",disc_lossW,'gen_lossW',gen_lossW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Sx_KbIfjiogE"
      },
      "outputs": [],
      "source": [
        "def train(dataset,y_train, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    for batch in range(len(dataset) // BATCH_SIZE):\n",
        "\n",
        "            target_images = dataset[batch * BATCH_SIZE: (batch+1) * BATCH_SIZE]\n",
        "            digits = y_train[batch * BATCH_SIZE: (batch+1) * BATCH_SIZE]\n",
        "\n",
        "            train_step(target_images,digits)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      print(epoch)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 789
        },
        "id": "IWp_3RkPg248",
        "outputId": "af59384d-5fcc-44f4-91cb-4755ea0256a7",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "disc_loss 0.350029 gen_loss 2.02937555\n",
            "disc_loss 0.34153229 gen_loss 1.94889224\n",
            "disc_loss 0.341673672 gen_loss 1.95526934\n",
            "disc_loss 0.350124806 gen_loss 1.94785\n",
            "disc_loss 0.328301907 gen_loss 2.03085899\n",
            "disc_loss 0.325354487 gen_loss 1.99654758\n",
            "disc_loss 0.327342659 gen_loss 2.13690042\n",
            "disc_loss 0.336910188 gen_loss 2.10558844\n",
            "disc_loss 0.332288086 gen_loss 1.99695313\n",
            "disc_loss 0.312247097 gen_loss 2.09886694\n",
            "disc_loss 0.312687576 gen_loss 2.15179539\n",
            "disc_loss 0.336143821 gen_loss 2.12655973\n",
            "disc_loss 0.315185845 gen_loss 2.12178659\n",
            "disc_loss 0.342726588 gen_loss 2.08521724\n",
            "disc_loss 0.31584239 gen_loss 2.14156413\n",
            "disc_loss 0.339746743 gen_loss 2.12246156\n",
            "disc_loss 0.325568736 gen_loss 2.1206336\n",
            "disc_loss 0.323138416 gen_loss 2.06716299\n",
            "disc_loss 0.334435612 gen_loss 2.16436958\n",
            "disc_loss 0.324235022 gen_loss 2.19221115\n",
            "disc_loss 0.334741533 gen_loss 2.11639738\n",
            "disc_loss 0.350979269 gen_loss 2.16229296\n",
            "disc_loss 0.358908 gen_loss 2.15455055\n",
            "disc_loss 0.340714037 gen_loss 2.11207604\n",
            "disc_loss 0.332588702 gen_loss 2.15900612\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-07e8ee322a97>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx_train2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx_train2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_train2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-37-3e7c8cbb4ec1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, y_train, epochs)\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mdigits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdigits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Save the model every 15 epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-1c4d609a30e8>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(real_images, digits)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m       \u001b[0mgradients_of_discriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisc_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminatorU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m       \u001b[0mdiscriminatorU_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients_of_discriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminatorU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1061\u001b[0m                           for x in output_gradients]\n\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1064\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_backward_function_wrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_index\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mbackward_function_inputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m           \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m       return backward._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    790\u001b[0m           processed_args, remapped_captures)\n\u001b[1;32m    791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1347\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1348\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_call_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1457\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1458\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "EPOCHS = 100\n",
        "x_train2 = np.expand_dims(x_train, axis=-1)\n",
        "x_train2 = (x_train2 - np.min(x_train2)) / (np.max(x_train2) - np.min(x_train2))\n",
        "train(x_train2,y_train, EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "9vPp5AiDkrAF",
        "outputId": "0fc0c6d8-6e10-4ef6-c883-23e777604d8d",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 89ms/step\n",
            "tf.Tensor([7], shape=(1,), dtype=int32)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "noise = tf.random.normal(shape=(1,100))\n",
        "random_number = tf.random.uniform(shape=[1,], minval=0, maxval=10, dtype=tf.int32)\n",
        "test = generator.predict((noise,random_number))\n",
        "print(random_number)\n",
        "plt.imshow(test.squeeze())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_r4IEg2iBLvP"
      },
      "outputs": [],
      "source": [
        "NOISE_DIM = 100\n",
        "GP_WEIGHT = 10\n",
        "\n",
        "\n",
        "#@tf.function\n",
        "def train_step(images,digits):\n",
        "\n",
        "\n",
        "    for i in range(3):\n",
        "      with tf.GradientTape() as disc_tapeU:\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        real_outputU = discriminatorU((images,digits), training=True)\n",
        "        fake_outputU = discriminatorU((generated_images,digits), training=True)\n",
        "        disc_lossU = cross_entropy(tf.ones_like(real_outputU), real_outputU)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      gradients_of_discriminatorU = disc_tapeU.gradient(disc_lossU, discriminatorU.trainable_variables)\n",
        "      discriminatorU_optimizer.apply_gradients(zip(gradients_of_discriminatorU, discriminatorU.trainable_variables))\n",
        "      if i == 0:\n",
        "        weights = discriminatorU.get_weights()\n",
        "\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tapeW:\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        real_outputW = discriminatorW((images,digits), training=True)\n",
        "        fake_outputW = discriminatorW((generated_images,digits), training=True)\n",
        "        real_outputU = discriminatorU((images,digits), training=True)\n",
        "        fake_outputU = discriminatorU((generated_images,digits), training=True)\n",
        "        disc_lossW = discriminator_lossW(real_outputW, fake_outputW)\n",
        "\n",
        "\n",
        "        gen_lossU = cross_entropy(tf.ones_like(fake_outputU), fake_outputU)\n",
        "        gen_lossW = generator_lossW(fake_outputW)\n",
        "        gen_loss = gen_lossU#+gen_lossW\n",
        "\n",
        "        gp = gradient_penalty(images, generated_images, digits)\n",
        "        disc_lossW += gp * GP_WEIGHT\n",
        "\n",
        "\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    gradients_of_discriminatorW = disc_tapeW.gradient(disc_lossW, discriminatorW.trainable_variables)\n",
        "    discriminatorW_optimizer.apply_gradients(zip(gradients_of_discriminatorW, discriminatorW.trainable_variables))\n",
        "\n",
        "    discriminatorU.set_weights(weights)\n",
        "\n",
        "    tf.print(\"disc_lossW\",disc_lossW,'disc_lossU',disc_lossU,'gen_lossU',gen_lossU,'gen_lossW',gen_lossW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhuRFc0ro5T_"
      },
      "outputs": [],
      "source": [
        "print(np.min(x_train2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojIuJFIAybro"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}