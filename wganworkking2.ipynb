{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aetev/Learning-stuff-/blob/main/wganworkking2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xI7rEeMMgDQI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qgyl_WtbgO5k",
        "outputId": "62f90ccb-f9e5-463a-836c-91ddaeb1dddc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 4s 0us/step\n"
          ]
        }
      ],
      "source": [
        "#(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "kik7wQ1qgOV-"
      },
      "outputs": [],
      "source": [
        "def make_generator_model():\n",
        "\n",
        "    input_noise = layers.Input(shape=(100,))\n",
        "    input_digit = layers.Input(shape=(1,))\n",
        "    digit = layers.Embedding(10, 10)(input_digit)\n",
        "    digit = layers.Flatten()(digit)\n",
        "\n",
        "    x = layers.concatenate([input_noise, digit])\n",
        "\n",
        "    x = layers.Dense(8*8*64,activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.Reshape((8, 8, 64))(x)\n",
        "\n",
        "\n",
        "    x = layers.Conv2DTranspose(64,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv2DTranspose(64,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv2D(3,3,1,padding='same',activation='sigmoid')(x)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=(input_noise,input_digit), outputs=x)\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "\n",
        "def make_discriminator_model():\n",
        "    input_img = layers.Input(shape=(32,32,3))\n",
        "    input_digit = layers.Input(shape=(1,))\n",
        "    digit = layers.Embedding(10, 5)(input_digit)\n",
        "    digit = layers.Flatten()(digit)\n",
        "\n",
        "    x = layers.Conv2D(64, 5, 2, padding='same', activation='LeakyReLU', kernel_regularizer=tf.keras.regularizers.l2(0.01))(input_img)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv2D(64, 3, 2, padding='same', activation='LeakyReLU', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv2D(64, 3, 2, padding='same', activation='LeakyReLU', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv2D(64, 3, 2, padding='same', activation='LeakyReLU', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "    x = layers.Flatten()(x)\n",
        "\n",
        "    x = layers.concatenate([x, digit])\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Dense(128, activation='LeakyReLU', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    dense_output = layers.Dense(64, activation='LeakyReLU', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    dense_output = layers.Dense(1, activation=None, kernel_regularizer=tf.keras.regularizers.l2(0.01))(dense_output)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=(input_img, input_digit), outputs=dense_output)\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "qzdSabqdVu_H"
      },
      "outputs": [],
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lS0DF8rjhHdY",
        "outputId": "1ce80bbd-8e7e-4b51-ac15-659b90de617e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_12 (InputLayer)       [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " embedding_5 (Embedding)     (None, 1, 10)                100       ['input_12[0][0]']            \n",
            "                                                                                                  \n",
            " input_11 (InputLayer)       [(None, 100)]                0         []                            \n",
            "                                                                                                  \n",
            " flatten_8 (Flatten)         (None, 10)                   0         ['embedding_5[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate  (None, 110)                  0         ['input_11[0][0]',            \n",
            " )                                                                   'flatten_8[0][0]']           \n",
            "                                                                                                  \n",
            " dense_11 (Dense)            (None, 4096)                 454656    ['concatenate_5[0][0]']       \n",
            "                                                                                                  \n",
            " reshape_2 (Reshape)         (None, 8, 8, 64)             0         ['dense_11[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_transpose_4 (Conv2D  (None, 16, 16, 64)           36928     ['reshape_2[0][0]']           \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " batch_normalization_22 (Ba  (None, 16, 16, 64)           256       ['conv2d_transpose_4[0][0]']  \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_5 (Conv2D  (None, 32, 32, 64)           36928     ['batch_normalization_22[0][0]\n",
            " Transpose)                                                         ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_23 (Ba  (None, 32, 32, 64)           256       ['conv2d_transpose_5[0][0]']  \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 32, 32, 3)            1731      ['batch_normalization_23[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 530855 (2.03 MB)\n",
            "Trainable params: 530599 (2.02 MB)\n",
            "Non-trainable params: 256 (1.00 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "generator = make_generator_model()\n",
        "generator_optimizer = tf.keras.optimizers.Adam(0.0004)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "GJxNxRSHkWfl"
      },
      "outputs": [],
      "source": [
        "discriminatorW = make_discriminator_model()\n",
        "discriminatorW_optimizer = tf.keras.optimizers.Adam(0.0004)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "6cDVGo73jfqZ"
      },
      "outputs": [],
      "source": [
        "discriminatorU = make_discriminator_model()\n",
        "discriminatorU_optimizer = tf.keras.optimizers.Adam(0.0004)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "DYQpIZyEgSlN"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "@tf.function\n",
        "def discriminator_lossW(real_output, fake_output):\n",
        "    real_loss = tf.reduce_mean(real_output)\n",
        "    fake_loss = tf.reduce_mean(fake_output)\n",
        "    total_loss = fake_loss - real_loss\n",
        "    return total_loss\n",
        "\n",
        "@tf.function\n",
        "def generator_lossW(fake_output):\n",
        "    return -tf.reduce_mean(fake_output)\n",
        "\n",
        "@tf.function\n",
        "def gradient_penalty(real_images, fake_images,digits):\n",
        "    alpha = tf.random.uniform([BATCH_SIZE, 1, 1, 1], 0., 1.)\n",
        "    real_images, fake_images = tf.cast(real_images, tf.float32), tf.cast(fake_images, tf.float32)\n",
        "    interpolated_images = alpha * real_images + ((1 - alpha) * fake_images)\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(interpolated_images)\n",
        "        pred = discriminatorW((interpolated_images,digits), training=True)\n",
        "    gradients = tape.gradient(pred, [interpolated_images])[0]\n",
        "    norm = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis=[1, 2, 3]))\n",
        "    gp = tf.reduce_mean((norm - 1.)**2)\n",
        "    return gp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "4rgSqI2sf1sT"
      },
      "outputs": [],
      "source": [
        "\n",
        "@tf.function\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "@tf.function\n",
        "def generator_loss(fake_output):\n",
        "    return -tf.reduce_mean(fake_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilj-woz7fSum"
      },
      "outputs": [],
      "source": [
        "NOISE_DIM = 100\n",
        "\n",
        "@tf.function\n",
        "def train_step(real_images,digits):\n",
        "    with tf.GradientTape() as disc_tape, tf.GradientTape() as gen_tape:\n",
        "        # Generate random noise\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "\n",
        "        # Generate fake images with the generator\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        # Discriminator loss calculation\n",
        "        real_output = discriminatorU((real_images,digits), training=True)\n",
        "        fake_output = discriminatorU((generated_images,digits), training=True)\n",
        "        d_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "        # Generator loss calculation\n",
        "        g_loss = generator_loss(fake_output)\n",
        "\n",
        "    # Update generator and discriminator variables\n",
        "    gradients_of_discriminator = disc_tape.gradient(d_loss, discriminatorU.trainable_variables)\n",
        "    gradients_of_generator = gen_tape.gradient(g_loss, generator.trainable_variables)\n",
        "    discriminatorU_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminatorU.trainable_variables))\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    tf.print(\"disc_loss\",d_loss,'gen_loss',g_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "8AuOxPdvp1hu"
      },
      "outputs": [],
      "source": [
        "NOISE_DIM = 100\n",
        "threshold = 0.5\n",
        "#@tf.function\n",
        "def train_step(real_images,digits):\n",
        "\n",
        "    for i in range(5):\n",
        "      with tf.GradientTape() as disc_tape:\n",
        "        # Generate random noise\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "\n",
        "        # Generate fake images with the generator\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        # Discriminator loss calculation\n",
        "        real_output = discriminatorU((real_images,digits), training=True)\n",
        "        fake_output = discriminatorU((generated_images,digits), training=True)\n",
        "        d_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "\n",
        "      gradients_of_discriminator = disc_tape.gradient(d_loss, discriminatorU.trainable_variables)\n",
        "      discriminatorU_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminatorU.trainable_variables))\n",
        "\n",
        "      if i == 0:\n",
        "        weights = discriminatorU.get_weights()\n",
        "\n",
        "    with tf.GradientTape() as gen_tape:\n",
        "      # Generate random noise\n",
        "      noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "\n",
        "      # Generate fake images with the generator\n",
        "      generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "      fake_output = discriminatorU((generated_images,digits), training=True)\n",
        "\n",
        "       # Generator loss calculation\n",
        "      g_loss = generator_loss(fake_output)\n",
        "\n",
        "    # Update generator and discriminator variables\n",
        "\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(g_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    discriminatorU.set_weights(weights)\n",
        "\n",
        "    tf.print(\"disc_loss\",d_loss,'gen_loss',g_loss)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cP3-wZztEeaE"
      },
      "outputs": [],
      "source": [
        "NOISE_DIM = 100\n",
        "GP_WEIGHT = 10\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def train_step(images,digits):\n",
        "\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tapeW:\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        real_outputW = discriminatorW((images,digits), training=True)\n",
        "        fake_outputW = discriminatorW((generated_images,digits), training=True)\n",
        "\n",
        "        disc_lossW = discriminator_lossW(real_outputW, fake_outputW)\n",
        "\n",
        "        gen_lossW = generator_lossW(fake_outputW)\n",
        "        gen_loss = gen_lossW\n",
        "\n",
        "        gp = gradient_penalty(images, generated_images, digits)\n",
        "        disc_lossW += gp * GP_WEIGHT\n",
        "\n",
        "\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    gradients_of_discriminatorW = disc_tapeW.gradient(disc_lossW, discriminatorW.trainable_variables)\n",
        "    discriminatorW_optimizer.apply_gradients(zip(gradients_of_discriminatorW, discriminatorW.trainable_variables))\n",
        "\n",
        "\n",
        "    tf.print(\"disc_lossW\",disc_lossW,'gen_lossW',gen_lossW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Sx_KbIfjiogE"
      },
      "outputs": [],
      "source": [
        "def train(dataset,y_train, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    for batch in range(len(dataset) // BATCH_SIZE):\n",
        "\n",
        "            target_images = dataset[batch * BATCH_SIZE: (batch+1) * BATCH_SIZE]\n",
        "            digits = y_train[batch * BATCH_SIZE: (batch+1) * BATCH_SIZE]\n",
        "\n",
        "            train_step(target_images,digits)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      print(epoch)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWp_3RkPg248",
        "outputId": "7856e496-2f5f-476d-8761-274fe8ec8629",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "disc_loss 1.02353859 gen_loss 0.356400609\n",
            "disc_loss 1.10023665 gen_loss 0.412564427\n",
            "disc_loss 1.08266091 gen_loss 0.315383732\n",
            "disc_loss 1.0469358 gen_loss 0.279537916\n",
            "disc_loss 1.01146317 gen_loss 0.330462337\n",
            "disc_loss 0.981273055 gen_loss 0.357274532\n",
            "disc_loss 1.00839674 gen_loss 0.29497084\n",
            "disc_loss 0.974602461 gen_loss 0.272180229\n",
            "disc_loss 0.933941841 gen_loss 0.358573198\n",
            "disc_loss 0.935132086 gen_loss 0.317082375\n",
            "disc_loss 0.92617619 gen_loss 0.286962748\n",
            "disc_loss 0.894209146 gen_loss 0.334106147\n",
            "disc_loss 0.914479494 gen_loss 0.308525681\n",
            "disc_loss 0.862807751 gen_loss 0.399880499\n",
            "disc_loss 0.89630419 gen_loss 0.340636551\n",
            "disc_loss 0.854586482 gen_loss 0.379963279\n",
            "disc_loss 0.835455179 gen_loss 0.35689798\n",
            "disc_loss 0.835494041 gen_loss 0.505642295\n",
            "disc_loss 0.81232518 gen_loss 0.390938401\n",
            "disc_loss 0.831374407 gen_loss 0.438524902\n",
            "disc_loss 0.824292958 gen_loss 0.439606309\n",
            "disc_loss 0.824866354 gen_loss 0.495231777\n",
            "disc_loss 0.799025536 gen_loss 0.547938466\n",
            "disc_loss 0.760155559 gen_loss 0.540552\n",
            "disc_loss 0.779617786 gen_loss 0.522992134\n",
            "disc_loss 0.744501293 gen_loss 0.546692491\n",
            "disc_loss 0.748885393 gen_loss 0.594355345\n",
            "disc_loss 0.710259438 gen_loss 0.536223292\n",
            "disc_loss 0.730826 gen_loss 0.709364653\n",
            "disc_loss 0.797715306 gen_loss 0.671557307\n",
            "disc_loss 0.68191725 gen_loss 0.594824255\n",
            "disc_loss 0.664743543 gen_loss 0.654533446\n",
            "disc_loss 0.701966584 gen_loss 0.723217785\n",
            "disc_loss 0.654590607 gen_loss 0.730657935\n",
            "disc_loss 0.67804873 gen_loss 0.835237443\n",
            "disc_loss 0.681985319 gen_loss 0.859328508\n",
            "disc_loss 0.660477638 gen_loss 0.843894184\n",
            "disc_loss 0.620258 gen_loss 0.844788194\n",
            "disc_loss 0.6273 gen_loss 0.896058321\n",
            "disc_loss 0.62077409 gen_loss 0.862611115\n",
            "disc_loss 0.603360415 gen_loss 0.948949933\n",
            "disc_loss 0.593093276 gen_loss 0.94854\n",
            "disc_loss 0.592897773 gen_loss 0.950735\n",
            "disc_loss 0.603239655 gen_loss 1.05364454\n",
            "disc_loss 0.592638254 gen_loss 0.965589464\n",
            "disc_loss 0.553016901 gen_loss 0.944849908\n",
            "disc_loss 0.549725294 gen_loss 1.01219964\n",
            "disc_loss 0.55212754 gen_loss 1.07361209\n",
            "disc_loss 0.539187491 gen_loss 1.05845332\n",
            "disc_loss 0.513247073 gen_loss 1.10018861\n",
            "disc_loss 0.496819735 gen_loss 1.07240474\n",
            "disc_loss 0.535075665 gen_loss 0.97763747\n",
            "disc_loss 0.539633155 gen_loss 1.14968669\n",
            "disc_loss 0.510579586 gen_loss 1.1920588\n",
            "disc_loss 0.491597772 gen_loss 1.14778662\n",
            "disc_loss 0.504134 gen_loss 1.0923326\n",
            "disc_loss 0.515252173 gen_loss 1.2084465\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 100\n",
        "x_train2 = np.expand_dims(x_train, axis=-1)\n",
        "x_train2 = (x_train2 - np.min(x_train2)) / (np.max(x_train2) - np.min(x_train2))\n",
        "train(x_train2,y_train, EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "9vPp5AiDkrAF",
        "outputId": "06a0310f-8a19-4847-bb7e-b074c907e370",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 201ms/step\n",
            "tf.Tensor([9], shape=(1,), dtype=int32)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA0K0lEQVR4nO3deVSV5fo+8AsVNvM2B6bE2XDEipQ4lpmSgOVIpWYnNY9TaCmZRj+HtDqkntQ01AbT7KSWndSjOWNgg0OSZKahEiWGYFoCggzC+/ujbxQnzftW8BG6PmvttRQuLp6Xd8PNZu/9bAfLsiwQERFdYzVML4CIiP6aOICIiMgIDiAiIjKCA4iIiIzgACIiIiM4gIiIyAgOICIiMoIDiIiIjKhlegH/q7S0FBkZGfDw8ICDg4Pp5RARkZJlWcjNzYWfnx9q1Lj07ZzrbgBlZGTA39/f9DKIiOgqpaeno0GDBpd8f6UNoLi4OMyePRuZmZlo3749FixYgI4dO1724zw8PAAAz+wcBGd3J9HnynqvjXhdtY6dFmcBwO/HH8TZ1JC6qm73Da7i7PePybMA0OWA/K+rC2p8oOruN3iUKt/1yDfi7Mwmd6m6G+14S5wN+eYWVffZEQ3F2U4eparuld9/pMoHWfKvS/rHyarufg/Jfww8t1v+/QAADUO7irOhCQmq7ndu/ps4u6dwnao7+uOfVPkShwhxttUtRaruTzNSxVm/5RNU3Sf7yq+Hbb7PFWfzCwsx8NU5ZT/PL6VSBtC7776L6OhoLF68GMHBwZg3bx7CwsKQkpICLy+vP/3YX//s5uzuBGcP2QCy2VzEa6vl6CzOAoBLLdkaAMDJ2abqttWUr8XRRblum3wA1ayhuxo4u+uGoZur/OtSy91N1e3k7CjOujrpvoaFiuN0d9cNIJub/HoFAK6WfC3ONt310MNdfv6dXHTrtnnI1+2m7HZyl3/f13SUX08AwNW5pip/wUF+3XJ309214OyquI7Xctd1K36uuNmKVd0ALns3SqU8CGHOnDkYPnw4hg4ditatW2Px4sVwdXXFm2++WRmfjoiIqqAKH0BFRUVISkpCaGjob5+kRg2EhoZi165df8gXFhYiJyen3IWIiKq/Ch9Ap0+fRklJCby9vcu93dvbG5mZmX/Ix8bGwm63l134AAQior8G488DiomJQXZ2dtklPT3d9JKIiOgaqPAHIdSrVw81a9ZEVlZWubdnZWXBx8fnD3mbzQab8k5TIiKq+ir8FpCTkxOCgoIQHx9f9rbS0lLEx8cjJCSkoj8dERFVUZXyMOzo6GgMHjwYt912Gzp27Ih58+YhLy8PQ4cOrYxPR0REVVClDKD+/fvjxx9/xNSpU5GZmYmbb74Zmzdv/sMDE4iI6K/LwbIsy/Qifi8nJwd2ux3BkVtQy1H2pEQ32xvi/mfa6x5lt+zf8idfBfSVPzEOAGa9tV6cfXWi/JnWALD0ji/F2dWP6X4x2H6ktyo/e9Mn4mzzHfJdEwBgl08LcdZ/boCqu83EVeJs7S26J+fOPtRelZ98+4/i7MfhMaru1B96iLMzC0IvH/qdFUWfi7NHTg1QdQfcO0+cPThlrqr7oS/l5x4Atn12VJx9vK/uujKotfw6Xr+wpap7xooXxdnEuHvF2aKCIqycugrZ2dnw9PS8ZM74o+CIiOiviQOIiIiM4AAiIiIjOICIiMgIDiAiIjKCA4iIiIzgACIiIiM4gIiIyAgOICIiMoIDiIiIjKiUveAqwvDOr8HVRfZa6M3SHxD3ztxaqlpH2rIfxFmvkbmq7no75oizK78+rurO33RKnM3rofs95PFmk1X5xYUjxNn9d/dXdd8zaqw423TeAVX35hWtxdklqdtU3TMnnVTl33aUb5fUOGOmqvvGRvKtlVp8+8dXNf4zBfldxdmImvmq7kHbnxBnZxbrXvLl7hnHVHn7PfLr+Ktzjqi601vI869/vV3Vvfa9JHH2VPMt4uyF/PMALr+dEW8BERGRERxARERkBAcQEREZwQFERERGcAAREZERHEBERGQEBxARERnBAUREREZwABERkREcQEREZAQHEBERGXHd7gXXYEdDuDnK9m+aMPINcW/r275VreNu917irPXO66rup0/J99WaNjBC1f3Bf+X7mM17XbdP1s74Sar8jLNR4uzkYfNV3a/d/Yg462lzUHUfOd9EnP17zddU3eGff6PLP/APcbZvrm5PwshG7uLsmJnFqm7fFafF2TUf9VN1h3gOFGcf7PFPVXfJiq2q/Iebk8XZkIkfq7qfvn2BOOuVoPsa7s27RZydPLqDOHs+/wL2CXK8BUREREZwABERkREcQEREZAQHEBERGcEBRERERnAAERGRERxARERkBAcQEREZwQFERERGcAAREZER1+1WPBt79YbNVbZFSOTxQ+LesytuVq0j4NkMcfb1glGqbudx94uzXUfEq7onb2guzjZs2krVPcVJt11Om5YF4mx24RZV91fue8TZBl03qrrPR84WZ61p76q6B245pcovv+W4OHvPS/ItUwDg87m+4mz9F0equp0i5NfblybLrycA0DhohTi7+q1tqu6eH61T5Rff+4k4m9fr76ruObdKNrX5xaL/6LbJws27xdFaO36SZ4uKRDneAiIiIiM4gIiIyAgOICIiMoIDiIiIjOAAIiIiIziAiIjICA4gIiIyggOIiIiM4AAiIiIjOICIiMgIDiAiIjLiut0LLi/nCIqLXUXZaT8cFffO6f6oah3u4SfE2a/atVZ1Tzgt3/vquOsiVXfLPcfE2RpPfqrq/uekG1X5V9fI9+wauWOKqrtPQFtxNn19Q1V3VMf64uyNr25QdXvePE+V/3vIeXF2UXKcqtvh077i7Pze8n3jAODOkgXibMcVy1XdUb73irPTIj5WdXdqoft+G7XngDg79l8dVd1vx3QRZ31Hf6PqnrpJfh2v3eMzcTb/fC7w78t/3/MWEBERGVHhA+jZZ5+Fg4NDuUvLli0r+tMQEVEVVyl/gmvTpg22b9/+2yepdd3+pY+IiAyplMlQq1Yt+Pj4VEY1ERFVE5VyH9DRo0fh5+eHpk2bYtCgQTh+/NIvplVYWIicnJxyFyIiqv4qfAAFBwdj2bJl2Lx5MxYtWoS0tDTceeedyM3NvWg+NjYWdru97OLv71/RSyIioutQhQ+giIgIPPDAAwgMDERYWBg2btyIs2fP4r333rtoPiYmBtnZ2WWX9PT0il4SERFdhyr90QG1a9fGTTfdhGPHLv68FJvNBpvNVtnLICKi60ylPw/o3LlzSE1Nha+v7glsRERUvVX4AJowYQISExPx3Xff4bPPPkPfvn1Rs2ZNDBw4sKI/FRERVWEOlmVZFVk4YMAA7Ny5E2fOnEH9+vVxxx134IUXXkCzZs1EH5+TkwO73Y6oiJdgc3QRfYzny6Xi9XkMvk2cBYAHJsizr7p5qLq3DT4szvrcKvv6/er2Zu+Ls4n+Q1Tdjrd9rsovHnFSnC3Z2kvVfaRTkTj7zAe637fCF/YQZ7vd1VvV7Zp1lyo/zDtWnG27IV7VvaTDanE25VALVXf8yDXibOnLXqruuYqlBD7xvarbbb5u2yanBTeLs6e7ybfJAoAXbB+Ks339I1XdLplnxNm2++SjorikABu/mY7s7Gx4enpeMlfh9wGtWrWqoiuJiKga4l5wRERkBAcQEREZwQFERERGcAAREZERHEBERGQEBxARERnBAUREREZwABERkREcQEREZAQHEBERGVHpL8dwpQZ4NoK7k6so+07UXHHvbXN6qtbh4D5bnB3tdp+q+4tNGeLsrP/qXil2V2hjcfZvzb5SdTd98XVVPn7oZnH2oOM6VbfNQ772lzI/UXXH3irPDz81TNV93PdOVX6H/wVxdl9kkqo7LHycOBuTNUbVfeh5d3E28JR87z0AGLLYQZz9/uazqu77vr70qzhfTGDk4+JsMaJV3etfk19X+j25UNXtufR5cXbQjf8QZ88VlmLjN5fP8RYQEREZwQFERERGcAAREZERHEBERGQEBxARERnBAUREREZwABERkREcQEREZAQHEBERGcEBRERERjhYlmWZXsTv5eTkwG63o/vETXC0uYk+pofb1+L+jJ/3qtZzSyv51iMtb0hVdQf87QVxdvwof1X3rPv/Jc5u+XKpqjs4/XNV/nQf+RYeN97SVtXd67CzODsm9R1V98SOy8VZz73yLAC4uZ1T5V9OOCPOTr7rO1V3jeKz8vAdI1TdM9/cJc763r5V1f1U92Jxdn3ic6ruhR8lq/LTVjYSZ1d2/UDVvWfhOHG2z4LDqu5JR+VbCP3Y9Rlx9sL5fOwYOxzZ2dnw9PS8ZI63gIiIyAgOICIiMoIDiIiIjOAAIiIiIziAiIjICA4gIiIyggOIiIiM4AAiIiIjOICIiMgIDiAiIjKCA4iIiIyoZXoBl/JUOuDmJMtmex0T94bfO1G1jqiUheLs9HVTVd0f1rtNnD116DVVd1TuAXG2eG+Qqrvw+69U+cmWfB+zv3dwUXXP8JDv73Z4wwVVt31wQ3F2zvi5qu7Ifrrf/Vat/UKcreen2zewhdMscfZ4gO7755vFceLsc7fMUXXfEC3fB3DQTzmq7lbWSFV+iOMT4uzCtvK9EQHgx5aO4mz/m+TrAID2+z8RZ9+esEycLTlXIMrxFhARERnBAUREREZwABERkREcQEREZAQHEBERGcEBRERERnAAERGRERxARERkBAcQEREZwQFERERGcAAREZER1+1ecG99dhxONWT7gvWZ9rO496HZM1XrePj1puLsorrJqu6hY/aIs/7vtVV1792XJM6OmzdQ1f3ZhBRV3tsrUpydcP8Nqu7ptZqJswH+X6u6n3n3S3G24VD5vmQAEB+6QJUPcX9LnP33G0tU3c8f3iHOrnpwvqr7vmbdxdlb58Squr9YKv+emH9SvmcgANR6fK0qf/Nt8p8Td0yU7+sHAK+5uImz/gXtVN3tH3lBnH3S6Zw4e96pCKMFOd4CIiIiI9QDaOfOnejZsyf8/Pzg4OCAtWvXlnu/ZVmYOnUqfH194eLigtDQUBw9erSi1ktERNWEegDl5eWhffv2iIu7+Dbrs2bNwvz587F48WLs2bMHbm5uCAsLQ0GBbHtuIiL6a1DfBxQREYGIiIiLvs+yLMybNw+TJ09G7969AQDLly+Ht7c31q5diwEDBlzdaomIqNqo0PuA0tLSkJmZidDQ0LK32e12BAcHY9euXRf9mMLCQuTk5JS7EBFR9VehAygzMxMA4O3tXe7t3t7eZe/7X7GxsbDb7WUXf3/dqzkSEVHVZPxRcDExMcjOzi67pKenm14SERFdAxU6gHx8fAAAWVlZ5d6elZVV9r7/ZbPZ4OnpWe5CRETVX4UOoCZNmsDHxwfx8fFlb8vJycGePXsQEhJSkZ+KiIiqOPWj4M6dO4djx46V/T8tLQ3JycmoU6cOGjZsiHHjxuH5559HixYt0KRJE0yZMgV+fn7o06dPRa6biIiqOPUA2rdvH+6+++6y/0dHRwMABg8ejGXLlmHixInIy8vDiBEjcPbsWdxxxx3YvHkznJ11W5X8vW99uNlkW1DEp4eLe0//s4tqHSf2vyLOFk59X9Vtu/fY5UP/p/3glqrudu8UibMHIz1U3a+/crsqP/OlmuLsq6G6bUoyJpwUZ8+27qbqPpPaUZzt+ZSl6k7felqVfzBC/qdp13q6rZIWtJ8mzibMzFV1L67xgzh794lGqu6SlvKndTy6/G+q7oiNU1T5binrxdks+e5EAICf28kfmPWhk+78rO76kzjr5yvfUCAv54Iopx5AXbp0gWVd+pvNwcEBM2bMwIwZM7TVRET0F2L8UXBERPTXxAFERERGcAAREZERHEBERGQEBxARERnBAUREREZwABERkREcQEREZAQHEBERGcEBRERERqi34rlWFvhuhaOzTZSdvWiVuLf+8DtV6wioL9+4Ke22z1Td33buLM7u+fQ2VXfyj7J99ABg9CLdvld77vtWlf9536PibJ63g6r7209GiLMdjs9Udbt+sUmc3ZiyUdX92P1vqPJJQQ3E2c5vDlF1JzQaKM6+Kv9yAwCK7lgnzma5z1J1x7XZIc46Lb778qHfWdbr4i+geSnvJo8TZx/rdK+qu+Uj08VZn7P7Vd2tHu0nzm7sESHOFl4oAHDxV8H+Pd4CIiIiIziAiIjICA4gIiIyggOIiIiM4AAiIiIjOICIiMgIDiAiIjKCA4iIiIzgACIiIiM4gIiIyIjrdiuetK4lqOl+QZQNuXWbuHdGaC/VOtp6ybfA6dNrlKq7Vy/59iopSZNV3Z/a3hVn/1byiKr7/gsuqvy68R+Isy/103UP2xsozu5YOkbVPaXWV+Jsr72X33bk91790EmVv6t/iDh7KEj2ffOru3+Sd0+uvVTVvfD1teKs/zeuqu51O9LF2dBN81XdTdJLVfltP/QQZ+M6tlF1f3fsvDj7QpOJqu6dL84VZx8O+6c461CYDyRdPsdbQEREZAQHEBERGcEBRERERnAAERGRERxARERkBAcQEREZwQFERERGcAAREZERHEBERGQEBxARERnBAUREREZct3vB9ZrtCWcnmyjbMWyYuLd2vdmqdTQ/c0Sc7Rx2QtV94Gb5XmOjcp9Xdd/e8G1x9sG8jaruV0Y/rMrf931dcXbU1CxVd1TzqeLsviffUHX3ni3fwy5qQrCqe/r3t6ryXcd/Kc4evtdT1f30A/LjDHjzuKr78IOtxNknW8j3PAOA3H/JvybO20JV3UfiblLlp77+oTg7qeMxVff33p+KszG58arul5+rKc6WOMj3x8t1KIVklzneAiIiIiM4gIiIyAgOICIiMoIDiIiIjOAAIiIiIziAiIjICA4gIiIyggOIiIiM4AAiIiIjOICIiMiI63YrnqYPu8LVzVmUHWXJt4j4V5p8+xsAGDWmWJz1gqOq+8xrks0qftGx9B1Vd8QD9cTZD5t0UHU/Vbhalbf/MEGcbb7wC1X3ywt7irM12su3NAGAxv9YIc7eGBGn6n5lh6sqP7yFfMuUNfMbqrp31X5PnL3rb/LvNQBo2PNZcfaBt7equmdNmCXOdsn1U3XvO7pPlX/l8HPi7J22Zaru8Hvri7OpI4aqumcE/l2cnXZGvh1YfqHs5yZvARERkREcQEREZIR6AO3cuRM9e/aEn58fHBwcsHbt2nLvHzJkCBwcHMpdwsPDK2q9RERUTagHUF5eHtq3b4+4uEv/zTs8PBwnT54su6xcufKqFklERNWP+kEIERERiIiI+NOMzWaDj4/PFS+KiIiqv0q5DyghIQFeXl4ICAjA6NGjcebMmUtmCwsLkZOTU+5CRETVX4UPoPDwcCxfvhzx8fGYOXMmEhMTERERgZKSkovmY2NjYbfbyy7+/v4VvSQiIroOVfjzgAYMGFD273bt2iEwMBDNmjVDQkICunXr9od8TEwMoqOjy/6fk5PDIURE9BdQ6Q/Dbtq0KerVq4djxy7+Oug2mw2enp7lLkREVP1V+gA6ceIEzpw5A19f38r+VEREVIWo/wR37ty5crdm0tLSkJycjDp16qBOnTqYPn06IiMj4ePjg9TUVEycOBHNmzdHWFhYhS6ciIiqNgfLsizNByQkJODuu+/+w9sHDx6MRYsWoU+fPti/fz/Onj0LPz8/dO/eHc899xy8vb1F/Tk5ObDb7Xjwvvvg6CjbW+3grG/F65/0oXxfJQDISJsqzn7oFKLqfjEnU5z17fWoqntGqzbi7BN78lTdbz1tV+WH7JR/zQ992FrVPfaWdHH2YFwXVffaU6PF2e4d31Z1d62h+rZDp8yl4uzdT3qouh/8OVCcnabbIg1PPHtEnC3pPFDVfdpHvv9a96fk5xIAlvucU+Vb+28UZ3/Y21/VPdT1CXF2wKkPVN1Z7sHi7JSh8v0Ocy/koc2nYcjOzv7Tu1XUt4C6dOmCP5tZW7Zs0VYSEdFfEPeCIyIiIziAiIjICA4gIiIyggOIiIiM4AAiIiIjOICIiMgIDiAiIjKCA4iIiIzgACIiIiM4gIiIyIgKfz2ginJubAoc3WqKssVfyl/CYXF2d9U6hibJ93hqecMUVfeNB1aJs2HTm6q6T51IFmcnOsj3gwKAx9oMU+W7/Sjfl+691fJ9/QBgwoNPi7Od6/dVdec//aU4O2aT/HoCAAObjVPl8bB8P7AOwbNV1f9O/VCcLcmYr+ruWGuGOHvo0zdV3b0el5/7dz7er+qusVq+TyMAHGnRT5x9Y12hqjuzsXw/vXsf0O1H+e6B78XZEXY3cfZCsWyvQ94CIiIiIziAiIjICA4gIiIyggOIiIiM4AAiIiIjOICIiMgIDiAiIjKCA4iIiIzgACIiIiM4gIiIyIjrdisej6dbw6mmoyh7793yrWECrM9V6/gyzEGcHe5VR9V966LG4mz3sXepuh9b/Jw4O2HxzarusDb+qvwbd/QRZ5uuXKLqvnHmy+LsOtyi6n75g17i7NsPdVR1T9j9kCq/Yd1Scbbm+7rreJJNvnXPqXnjVd1nvtwrzr72/FZV96m+KeLst9Y9qu6EsW+p8rM3LhBn0zbNVXV/0mekOBvaPFHV7bZ+sTgbvucncbaoNE+U4y0gIiIyggOIiIiM4AAiIiIjOICIiMgIDiAiIjKCA4iIiIzgACIiIiM4gIiIyAgOICIiMoIDiIiIjOAAIiIiI67bveAiQu6Bq81FlN2Td0rc+/n7TVXrGDXJTZxNvxCu6m7l0FycfbjnCVX3se/uF2fHNVuu6vb777uqfJ3JoeJsYY/PVN2n18vPT8fRAaru6DueEGe7tNHtNfbNT/VV+cZNp4qzzRN0X8OxHzuLswEtFqq6I588LM4+WmOQqvuWj13F2bSox1XdrfZuV+X7f9RNnA1Oi1d1Dx3YUpz9ef1mVffI1qXi7D/+c6s4m5tfiKUDLp/jLSAiIjKCA4iIiIzgACIiIiM4gIiIyAgOICIiMoIDiIiIjOAAIiIiIziAiIjICA4gIiIyggOIiIiMuG634ll2+i7UcvIQZQe6LBH3Ot/RRLWOBc43i7M/dpis6n4yTt790qC+qu4BBfJtSnp9tkbV3Sd6hyp/+msfcTbmWG9V98CeBeLsgAu6bZheeW6nOHv/pI2q7u1f6L6Gqwe0EWfbjflO1b2w5jJxduTkQ6rulYejxNks792q7qBHY8XZJ8J1W9S0+FG3likt7xNnf/iml6p7+9JHxNkXP5yi6v7gscbirJd3kThbcO68KMdbQEREZIRqAMXGxqJDhw7w8PCAl5cX+vTpg5SUlHKZgoICREVFoW7dunB3d0dkZCSysrIqdNFERFT1qQZQYmIioqKisHv3bmzbtg3FxcXo3r078vLyyjLjx4/H+vXrsXr1aiQmJiIjIwP9+vWr8IUTEVHVproPaPPm8n9HXbZsGby8vJCUlITOnTsjOzsbS5YswYoVK9C1a1cAwNKlS9GqVSvs3r0bt99+e8WtnIiIqrSrug8oOzsbAFCnTh0AQFJSEoqLixEa+tvrv7Rs2RINGzbErl27LtpRWFiInJycchciIqr+rngAlZaWYty4cejUqRPatm0LAMjMzISTkxNq165dLuvt7Y3MzMyL9sTGxsJut5dd/P39r3RJRERUhVzxAIqKisLBgwexatWqq1pATEwMsrOzyy7p6elX1UdERFXDFT0PaMyYMdiwYQN27tyJBg0alL3dx8cHRUVFOHv2bLlbQVlZWfDxufhzQWw2G2w225Usg4iIqjDVLSDLsjBmzBisWbMGO3bsQJMm5Z/UGRQUBEdHR8TH//aa5ykpKTh+/DhCQkIqZsVERFQtqG4BRUVFYcWKFVi3bh08PDzK7tex2+1wcXGB3W7HsGHDEB0djTp16sDT0xNjx45FSEgIHwFHRETlqAbQokWLAABdunQp9/alS5diyJAhAIC5c+eiRo0aiIyMRGFhIcLCwrBw4cIKWSwREVUfqgFkWdZlM87OzoiLi0NcXNwVLwoABgTsh4uzbD+z0rqF4t5WHrqHeS///nNxtuBYtKr75KttxdnTp3R7pE1s002c3XlHI1X3GyUlqvy4IvnXsLhA96faBQtGi7O1HSNU3eN894uz61o0V3Unn/pYlT/4+Fh5uOcYVfe4CwfF2ZcvdFV1/2el/Dq+9+Arqu7aORni7Oma8ZcP/U6j3bJ9KH81ZeIWcbbfA/eouk8/KP8apvSaqOreesFbnF342CZxtqAk7/IhcC84IiIyhAOIiIiM4AAiIiIjOICIiMgIDiAiIjKCA4iIiIzgACIiIiM4gIiIyAgOICIiMoIDiIiIjHCwJPvrXEM5OTmw2+2Y3vwBONd0FH3MyY6Hxf1Wv2dV6zm6Il+cHR78mao77uch4mz4U6pquB1eKc66nG6m6q7/1NOqfOuhs8TZT9Z21K2l5Ftxdt3PS1Td3e7oIM5OHHvxV/y9lEHfPaTKx30rv27NaL1e1f31jmRxNvLzkaru7knbxNk56YtV3T+/0EacDRkqv54AQNTyGar8l1/eL85OGqjbyurD3NDLh/7PR7Pl25IBQPYyF3F2hN8P4mzJuXwkBQ1BdnY2PD09L5njLSAiIjKCA4iIiIzgACIiIiM4gIiIyAgOICIiMoIDiIiIjOAAIiIiIziAiIjICA4gIiIyggOIiIiM4AAiIiIjaplewKV4jgyDi4urKHvzg5fea+h/RX3VULWOVyfK9wNb6dtd1f3+z/L9wAb8t5eqe7SvfD+wNdv+qeoedONgVb7r4B7i7Jt1dN3LHpbvNXbqmG5/r89Sp4mzn+zsq+qeG79VlY9evk+cPZmbo+rOGDVHnH3WeZSqu3EnP3H2dGPdfm1PfP4vcfbzuZ1U3RlzN6vyPu0/Emc/bTxO1f30z0fE2aktJqq6v/lvT3F2Sox8X8z8Whb6C3K8BUREREZwABERkREcQEREZAQHEBERGcEBRERERnAAERGRERxARERkBAcQEREZwQFERERGcAAREZER1+1WPLn3/4xijwJRdvP89uLeZ29oolpH9p23ibM/fVxH1b0oeoQ4W/yPdFV3SVf5Fhv73N9TdRf8dKsq/17pfHE2Lbytqjv+1Ffi7KH9qmqsW/yKOJvxmpeqe8tRmyofZNskzhb3+EnVHfum/PfQhT9/oOqu3ypSnB325Ieq7uClq8RZj1nJqu7B+VNU+bf6yb/3X14YpureNPh5cXZL3ddU3XWWW+JscecHxdnc/CIAb142x1tARERkBAcQEREZwQFERERGcAAREZERHEBERGQEBxARERnBAUREREZwABERkREcQEREZAQHEBERGcEBRERERly3e8FtX1GKWs4lomyQq7u41xYfoFrHh//2E2e3nbv83ke/5xd4lzg7eqLud4X4VtnibHbthqru3NGfqfJ9ci+Is4uO6Pay6lPPLs4+s/NjVfezqa3F2dCndPuYnZj2gCp/aPhhcfa58QdV3f0nnBNn/YMcVd09+++TZ4cMVnWv2+wqzk6P2aDqHuXtocr/cI98LfsXdFV1bz+0Wpw9ssNB1V235wpx9t1/NhZnC0pywb3giIjouqUaQLGxsejQoQM8PDzg5eWFPn36ICUlpVymS5cucHBwKHcZNWpUhS6aiIiqPtUASkxMRFRUFHbv3o1t27ahuLgY3bt3R15eXrnc8OHDcfLkybLLrFmzKnTRRERU9anuA9q8eXO5/y9btgxeXl5ISkpC586dy97u6uoKHx+filkhERFVS1d1H1B29i93dNepU/7FmN555x3Uq1cPbdu2RUxMDPLz8y/ZUVhYiJycnHIXIiKq/q74UXClpaUYN24cOnXqhLZtf3sVy4ceegiNGjWCn58fDhw4gEmTJiElJQUffHDxV1KMjY3F9OnTr3QZRERURV3xAIqKisLBgwfxySeflHv7iBG/vcx0u3bt4Ovri27duiE1NRXNmjX7Q09MTAyio6PL/p+TkwN/f/8rXRYREVURVzSAxowZgw0bNmDnzp1o0KDBn2aDg4MBAMeOHbvoALLZbLDZbFeyDCIiqsJUA8iyLIwdOxZr1qxBQkICmjRpctmPSU5OBgD4+vpe0QKJiKh6Ug2gqKgorFixAuvWrYOHhwcyMzMBAHa7HS4uLkhNTcWKFSvQo0cP1K1bFwcOHMD48ePRuXNnBAYGVsoBEBFR1aQaQIsWLQLwy5NNf2/p0qUYMmQInJycsH37dsybNw95eXnw9/dHZGQkJk+eXGELJiKi6sHBsizL9CJ+LycnB3a7HQdmT4WHi7PoY5bEbRP3p9yk22vs5+E/iLOFOxJV3fc9tUacvX+f7u66Q37yvalu//SP9839mYGffq3K+89cJc7eEFms6n53qfzc337vTFX3SJ+J4uzHbxxRdbcemqnKj3ughzj7VcABVfeMNjvF2bZ9PFXdb/zYTpy9a/+jqu5m/euKs2enO6m6F7k+osrvbXaPOPve2f6q7vhB6eJs4nvzVN33BMqv496fy68nRecK8HrHZ5CdnQ1Pz0tfZ7gXHBERGcEBRERERnAAERGRERxARERkBAcQEREZwQFERERGcAAREZERHEBERGQEBxARERnBAUREREZc8esBVbYVm++CrZabKPtt7Kvi3nnJp1TrOOOeJM66b92r6u4/dbs4+8/UAaruJW9/Ks4ubql7QcCcrGGq/PYQ+TYlj8ZMUnU7x7a9fOj/2B+uqere+Lj83DfJ123Fc8L2gCp/a2tHcfaxPQNV3YO6X/zFIi8m5BHdtk2L75N/Df9xz2FVd93/9BJnv5ui+75/ZZp8iycAuLevfLf/mXUXq7oDTsq3D1vluE7VPdCtqTj7d5eN4mzehRK8LsjxFhARERnBAUREREZwABERkREcQEREZAQHEBERGcEBRERERnAAERGRERxARERkBAcQEREZwQFERERGcAAREZER1+1ecCfvT4WTi4so2/WGDuLerVu9VetI6PW1OPv4J39Xdb+2va84e+jBnqru93uNFmc91ur2JcNXsj36fvWj30/i7JeddHuNnQhYKc72cBqq6k6atEmcfWjCSFX3C3NuVuUfP7hLnP2oxgJV97hH/iXOhozep+pe+Yy8e1HL3aru8RPkewxujPxR1e035l5VPjxDfpylH/qrutf+P/nX/MvBX6q6290aJc6OS7hDnL1wvgjA5X928hYQEREZwQFERERGcAAREZERHEBERGQEBxARERnBAUREREZwABERkREcQEREZAQHEBERGcEBRERERly3W/EEYhdc4CTKvv/cSXFvj+FnVOtoef8AcfYf+5arul0GHhdnv3trkKr7zW/yxdn377xF1e19l7wbAHa++qQ4W2u47Jz/asfwGHH28Ygxqm635Hni7Khb/6vqLvhngCo/7sAscTbWdbaq+4v2R8TZ8NdXq7r/sb9EnH21KEnV/UxKD3E2/nZ5FgBSfvyPKn9XqHyrpI+DdL/3f10o3w4sO0O3ndHd2RfE2VcbTxRnz1m56IQ3LpvjLSAiIjKCA4iIiIzgACIiIiM4gIiIyAgOICIiMoIDiIiIjOAAIiIiIziAiIjICA4gIiIyggOIiIiM4AAiIiIjHCzLskwv4vdycnJgt9vxdq9H4eoo2xcsdsbH4v72Xw5VredGz5ri7G0XflZ1P9DdQZzdN1a+XxcA7O8TIs7ubfSJqrtD4WRVPvVO+T5p9zy9VtVdXPKyOPtBr52q7t2xI8XZp250VnVnTJDvjwcAHzicFWdHjJSfewAIfftOcfY/79tU3R0f3CDOxke7q7rjb7pPnL35s/Wq7rC+G1X5SU8eE2cvLJSvGwDa/fddcfaGO7NV3duSVomzzUf8IM4W553H1m5PIDs7G56enpfM8RYQEREZoRpAixYtQmBgIDw9PeHp6YmQkBBs2rSp7P0FBQWIiopC3bp14e7ujsjISGRlZVX4oomIqOpTDaAGDRrgxRdfRFJSEvbt24euXbuid+/e+PrrX7YLHz9+PNavX4/Vq1cjMTERGRkZ6NevX6UsnIiIqjbV6wH17Nmz3P9feOEFLFq0CLt370aDBg2wZMkSrFixAl27dgUALF26FK1atcLu3btx++23V9yqiYioyrvi+4BKSkqwatUq5OXlISQkBElJSSguLkZoaGhZpmXLlmjYsCF27br0izUVFhYiJyen3IWIiKo/9QD66quv4O7uDpvNhlGjRmHNmjVo3bo1MjMz4eTkhNq1a5fLe3t7IzMz85J9sbGxsNvtZRd/f3/1QRARUdWjHkABAQFITk7Gnj17MHr0aAwePBiHDh264gXExMQgOzu77JKenn7FXUREVHWo7gMCACcnJzRv3hwAEBQUhM8//xwvv/wy+vfvj6KiIpw9e7bcraCsrCz4+Phcss9ms8Fm0z23gIiIqr6rfh5QaWkpCgsLERQUBEdHR8THx5e9LyUlBcePH0dIiO6JcUREVP2pbgHFxMQgIiICDRs2RG5uLlasWIGEhARs2bIFdrsdw4YNQ3R0NOrUqQNPT0+MHTsWISEhfAQcERH9gWoAnTp1Co888ghOnjwJu92OwMBAbNmyBffccw8AYO7cuahRowYiIyNRWFiIsLAwLFy48IoWlvpoOJzdXEXZR86fFveGOvqp1jHlhHw7lmaHpqm6g/GSOLtnSJCqu/DTeeLsg3ktVd3jj/VS5V8a9oY4O661fHsiAMAJ+fYtI5fPV1WPbCu/rjiN2nT50O8kv6U8n437iLMhLTarujeffVacdVl2v647o4U4m/2NfEsgABhUPFWcDfL2VnXvOxKmynd5+E1xttaNE1TdA9u8Js4mhS5Xdd/3ooc4W3/mt+LsudxCbBXkVANoyZIlf/p+Z2dnxMXFIS4uTlNLRER/QdwLjoiIjOAAIiIiIziAiIjICA4gIiIyggOIiIiM4AAiIiIjOICIiMgIDiAiIjKCA4iIiIxQ74Zd2SzLAgAU5OeLP8bBsVicPafoBYDi85Y4e76wQNV9Ib9U3u0sP0YAKCyQd+fl67pLFN0AkFeUJ+/O130NUXBOHD1fpFv3ucLz4qxTrvb86I6zJD9XnM1VrBsAzivWXnpB111QKP8dt/CC/BgB4HxxkTh7robu631e+TUsLJKvvSRPvm4AOFcg/5l1/pzuephXKv/edMktlPf+X/bXn+eX4mBdLnGNnThxgi9KR0RUDaSnp6NBgwaXfP91N4BKS0uRkZEBDw8PODj8tjFlTk4O/P39kZ6eDk9PT4MrrFw8zurjr3CMAI+zuqmI47QsC7m5ufDz80ONGpe+FXzd/QmuRo0afzoxPT09q/XJ/xWPs/r4KxwjwOOsbq72OO12+2UzfBACEREZwQFERERGVJkBZLPZMG3aNNhsNtNLqVQ8zurjr3CMAI+zurmWx3ndPQiBiIj+GqrMLSAiIqpeOICIiMgIDiAiIjKCA4iIiIyoMgMoLi4OjRs3hrOzM4KDg7F3717TS6pQzz77LBwcHMpdWrZsaXpZV2Xnzp3o2bMn/Pz84ODggLVr15Z7v2VZmDp1Knx9feHi4oLQ0FAcPXrUzGKvwuWOc8iQIX84t+Hh4WYWe4ViY2PRoUMHeHh4wMvLC3369EFKSkq5TEFBAaKiolC3bl24u7sjMjISWVlZhlZ8ZSTH2aVLlz+cz1GjRhla8ZVZtGgRAgMDy55sGhISgk2bNpW9/1qdyyoxgN59911ER0dj2rRp+OKLL9C+fXuEhYXh1KlTppdWodq0aYOTJ0+WXT755BPTS7oqeXl5aN++PeLi4i76/lmzZmH+/PlYvHgx9uzZAzc3N4SFhaFAuVGnaZc7TgAIDw8vd25Xrlx5DVd49RITExEVFYXdu3dj27ZtKC4uRvfu3ZGX99tmluPHj8f69euxevVqJCYmIiMjA/369TO4aj3JcQLA8OHDy53PWbNmGVrxlWnQoAFefPFFJCUlYd++fejatSt69+6Nr7/+GsA1PJdWFdCxY0crKiqq7P8lJSWWn5+fFRsba3BVFWvatGlW+/btTS+j0gCw1qxZU/b/0tJSy8fHx5o9e3bZ286ePWvZbDZr5cqVBlZYMf73OC3LsgYPHmz17t3byHoqy6lTpywAVmJiomVZv5w7R0dHa/Xq1WWZw4cPWwCsXbt2mVrmVfvf47Qsy7rrrrusJ554wtyiKskNN9xgvfHGG9f0XF73t4CKioqQlJSE0NDQsrfVqFEDoaGh2LVrl8GVVbyjR4/Cz88PTZs2xaBBg3D8+HHTS6o0aWlpyMzMLHde7XY7goODq915BYCEhAR4eXkhICAAo0ePxpkzZ0wv6apkZ2cDAOrUqQMASEpKQnFxcbnz2bJlSzRs2LBKn8//Pc5fvfPOO6hXrx7atm2LmJgY5Ctf5uV6UlJSglWrViEvLw8hISHX9Fxed5uR/q/Tp0+jpKQE3t7e5d7u7e2Nb775xtCqKl5wcDCWLVuGgIAAnDx5EtOnT8edd96JgwcPwsPDw/TyKlxmZiYAXPS8/vq+6iI8PBz9+vVDkyZNkJqaimeeeQYRERHYtWsXatasaXp5aqWlpRg3bhw6deqEtm3bAvjlfDo5OaF27drlslX5fF7sOAHgoYceQqNGjeDn54cDBw5g0qRJSElJwQcffGBwtXpfffUVQkJCUFBQAHd3d6xZswatW7dGcnLyNTuX1/0A+quIiIgo+3dgYCCCg4PRqFEjvPfeexg2bJjBldHVGjBgQNm/27Vrh8DAQDRr1gwJCQno1q2bwZVdmaioKBw8eLDK30d5OZc6zhEjRpT9u127dvD19UW3bt2QmpqKZs2aXetlXrGAgAAkJycjOzsb77//PgYPHozExMRruobr/k9w9erVQ82aNf/wCIysrCz4+PgYWlXlq127Nm666SYcO3bM9FIqxa/n7q92XgGgadOmqFevXpU8t2PGjMGGDRvw0UcflXvZFB8fHxQVFeHs2bPl8lX1fF7qOC8mODgYAKrc+XRyckLz5s0RFBSE2NhYtG/fHi+//PI1PZfX/QBycnJCUFAQ4uPjy95WWlqK+Ph4hISEGFxZ5Tp37hxSU1Ph6+treimVokmTJvDx8Sl3XnNycrBnz55qfV6BX17198yZM1Xq3FqWhTFjxmDNmjXYsWMHmjRpUu79QUFBcHR0LHc+U1JScPz48Sp1Pi93nBeTnJwMAFXqfF5MaWkpCgsLr+25rNCHNFSSVatWWTabzVq2bJl16NAha8SIEVbt2rWtzMxM00urME8++aSVkJBgpaWlWZ9++qkVGhpq1atXzzp16pTppV2x3Nxca//+/db+/fstANacOXOs/fv3W99//71lWZb14osvWrVr17bWrVtnHThwwOrdu7fVpEkT6/z584ZXrvNnx5mbm2tNmDDB2rVrl5WWlmZt377duvXWW60WLVpYBQUFppcuNnr0aMtut1sJCQnWyZMnyy75+fllmVGjRlkNGza0duzYYe3bt88KCQmxQkJCDK5a73LHeezYMWvGjBnWvn37rLS0NGvdunVW06ZNrc6dOxteuc7TTz9tJSYmWmlpadaBAwesp59+2nJwcLC2bt1qWda1O5dVYgBZlmUtWLDAatiwoeXk5GR17NjR2r17t+klVaj+/ftbvr6+lpOTk3XjjTda/fv3t44dO2Z6WVflo48+sgD84TJ48GDLsn55KPaUKVMsb29vy2azWd26dbNSUlLMLvoK/Nlx5ufnW927d7fq169vOTo6Wo0aNbKGDx9e5X55utjxAbCWLl1aljl//rz12GOPWTfccIPl6upq9e3b1zp58qS5RV+Byx3n8ePHrc6dO1t16tSxbDab1bx5c+upp56ysrOzzS5c6dFHH7UaNWpkOTk5WfXr17e6detWNnws69qdS74cAxERGXHd3wdERETVEwcQEREZwQFERERGcAAREZERHEBERGQEBxARERnBAUREREZwABERkREcQEREZAQHEBERGcEBRERERnAAERGREf8fYHykwQid6T8AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "noise = tf.random.normal(shape=(1,100))\n",
        "random_number = tf.random.uniform(shape=[1,], minval=0, maxval=10, dtype=tf.int32)\n",
        "test = generator.predict((noise,random_number))\n",
        "print(random_number)\n",
        "plt.imshow(test.squeeze())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_r4IEg2iBLvP"
      },
      "outputs": [],
      "source": [
        "NOISE_DIM = 100\n",
        "GP_WEIGHT = 10\n",
        "\n",
        "\n",
        "#@tf.function\n",
        "def train_step(images,digits):\n",
        "\n",
        "\n",
        "    for i in range(3):\n",
        "      with tf.GradientTape() as disc_tapeU:\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        real_outputU = discriminatorU((images,digits), training=True)\n",
        "        fake_outputU = discriminatorU((generated_images,digits), training=True)\n",
        "        disc_lossU = cross_entropy(tf.ones_like(real_outputU), real_outputU)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      gradients_of_discriminatorU = disc_tapeU.gradient(disc_lossU, discriminatorU.trainable_variables)\n",
        "      discriminatorU_optimizer.apply_gradients(zip(gradients_of_discriminatorU, discriminatorU.trainable_variables))\n",
        "      if i == 0:\n",
        "        weights = discriminatorU.get_weights()\n",
        "\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tapeW:\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        real_outputW = discriminatorW((images,digits), training=True)\n",
        "        fake_outputW = discriminatorW((generated_images,digits), training=True)\n",
        "        real_outputU = discriminatorU((images,digits), training=True)\n",
        "        fake_outputU = discriminatorU((generated_images,digits), training=True)\n",
        "        disc_lossW = discriminator_lossW(real_outputW, fake_outputW)\n",
        "\n",
        "\n",
        "        gen_lossU = cross_entropy(tf.ones_like(fake_outputU), fake_outputU)\n",
        "        gen_lossW = generator_lossW(fake_outputW)\n",
        "        gen_loss = gen_lossU#+gen_lossW\n",
        "\n",
        "        gp = gradient_penalty(images, generated_images, digits)\n",
        "        disc_lossW += gp * GP_WEIGHT\n",
        "\n",
        "\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    gradients_of_discriminatorW = disc_tapeW.gradient(disc_lossW, discriminatorW.trainable_variables)\n",
        "    discriminatorW_optimizer.apply_gradients(zip(gradients_of_discriminatorW, discriminatorW.trainable_variables))\n",
        "\n",
        "    discriminatorU.set_weights(weights)\n",
        "\n",
        "    tf.print(\"disc_lossW\",disc_lossW,'disc_lossU',disc_lossU,'gen_lossU',gen_lossU,'gen_lossW',gen_lossW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhuRFc0ro5T_"
      },
      "outputs": [],
      "source": [
        "print(np.min(x_train2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojIuJFIAybro"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}