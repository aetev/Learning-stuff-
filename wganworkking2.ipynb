{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aetev/Learning-stuff-/blob/main/wganworkking2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xI7rEeMMgDQI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgyl_WtbgO5k",
        "outputId": "e5e117b0-abc2-4a8e-be40-4eb41c9226d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 10s 0us/step\n"
          ]
        }
      ],
      "source": [
        "#(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kik7wQ1qgOV-"
      },
      "outputs": [],
      "source": [
        "def make_generator_model():\n",
        "\n",
        "    input_noise = layers.Input(shape=(100,))\n",
        "    input_digit = layers.Input(shape=(1,))\n",
        "    digit = layers.Embedding(10, 10)(input_digit)\n",
        "    digit = layers.Flatten()(digit)\n",
        "\n",
        "    x = layers.concatenate([input_noise, digit])\n",
        "\n",
        "    x = layers.Dense(8*8*24,activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.Reshape((8, 8, 24))(x)\n",
        "\n",
        "\n",
        "    x = layers.Conv2DTranspose(64,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv2DTranspose(64,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv2D(3,3,1,padding='same',activation='sigmoid')(x)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=(input_noise,input_digit), outputs=x)\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "\n",
        "def make_discriminator_model():\n",
        "    input_img = layers.Input(shape=(32,32,3))\n",
        "\n",
        "    input_digit = layers.Input(shape=(1,))\n",
        "    digit = layers.Embedding(10, 5)(input_digit)\n",
        "    digit = layers.Flatten()(digit)\n",
        "\n",
        "\n",
        "\n",
        "    x = layers.Conv2D(64,5,2,padding='same',activation='LeakyReLU')(input_img)\n",
        "\n",
        "\n",
        "    x = layers.Conv2D(64,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "\n",
        "    x = layers.Conv2D(64,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "\n",
        "    x = layers.Conv2D(64,3,2,padding='same',activation='LeakyReLU')(x)\n",
        "\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "\n",
        "    x = layers.concatenate([x, digit])\n",
        "\n",
        "    x = layers.Dense(128, activation='LeakyReLU')(x)\n",
        "\n",
        "    dense_output = layers.Dense(64, activation='LeakyReLU')(x)\n",
        "\n",
        "\n",
        "    dense_output = layers.Dense(1, activation=None)(dense_output)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=(input_img,input_digit), outputs=dense_output)\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qzdSabqdVu_H"
      },
      "outputs": [],
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lS0DF8rjhHdY",
        "outputId": "17cac126-3531-47f5-ade7-9689d743bedc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, 1, 10)                100       ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)        [(None, 100)]                0         []                            \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 10)                   0         ['embedding[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 110)                  0         ['input_1[0][0]',             \n",
            "                                                                     'flatten[0][0]']             \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 1536)                 170496    ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " reshape (Reshape)           (None, 8, 8, 24)             0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTr  (None, 16, 16, 64)           13888     ['reshape[0][0]']             \n",
            " anspose)                                                                                         \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 16, 16, 64)           256       ['conv2d_transpose[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2D  (None, 32, 32, 64)           36928     ['batch_normalization[0][0]'] \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 32, 32, 64)           256       ['conv2d_transpose_1[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 32, 32, 3)            1731      ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 223655 (873.65 KB)\n",
            "Trainable params: 223399 (872.65 KB)\n",
            "Non-trainable params: 256 (1.00 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "generator = make_generator_model()\n",
        "generator_optimizer = tf.keras.optimizers.Adam(0.0002)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GJxNxRSHkWfl"
      },
      "outputs": [],
      "source": [
        "discriminatorW = make_discriminator_model()\n",
        "discriminatorW_optimizer = tf.keras.optimizers.Adam(0.0004)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6cDVGo73jfqZ"
      },
      "outputs": [],
      "source": [
        "discriminatorU = make_discriminator_model()\n",
        "discriminatorU_optimizer = tf.keras.optimizers.Adam(0.0004)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DYQpIZyEgSlN"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "@tf.function\n",
        "def discriminator_lossW(real_output, fake_output):\n",
        "    real_loss = tf.reduce_mean(real_output)\n",
        "    fake_loss = tf.reduce_mean(fake_output)\n",
        "    total_loss = fake_loss - real_loss\n",
        "    return total_loss\n",
        "\n",
        "@tf.function\n",
        "def generator_lossW(fake_output):\n",
        "    return -tf.reduce_mean(fake_output)\n",
        "\n",
        "@tf.function\n",
        "def gradient_penalty(real_images, fake_images,digits):\n",
        "    alpha = tf.random.uniform([BATCH_SIZE, 1, 1, 1], 0., 1.)\n",
        "    real_images, fake_images = tf.cast(real_images, tf.float32), tf.cast(fake_images, tf.float32)\n",
        "    interpolated_images = alpha * real_images + ((1 - alpha) * fake_images)\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(interpolated_images)\n",
        "        pred = discriminatorW((interpolated_images,digits), training=True)\n",
        "    gradients = tape.gradient(pred, [interpolated_images])[0]\n",
        "    norm = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis=[1, 2, 3]))\n",
        "    gp = tf.reduce_mean((norm - 1.)**2)\n",
        "    return gp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4rgSqI2sf1sT"
      },
      "outputs": [],
      "source": [
        "\n",
        "@tf.function\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "@tf.function\n",
        "def generator_loss(fake_output):\n",
        "    return -tf.reduce_mean(fake_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilj-woz7fSum"
      },
      "outputs": [],
      "source": [
        "NOISE_DIM = 100\n",
        "\n",
        "@tf.function\n",
        "def train_step(real_images,digits):\n",
        "    with tf.GradientTape() as disc_tape, tf.GradientTape() as gen_tape:\n",
        "        # Generate random noise\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "\n",
        "        # Generate fake images with the generator\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        # Discriminator loss calculation\n",
        "        real_output = discriminatorU((real_images,digits), training=True)\n",
        "        fake_output = discriminatorU((generated_images,digits), training=True)\n",
        "        d_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "        # Generator loss calculation\n",
        "        g_loss = generator_loss(fake_output)\n",
        "\n",
        "    # Update generator and discriminator variables\n",
        "    gradients_of_discriminator = disc_tape.gradient(d_loss, discriminatorU.trainable_variables)\n",
        "    gradients_of_generator = gen_tape.gradient(g_loss, generator.trainable_variables)\n",
        "    discriminatorU_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminatorU.trainable_variables))\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    tf.print(\"disc_loss\",d_loss,'gen_loss',g_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8AuOxPdvp1hu"
      },
      "outputs": [],
      "source": [
        "NOISE_DIM = 100\n",
        "threshold = 0.5\n",
        "#@tf.function\n",
        "def train_step(real_images,digits):\n",
        "\n",
        "    for i in range(5):\n",
        "      with tf.GradientTape() as disc_tape:\n",
        "        # Generate random noise\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "\n",
        "        # Generate fake images with the generator\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        # Discriminator loss calculation\n",
        "        real_output = discriminatorU((real_images,digits), training=True)\n",
        "        fake_output = discriminatorU((generated_images,digits), training=True)\n",
        "        d_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "\n",
        "      gradients_of_discriminator = disc_tape.gradient(d_loss, discriminatorU.trainable_variables)\n",
        "      discriminatorU_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminatorU.trainable_variables))\n",
        "\n",
        "      if i == 0:\n",
        "        weights = discriminatorU.get_weights()\n",
        "\n",
        "    with tf.GradientTape() as gen_tape:\n",
        "      # Generate random noise\n",
        "      noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "\n",
        "      # Generate fake images with the generator\n",
        "      generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "      fake_output = discriminatorU((generated_images,digits), training=True)\n",
        "\n",
        "       # Generator loss calculation\n",
        "      g_loss = generator_loss(fake_output)\n",
        "\n",
        "    # Update generator and discriminator variables\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(g_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    discriminatorU.set_weights(weights)\n",
        "\n",
        "    tf.print(\"disc_loss\",d_loss,'gen_loss',g_loss,'LR',generator_optimizer.learning_rate)\n",
        "\n",
        "    modi = .000001\n",
        "\n",
        "    mult = abs(min(loss,1)-.5)*2\n",
        "\n",
        "    if d_loss > threshold:\n",
        "      new_lr = generator_optimizer.learning_rate-.000001\n",
        "    else:\n",
        "      new_lr = generator_optimizer.learning_rate+.000001\n",
        "\n",
        "    generator_optimizer.learning_rate.assign(new_lr)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cP3-wZztEeaE"
      },
      "outputs": [],
      "source": [
        "NOISE_DIM = 100\n",
        "GP_WEIGHT = 10\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def train_step(images,digits):\n",
        "\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tapeW:\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        real_outputW = discriminatorW((images,digits), training=True)\n",
        "        fake_outputW = discriminatorW((generated_images,digits), training=True)\n",
        "\n",
        "        disc_lossW = discriminator_lossW(real_outputW, fake_outputW)\n",
        "\n",
        "        gen_lossW = generator_lossW(fake_outputW)\n",
        "        gen_loss = gen_lossW\n",
        "\n",
        "        gp = gradient_penalty(images, generated_images, digits)\n",
        "        disc_lossW += gp * GP_WEIGHT\n",
        "\n",
        "\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    gradients_of_discriminatorW = disc_tapeW.gradient(disc_lossW, discriminatorW.trainable_variables)\n",
        "    discriminatorW_optimizer.apply_gradients(zip(gradients_of_discriminatorW, discriminatorW.trainable_variables))\n",
        "\n",
        "\n",
        "    tf.print(\"disc_lossW\",disc_lossW,'gen_lossW',gen_lossW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Sx_KbIfjiogE"
      },
      "outputs": [],
      "source": [
        "def train(dataset,y_train, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    for batch in range(len(dataset) // BATCH_SIZE):\n",
        "\n",
        "            target_images = dataset[batch * BATCH_SIZE: (batch+1) * BATCH_SIZE]\n",
        "            digits = y_train[batch * BATCH_SIZE: (batch+1) * BATCH_SIZE]\n",
        "\n",
        "            train_step(target_images,digits)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      print(epoch)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = .5\n",
        "modi = .000001\n",
        "\n",
        "mult = abs(min(loss,1)-.5)*2\n",
        "print(mult)"
      ],
      "metadata": {
        "id": "vN5GmsyfuiNd",
        "outputId": "84e99c1f-4617-4200-e97c-0ff6adbb1406",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IWp_3RkPg248",
        "outputId": "76e285b6-49ba-4fb0-dd24-6d65d3b97194",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "disc_loss 0.38694796 gen_loss 1.5712347 LR 0.000185000099\n",
            "disc_loss 0.515576839 gen_loss 1.89647651 LR 0.000186000092\n",
            "disc_loss 0.33946982 gen_loss 2.33046 LR 0.000185000099\n",
            "disc_loss 0.436077237 gen_loss 2.03042936 LR 0.000186000092\n",
            "disc_loss 0.360194355 gen_loss 1.15781915 LR 0.000187000085\n",
            "disc_loss 0.418891072 gen_loss 2.57995701 LR 0.000188000078\n",
            "disc_loss 0.469524592 gen_loss 1.01734006 LR 0.000189000071\n",
            "disc_loss 0.445849478 gen_loss 2.22704935 LR 0.000190000064\n",
            "disc_loss 0.418547541 gen_loss 2.25320959 LR 0.000191000057\n",
            "disc_loss 0.577931166 gen_loss 2.06717539 LR 0.00019200005\n",
            "disc_loss 1.75614011 gen_loss 2.25333405 LR 0.000191000057\n",
            "disc_loss 0.960252702 gen_loss 2.78567052 LR 0.000190000064\n",
            "disc_loss 1.19124293 gen_loss 2.30722213 LR 0.000189000071\n",
            "disc_loss 0.673210323 gen_loss 0.867636681 LR 0.000188000078\n",
            "disc_loss 0.656851292 gen_loss 1.30301571 LR 0.000187000085\n",
            "disc_loss 0.63303721 gen_loss 1.34242737 LR 0.000186000092\n",
            "disc_loss 0.675143957 gen_loss 1.32764983 LR 0.000185000099\n",
            "disc_loss 0.624659717 gen_loss 0.690569758 LR 0.000184000106\n",
            "disc_loss 0.718441248 gen_loss 1.75851917 LR 0.000183000113\n",
            "disc_loss 0.629766464 gen_loss 2.19196439 LR 0.00018200012\n",
            "disc_loss 0.792782187 gen_loss 2.3517108 LR 0.000181000127\n",
            "disc_loss 0.672099471 gen_loss 0.42196694 LR 0.000180000134\n",
            "disc_loss 0.649974465 gen_loss 1.54754257 LR 0.000179000141\n",
            "disc_loss 0.636775 gen_loss 1.87713611 LR 0.000178000148\n",
            "disc_loss 0.639090896 gen_loss 1.23435092 LR 0.000177000155\n",
            "disc_loss 0.600594163 gen_loss 1.45945251 LR 0.000176000161\n",
            "disc_loss 0.544937968 gen_loss 2.33821177 LR 0.000175000168\n",
            "disc_loss 0.783306956 gen_loss 1.65870881 LR 0.000174000175\n",
            "disc_loss 0.599975944 gen_loss 0.508802235 LR 0.000173000182\n",
            "disc_loss 0.671416044 gen_loss 1.76012921 LR 0.000172000189\n",
            "disc_loss 0.541429937 gen_loss 1.83114111 LR 0.000171000196\n",
            "disc_loss 0.595154524 gen_loss 1.1745286 LR 0.000170000203\n",
            "disc_loss 0.525331378 gen_loss 0.709772289 LR 0.00016900021\n",
            "disc_loss 0.688884079 gen_loss 2.17798328 LR 0.000168000217\n",
            "disc_loss 0.656921744 gen_loss 1.82012773 LR 0.000167000224\n",
            "disc_loss 0.529160678 gen_loss 0.737790167 LR 0.000166000231\n",
            "disc_loss 0.766516924 gen_loss 1.99504507 LR 0.000165000238\n",
            "disc_loss 0.849674106 gen_loss 2.35268545 LR 0.000164000245\n",
            "disc_loss 0.530549347 gen_loss 1.33567357 LR 0.000163000252\n",
            "disc_loss 0.605034173 gen_loss 1.77823055 LR 0.000162000259\n",
            "disc_loss 0.589079916 gen_loss 1.81013393 LR 0.000161000266\n",
            "disc_loss 0.514583707 gen_loss 0.869586 LR 0.000160000272\n",
            "disc_loss 0.692711592 gen_loss 1.94277596 LR 0.000159000279\n",
            "disc_loss 1.68364465 gen_loss 1.21545637 LR 0.000158000286\n",
            "disc_loss 0.752330661 gen_loss 2.11710262 LR 0.000157000293\n",
            "disc_loss 0.965743423 gen_loss 1.72964406 LR 0.0001560003\n",
            "disc_loss 0.585901 gen_loss 0.777493656 LR 0.000155000307\n",
            "disc_loss 0.626409769 gen_loss 1.29771709 LR 0.000154000314\n",
            "disc_loss 0.709564686 gen_loss 1.01889443 LR 0.000153000321\n",
            "disc_loss 0.625595 gen_loss 0.951412559 LR 0.000152000328\n",
            "disc_loss 0.703191102 gen_loss 1.80088949 LR 0.000151000335\n",
            "disc_loss 0.758052409 gen_loss 1.14587653 LR 0.000150000342\n",
            "disc_loss 0.776247144 gen_loss 1.33074701 LR 0.000149000349\n",
            "disc_loss 0.680200756 gen_loss 1.77813601 LR 0.000148000356\n",
            "disc_loss 0.717954218 gen_loss 1.04279113 LR 0.000147000363\n",
            "disc_loss 0.553719521 gen_loss 1.05808747 LR 0.00014600037\n",
            "disc_loss 0.717497706 gen_loss 1.46251452 LR 0.000145000377\n",
            "disc_loss 0.620999455 gen_loss 1.15674376 LR 0.000144000383\n",
            "disc_loss 0.722267747 gen_loss 0.696317554 LR 0.00014300039\n",
            "disc_loss 0.633628 gen_loss 1.08648849 LR 0.000142000397\n",
            "disc_loss 0.759184659 gen_loss 1.62445951 LR 0.000141000404\n",
            "disc_loss 0.484327972 gen_loss 1.20644426 LR 0.000140000411\n",
            "disc_loss 0.666937411 gen_loss 0.768436074 LR 0.000141000404\n",
            "disc_loss 0.834536314 gen_loss 1.88606524 LR 0.000140000411\n",
            "disc_loss 0.634417593 gen_loss 2.45269203 LR 0.000139000418\n",
            "disc_loss 0.555126667 gen_loss 1.73593307 LR 0.000138000425\n",
            "disc_loss 0.599222481 gen_loss 0.723492146 LR 0.000137000432\n",
            "disc_loss 1.01994562 gen_loss 2.04250288 LR 0.000136000439\n",
            "disc_loss 1.00089717 gen_loss 2.0308342 LR 0.000135000446\n",
            "disc_loss 0.693224847 gen_loss 1.12805533 LR 0.000134000453\n",
            "disc_loss 0.669959 gen_loss 1.33537149 LR 0.00013300046\n",
            "disc_loss 0.522383 gen_loss 1.77948928 LR 0.000132000467\n",
            "disc_loss 0.564669 gen_loss 1.36390495 LR 0.000131000474\n",
            "disc_loss 0.488161027 gen_loss 0.79196918 LR 0.000130000481\n",
            "disc_loss 0.444861472 gen_loss 2.22593904 LR 0.000131000474\n",
            "disc_loss 0.473089516 gen_loss 1.6233592 LR 0.000132000467\n",
            "disc_loss 0.528337 gen_loss 1.59832883 LR 0.00013300046\n",
            "disc_loss 0.519559741 gen_loss 2.41553164 LR 0.000132000467\n",
            "disc_loss 0.506786 gen_loss 1.56806409 LR 0.000131000474\n",
            "disc_loss 0.327918261 gen_loss 1.30756807 LR 0.000130000481\n",
            "disc_loss 0.614175916 gen_loss 2.79774141 LR 0.000131000474\n",
            "disc_loss 0.47140938 gen_loss 0.363140285 LR 0.000130000481\n",
            "disc_loss 0.553415477 gen_loss 2.46140385 LR 0.000131000474\n",
            "disc_loss 0.564173639 gen_loss 1.08118486 LR 0.000130000481\n",
            "disc_loss 0.431326687 gen_loss -0.169252723 LR 0.000129000488\n",
            "disc_loss 1.37271321 gen_loss 1.67485213 LR 0.000130000481\n",
            "disc_loss 0.666412175 gen_loss 2.12718 LR 0.000129000488\n",
            "disc_loss 0.517034173 gen_loss 0.564377904 LR 0.000128000494\n",
            "disc_loss 0.716285169 gen_loss 1.95589447 LR 0.000127000501\n",
            "disc_loss 0.382368773 gen_loss 2.58998322 LR 0.000126000508\n",
            "disc_loss 0.567932487 gen_loss 0.881117642 LR 0.000127000501\n",
            "disc_loss 0.531783342 gen_loss 0.810904264 LR 0.000126000508\n",
            "disc_loss 0.638809204 gen_loss 2.48314953 LR 0.000125000515\n",
            "disc_loss 0.717418909 gen_loss 1.70931089 LR 0.000124000522\n",
            "disc_loss 0.66189903 gen_loss 0.807410717 LR 0.000123000529\n",
            "disc_loss 0.722329736 gen_loss 1.41156077 LR 0.000122000529\n",
            "disc_loss 0.526625574 gen_loss 2.07847095 LR 0.000121000528\n",
            "disc_loss 0.52676475 gen_loss 1.69438052 LR 0.000120000528\n",
            "disc_loss 0.523368239 gen_loss 1.96853185 LR 0.000119000528\n",
            "disc_loss 0.677832782 gen_loss 1.19017386 LR 0.000118000527\n",
            "disc_loss 0.494021714 gen_loss 1.0381546 LR 0.000117000527\n",
            "disc_loss 0.642529607 gen_loss 2.49834728 LR 0.000118000527\n",
            "disc_loss 0.636599422 gen_loss 1.03338122 LR 0.000117000527\n",
            "disc_loss 0.808811426 gen_loss 1.46895981 LR 0.000116000527\n",
            "disc_loss 0.701414168 gen_loss -1.76635551 LR 0.000115000526\n",
            "disc_loss 1.49933016 gen_loss 2.59962177 LR 0.000114000526\n",
            "disc_loss 0.601666093 gen_loss -0.628610611 LR 0.000113000526\n",
            "disc_loss 1.34567297 gen_loss 2.35255885 LR 0.000112000525\n",
            "disc_loss 1.2541821 gen_loss 0.854374766 LR 0.000111000525\n",
            "disc_loss 0.968812823 gen_loss 1.98443794 LR 0.000110000525\n",
            "disc_loss 1.57713556 gen_loss 1.8480773 LR 0.000109000524\n",
            "disc_loss 0.884194136 gen_loss 1.11789286 LR 0.000108000524\n",
            "disc_loss 1.01905596 gen_loss 0.731508136 LR 0.000107000524\n",
            "disc_loss 0.845176339 gen_loss 1.30630398 LR 0.000106000523\n",
            "disc_loss 0.909814119 gen_loss 0.843161702 LR 0.000105000523\n",
            "disc_loss 0.823767126 gen_loss 1.37560689 LR 0.000104000523\n",
            "disc_loss 0.907479882 gen_loss 0.727754295 LR 0.000103000522\n",
            "disc_loss 0.78640759 gen_loss 1.50112724 LR 0.000102000522\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-07e8ee322a97>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx_train2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx_train2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_train2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-3e7c8cbb4ec1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, y_train, epochs)\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mdigits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdigits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Save the model every 15 epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-bc0095d4c81e>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(real_images, digits)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# Update generator and discriminator variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mgradients_of_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mgenerator_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients_of_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1061\u001b[0m                           for x in output_gradients]\n\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1064\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    144\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_LeakyReluGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    447\u001b[0m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m   \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"alpha\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_nn_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mleaky_relu_grad\u001b[0;34m(gradients, features, alpha, name)\u001b[0m\n\u001b[1;32m   5803\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5804\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5805\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   5806\u001b[0m         _ctx, \"LeakyReluGrad\", name, gradients, features, \"alpha\", alpha)\n\u001b[1;32m   5807\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "EPOCHS = 100\n",
        "x_train2 = np.expand_dims(x_train, axis=-1)\n",
        "x_train2 = (x_train2 - np.min(x_train2)) / (np.max(x_train2) - np.min(x_train2))\n",
        "train(x_train2,y_train, EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "9vPp5AiDkrAF",
        "outputId": "3c959456-7e4f-43b7-8f0b-afabe51f7683",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n",
            "tf.Tensor([3], shape=(1,), dtype=int32)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAyZklEQVR4nO3de3SU9bkv8O9MkplMbpP7jVwI1wghURFiilKECMSWonC6va290bp0a4Onynbbsk/rrXuvWLtX6+VQPPvUgu4lorSiVStWUUKtBCUSuRpJDCSQC9dkkkkymcy85w+PaaMgzxMSfkn4ftaatUjmy5Pf+74z8+TNzDxjsyzLAhER0XlmN70AIiK6MLEBERGREWxARERkBBsQEREZwQZERERGsAEREZERbEBERGQEGxARERkRanoBXxUMBtHY2Ijo6GjYbDbTyyEiIiXLstDe3o709HTY7Wc+zxl2DaixsRGZmZmml0FEROeooaEBGRkZZ7x+yBrQqlWr8Mtf/hLNzc0oKCjAU089hZkzZ571/0VHRwMAfvH8/XBFOEU/a0x9uHhdvZnbxVkA2Fy3RJy97pKPVLWPNkeJs/HWSVXtkyejxdkQ5yRV7eaeRlUeBzvE0T8l56pK3xz5vDgbb/uuqnZ9YpM4u7PrclXt695rUeX/kLFHnE3Yt19VO3tavDh77KhDVdsKuUicjS/S3cajm3PE2Uu+9Zmqds0nWaq8PfawONvU5lLV7q6VP04cGS9fBwDEtY8RZ7tiIsRZX1c3nvrRQ32P52cyJA3oxRdfxIoVK/D000+jsLAQjz/+OBYsWIDq6mokJyd/4//98s9urggnXJGyxhLpkjcgf2SYOAsADpd8p0dGyRrmlyKEDRYAIi3dHb+7S147xKm7Q7hC5PsbAOD0i6Ohiv0NABEu+U040qbcTsXxcdh064506NbiCJevxRmmu1u7wuX3iXCn7v5jKW4rmv0NAC6XfB9Gae+biscUALAr1u7q0a0FTvlanC7d40R4r7x2ULlPAJz1aZQheRHCr371K9x+++249dZbMWXKFDz99NOIiIjA7373u6H4cURENAINegPq6elBZWUliouL//ZD7HYUFxdj27ZtX8v7fD54PJ5+FyIiGv0GvQEdP34cgUAAKSkp/b6fkpKC5ubmr+XLysrgdrv7LnwBAhHRhcH4+4BWrlyJtra2vktDQ4PpJRER0Xkw6C9CSExMREhICFpa+r/Kp6WlBampqV/LO51OOJ3KJ+WIiGjEG/QzIIfDgenTp2Pz5s193wsGg9i8eTOKiooG+8cREdEINSQvw16xYgWWLVuGyy67DDNnzsTjjz8Or9eLW2+9dSh+HBERjUBD0oCuv/56HDt2DA888ACam5tx8cUXY9OmTV97YQIREV24hmwSwvLly7F8+fIB//+xvW5E+mVvNNs8rldc97axN6vW8XHwc3E21D5RVftU7Ifi7GUx/6Cq/alN/nL2K2LyVLU/r9X95TYzvkKcdfbq3g1/tNctzm76/DVV7YKk74izU3a9rqr9Z79uIkfCWz5xtiNSN2Wh6eRYcXZPs+4NtDcV94izcSHXqWq/knJCnF3Qo7vfu1y/UeXjx0wQZ98/IJ+wAQAhdS+Js80f6N6I6ptzuzgbv3+3OBvSIzvuxl8FR0REFyY2ICIiMoINiIiIjGADIiIiI9iAiIjICDYgIiIygg2IiIiMYAMiIiIj2ICIiMgINiAiIjJiyEbxnKswx2GECT+mYfyJRHndabpRFdlj5SNQYvy5qtqpqQfF2XZHvap2a3urOHu89TNV7bj0g6r89ni/OHvd5mOq2m8svU+czf3WQ6ra9v87SZytn/JbVe1PNsxQ5bvSD4izyfXtqtrTw+WjrELrdPefjfkx4uwVU+SjdQDgRku+T2zpharan56cq8p/99QWcTaqXT6eCADePvj1j7E5k5ywJFXt+oj3xdmIyHxx1hfaLcrxDIiIiIxgAyIiIiPYgIiIyAg2ICIiMoINiIiIjGADIiIiI9iAiIjICDYgIiIygg2IiIiMYAMiIiIj2ICIiMiIYTsL7rOEi+GKihBl26JPiesGT05TrePyuCpxNrytQFU7NXyCODumWzcLbn7uE+Lsx683qmq/9OR/qvIhac+Ls9dN+LOqdvgTO8TZQ8ny2wkAhB97Upy9KqCr/ZHrRVX+3kbZXEQA+HmXV1W7Nlo+r80WuU9VO+/PUeKsy1+pqv3O+BBxdkl4l6p2w1//pMq/kdkqzl6cJp9hBwCfuOXnCdOKilW1nwmTzzAcExcpzvZ0y+bd8QyIiIiMYAMiIiIj2ICIiMgINiAiIjKCDYiIiIxgAyIiIiPYgIiIyAg2ICIiMoINiIiIjGADIiIiI4btKJ6IziZE2MJF2ULkiOs6w/6gWseOxu+Ks/PSPararYFD8nDH71S1rfZx4uyhcUtVtdPuX6fKJzTtFWcbfbqb5LXlAXH2qcu/p6od4dsvzjrHyMfZAMBNR3XbuX6MfBTP5PY2VW3b/mZx9tOeVFXtSbFV4mxCQpqq9vcyLxJnA4d3qWp3Fy1W5SM3HBRnP4zX3VayIuQju5q3bVfVdu2RP775CixxtscvG5PEMyAiIjKCDYiIiIxgAyIiIiPYgIiIyAg2ICIiMoINiIiIjGADIiIiI9iAiIjICDYgIiIygg2IiIiMYAMiIiIjhu0suNkZ30F0dLQoe8QunwfmiJ6qWsfzn8tmGgHA7LZPVbX/Et4tzs5K+1+q2tsb5PO9ij86oKr9xz3lqnzVVvn8MOc1Para+7BTnE357BNV7QMvuMTZYxN16w4JOanKR3XL1/LXoOx+86X0kghx9uiTR1S1Z1w5XZz1rK5W1X79Mvnvz/meN1S14z6U728A+K8w+Ry7kN4pqtpHIp4VZzODQVXtY7Z2cbY6J1Kc7fX1inI8AyIiIiMGvQE99NBDsNls/S65ubmD/WOIiGiEG5I/wU2dOhXvvPPO335I6LD9Sx8RERkyJJ0hNDQUqam6zw0hIqILy5A8B3TgwAGkp6dj3LhxuPnmm1FfX3/GrM/ng8fj6XchIqLRb9AbUGFhIdauXYtNmzZh9erVqKurw5VXXon29tO/2qKsrAxut7vvkpmZOdhLIiKiYWjQG1BJSQm+//3vIz8/HwsWLMCf/vQntLa24qWXXjptfuXKlWhra+u7NDQ0DPaSiIhoGBryVwfExsZi0qRJqKmpOe31TqcTTqf88+6JiGh0GPL3AXV0dKC2thZpafI3ahER0eg36A3ovvvuQ3l5OQ4ePIgPPvgA1113HUJCQnDjjTcO9o8iIqIRbND/BHf48GHceOONOHHiBJKSknDFFVegoqICSUlJqjp7w3oQGeYTZW098jEbkViqWsf3LpGPB/F2F6hqZ7TtFWcTu3Vjfgq6WuXriNCdnaaFZ6nyeZNjxNk6r27Uy+HP5eNBmrp1L3Cx0veLs/9gC1PVfj+kWJVP6KgQZ6Ptut8rv/2GX5ytCJGPvQKATX/6TJx1Fegejkq2nhBnX8yZpqp9IF83zijRLn/u2rX7lKr27kOJ4qzTKb8/AIDXvluc7XzrW+JsIGAT5Qa9Aa1fv36wSxIR0SjEWXBERGQEGxARERnBBkREREawARERkRFsQEREZAQbEBERGcEGRERERrABERGREWxARERkBBsQEREZMeQfxzBQmd4qRNkjRNmnj8vnH42NcqvWkbSlR5x1dunmZDUc2SnOOu7ep6rds6ZRnG327lHV/mjPZFXe1vauODv7hG4fZiY6xFmrV/dpuzWt8mPf69Ktu71jkyp/caj8rlrVEaKq/fJM+dq9tbrfWRde2i3OPrujVVU7eb782O/94+eq2qesBFV+p+ekOJs6tUpVO8kbLs56vbp1B1M6xNlLrpLPu+vpCWDXgbPneAZERERGsAEREZERbEBERGQEGxARERnBBkREREawARERkRFsQEREZAQbEBERGcEGRERERrABERGREcN2FE8wMAnB3ihRNq2xVVz3cNpB1TqaF8jHT1S2yEcCAcCYrmxxNvx/y8eOAEDNhHZx9viaG1S1Q2e9qcoff9Ylzr6cGaeqHXkqVZzNu0o3iufkW/XibPWELFXtGe9lqPIfTJaNpQKAmLo/qmo76+PF2cSeCaraHxzcLc6mNcnXAQAlf5GPEHrn2DRV7bgo+YgaAAj6jouzzupLVLUDAfl9vztcfr8HgN4G+bp3HpXXDviDohzPgIiIyAg2ICIiMoINiIiIjGADIiIiI9iAiIjICDYgIiIygg2IiIiMYAMiIiIj2ICIiMgINiAiIjKCDYiIiIwYtrPgPq/+CBERshlirW0TxXUv+W2Vah2BQK042/TxM6rau+K6xNmE8CRV7Y891eJsw76tqtqz62NV+aauNnE20pLPxwOAQPADcbaqsUBVuxOd4mxjU4Kq9seu11X5uOZEcbajPURVe8Mp+XbG9H6oqp1slz/EVFvdqto/gXyfhIVsV9X2OvNU+aBHPgfy1EUHVLXbK8PF2XzrpKr2bpts3iYAJO+R38Z7AwEAZ5+jyTMgIiIygg2IiIiMYAMiIiIj2ICIiMgINiAiIjKCDYiIiIxgAyIiIiPYgIiIyAg2ICIiMoINiIiIjGADIiIiI4btLLgt/o/h8DtE2cimN8R1/0/mONU6Jta3iLNbOgOq2p86UsTZuGPydQDAOG+0OBvp1617U1erKt8REybOXnqiR1X7g2CmODuhRj7XDwAaQ+V3j0m7dTPSjoTeqMqfjNogznbBpqq94IRTnN0RtFS1a6vSxdmg7XNV7dzDXnF2J3Sz3Rzug6p8eKtPnM3YvUBVu95WJc7udV2sqm2zy2s3efPF2UCwB8AnZ83xDIiIiIxQN6CtW7di0aJFSE9Ph81mwyuvvNLvesuy8MADDyAtLQ0ulwvFxcU4cEA3/ZWIiEY/dQPyer0oKCjAqlWrTnv9Y489hieffBJPP/00tm/fjsjISCxYsADd3bpR60RENLqpnwMqKSlBSUnJaa+zLAuPP/44fvrTn2Lx4sUAgOeeew4pKSl45ZVXcMMNN5zbaomIaNQY1OeA6urq0NzcjOLi4r7vud1uFBYWYtu2baf9Pz6fDx6Pp9+FiIhGv0FtQM3NzQCAlJT+r+5KSUnpu+6rysrK4Ha7+y6ZmfJXNRER0chl/FVwK1euRFtbW9+loeHsH+NKREQj36A2oNTUVABAS0v/96y0tLT0XfdVTqcTMTEx/S5ERDT6DWoDysnJQWpqKjZv3tz3PY/Hg+3bt6OoqGgwfxQREY1w6lfBdXR0oKampu/ruro6VFVVIT4+HllZWbjnnnvw7//+75g4cSJycnLws5/9DOnp6bj22msHc91ERDTCqRvQjh07cNVVV/V9vWLFCgDAsmXLsHbtWtx///3wer2444470NraiiuuuAKbNm1CeHi46udMdjjhcshG8ez1Z4vrLhwrHwsDAFtzxouzgb8cU9UusS4SZ1+2f6aqPTY0KM5WxrWqao+z6Y5lzSn5aJgjyftVtVOi5GNkGgNjVLU7Yg6Js3af7q4UHvy9Kh/aECfOdoS2q2p7nR3y2kHddk5RxPd16mrH54WIs1FHWlW1Q+ojVfn0xHhxtjepXFXb7pXfly87pXsVcU2O/I9g37mk5uyh/8/X04u9L509p25Ac+bMgWWdeR6UzWbDI488gkceeURbmoiILiDGXwVHREQXJjYgIiIygg2IiIiMYAMiIiIj2ICIiMgINiAiIjKCDYiIiIxgAyIiIiPYgIiIyAg2ICIiMkI9iud8CUS4EIiUzfmamtQprrsjeFC1jjkfzhFnbYm63flh6E5x9rJoXW37THl+4i/OPFrpdKrjYlX5fMiPz22XTVHVvmNTqzibEJerqu050SvOtrkDqtpzO+S1AaAiXz7DMHS/bhZccso4cfbiar+q9lHFnMEJfvnMMwCYFogWZ1td8rlxAND7A/mMQQA49qZ8v1zhmKSq3X7yoDj7ZiBKVTvrcJc42x0vvx/7emX3B54BERGREWxARERkBBsQEREZwQZERERGsAEREZERbEBERGQEGxARERnBBkREREawARERkRFsQEREZMSwHcWT130ZIu0RouzeMX8Q1705e7FqHY8eOCrO/mBqoar2xyl/FWe/075UVdvXWivObprbpKo9eXy3Kn/8jzHi7J7IBFVtK3yzODshY4yq9mdNstsfAOwNO6mqvcs6ocpPPZgizp7s1f1eudV7XJx1BnWjeOyeLHH2UEysqvYr/3yZOFscSFLVTo+5QpX/5JM/i7NtIbqxQLMVE4r2FzpUteeeuF6cdcyRH/tunw/Y9slZczwDIiIiI9iAiIjICDYgIiIygg2IiIiMYAMiIiIj2ICIiMgINiAiIjKCDYiIiIxgAyIiIiPYgIiIyAg2ICIiMmLYzoJrSKxERKRTlHUfls95OhEZqVrHpdmJ4mxY9Qeq2jMbs8XZgh/Vq2pXNOSJs3cccalqP3u5bq7W4mflN7Pt1c+paieEpYuze0J3qmrbpjWKs9fUyfc3APyxc4IqfyBynzjbG6Wb15bSlCPOHopwq2pHJh4RZy/pDlPVvvpZ+Qy7nEU9qtr/ffA/VfkrfiSfeRcvH9MIAEg/4ZOvo2Oqqva8zD+Ks9uOyOfjhfbI9jfPgIiIyAg2ICIiMoINiIiIjGADIiIiI9iAiIjICDYgIiIygg2IiIiMYAMiIiIj2ICIiMgINiAiIjLCZlmWZXoRf8/j8cDtduO9D15EVFSE6P+UB46K69+aNFm1npYDu8RZd2aCqnajlSbOjnU0qWrX41Vxtudz3ViYxn0ndWtplo9Mybp4v6r2joPfEmcP/kK+vwFgV/YfxNm8dt2opBZfvCq/vz0ozp4KOaaqfU26/CHg08MZqtpL3LL7MADghxNVta/OlY+EmpBYqqr9RuImVX6J+1ZxdnftGlXt/HHytXf5tqpqtyfJRwjZDnwsznZ0dGJm4W1oa2tDTEzMGXM8AyIiIiPYgIiIyAh1A9q6dSsWLVqE9PR02Gw2vPLKK/2uv+WWW2Cz2fpdFi5cOFjrJSKiUULdgLxeLwoKCrBq1aozZhYuXIimpqa+ywsvvHBOiyQiotFH/XlAJSUlKCkp+caM0+lEamrqgBdFRESj35A8B7RlyxYkJydj8uTJuOuuu3DixIkzZn0+HzweT78LERGNfoPegBYuXIjnnnsOmzdvxi9+8QuUl5ejpKQEgUDgtPmysjK43e6+S2Zm5mAviYiIhqFB/0juG264oe/f06ZNQ35+PsaPH48tW7Zg3rx5X8uvXLkSK1as6Pva4/GwCRERXQCG/GXY48aNQ2JiImpqak57vdPpRExMTL8LERGNfkPegA4fPowTJ04gLU33LnQiIhrd1H+C6+jo6Hc2U1dXh6qqKsTHxyM+Ph4PP/wwli5ditTUVNTW1uL+++/HhAkTsGDBgkFdOBERjWzqBrRjxw5cddVVfV9/+fzNsmXLsHr1auzatQvPPvssWltbkZ6ejvnz5+PnP/85nE6n6ufEJLciKtonyoYdkf/ZznLo5pjVxMqfjypwvKGqfcy6Q5xN72xQ1f7MvkicnR0zXlX7zVm/UuVvORonzv73zvmq2sWXXirO+ja/rqpd92KPOJt7cKqq9hPbFDPSAEyd7RBnj2yuVtW+5Er5bTzMo5thdyBcPgdwiUc37zA5/jvibHTeblVtx55rVHl3+g5xdvNk+X0TAGZFdomzzUfCVLUnBbzi7P62y8TZHm+7KKduQHPmzME3zS996623tCWJiOgCxFlwRERkBBsQEREZwQZERERGsAEREZERbEBERGQEGxARERnBBkREREawARERkRFsQEREZAQbEBERGTHonwc0WCK6chAZGinKJvrln6IaFp2gWsfRSPnsOJf3ZlXtjv114qzj25NUtRNa5PlAkl9Ve1aNfP4aAPgiZoiziRk7VbUde+RzsmISblLVjj2ULs7+peiQqnZY9XZVPtAzTpxt7S1U1a5PShZnD+/XrXvmP4SLs6GJP1TV3h4nPz43HZ6oqn1p3j5VHrhcnJwRIp+/BgAh3fK5geHpGaraoTb5HMDmMfLHK297UJTjGRARERnBBkREREawARERkRFsQEREZAQbEBERGcEGRERERrABERGREWxARERkBBsQEREZwQZERERGDNtRPIfDvIgMk2V7E23iuiGBWNU6ksJlIyUAICRengUARI0VRyMcH+tKn0oSZzvGyEYefSkZulEiyfYmcTYzboqqdiDsHXH2rVcOqmqPXSLPHt6lKo25M+UjUADgv50OcbbAVqOqnbG3TZztilGVxpQP5GN+YhbVqmoHP5GP+eks0Y3WsXlDdPk4+T7s9rtVta2IVnE2tFU3agxx8sfOi2J6xNl2yLI8AyIiIiPYgIiIyAg2ICIiMoINiIiIjGADIiIiI9iAiIjICDYgIiIygg2IiIiMYAMiIiIj2ICIiMgINiAiIjJi2M6CizmZiqieKFF2X6hfXHd2MFW1jksTT4mzUbaZutqxLeKs1/U9Ve2peT5x9uhu3Qy7Uwm3qPLdafK1oHudqva4bfI5du9eeVxVOzcxV5yN65XfTgAgkB2tyue/I68fN0k+swsAJl97RJz97snlqtpbEuWz4KZOy1bV7rLJHh8AINJKU9X2xMj3CQDYFPPdvh3eqaptD8jnu8XEBVS1bYoWEG2fIM5ado8oxzMgIiIygg2IiIiMYAMiIiIj2ICIiMgINiAiIjKCDYiIiIxgAyIiIiPYgIiIyAg2ICIiMoINiIiIjBi2o3gORh9ARHSEKDvjpHy8Tphjn2odn/VOFWdTXUdVtd0++e6PCX6uqv17v3z0yDV5O1S1e/zxqnxvQL5f9nZ9X1V75vxj4mzGR7rj47f+Is56HUtVtSdG646n85pacbakbqKq9qZG+agX9wSbqnZuVLM4G2Efq6p95KA8m5Er338AEOiOVeVt4V3ibHVnmKp2SqRXnPV2O1S148I7xNnmBvk6OjraRTmeARERkRGqBlRWVoYZM2YgOjoaycnJuPbaa1FdXd0v093djdLSUiQkJCAqKgpLly5FS4t86CYREV0YVA2ovLwcpaWlqKiowNtvvw2/34/58+fD6/3bqdm9996L1157DRs2bEB5eTkaGxuxZMmSQV84ERGNbKrngDZt2tTv67Vr1yI5ORmVlZWYPXs22tra8Mwzz2DdunWYO3cuAGDNmjW46KKLUFFRgcsvv3zwVk5ERCPaOT0H1NbWBgCIj//iSenKykr4/X4UFxf3ZXJzc5GVlYVt27adtobP54PH4+l3ISKi0W/ADSgYDOKee+7BrFmzkJeXBwBobm6Gw+FAbGxsv2xKSgqam0//apiysjK43e6+S2Zm5kCXREREI8iAG1BpaSn27NmD9evXn9MCVq5ciba2tr5LQ0PDOdUjIqKRYUDvA1q+fDlef/11bN26FRkZGX3fT01NRU9PD1pbW/udBbW0tCA19fTv1XE6nXA6nQNZBhERjWCqMyDLsrB8+XJs3LgR7777LnJycvpdP336dISFhWHz5s1936uurkZ9fT2KiooGZ8VERDQqqM6ASktLsW7dOrz66quIjo7ue17H7XbD5XLB7Xbjtttuw4oVKxAfH4+YmBjcfffdKCoq4ivgiIioH1UDWr16NQBgzpw5/b6/Zs0a3HLLLQCAX//617Db7Vi6dCl8Ph8WLFiA3/zmN4OyWCIiGj1UDciyrLNmwsPDsWrVKqxatWrAiwKAy05NRbQ/SpR9OVM+DyyuJ+fsob9zJLRTnLW162ak7Y2oEGcvt12mqp0m23UAAH/3AlXtP/qrVPl/DLtKnL0i4uy3sb/n+PS4OBsVq5u/FpcwXZw92aib9hFsO6DKX9F0kTibOGa7qnbitEvE2TG7p6lq1856WZx1+JJUtY9PbBJnQwPy/QcAceHyGXYAYAvKn8fuipDNuPwb+Xy3j50BVeUxitqHk/zirDdcNu+Os+CIiMgINiAiIjKCDYiIiIxgAyIiIiPYgIiIyAg2ICIiMoINiIiIjGADIiIiI9iAiIjICDYgIiIyYkAfx3A+VNv3ItIuG1mRVN0urttZOEG1jqmN9eKsJ1035ie7Z6w4a3P0qGof2X1UnL14gk1V+3q/7mYTEiUflfRZoEpVOzZsrDgb749R1XaHy0fUlOfKR84AwM1HrlHlGyZ/Js4WfJKiqh21Sf4pxE3f+6Wqdsyh68VZ/8Vdqtq9x3rl4eRDqtoRHS5V3oqWj+JpPaH71GcrMVKczWrTfbSNzS3PTnPJxusAQLufo3iIiGgYYwMiIiIj2ICIiMgINiAiIjKCDYiIiIxgAyIiIiPYgIiIyAg2ICIiMoINiIiIjGADIiIiI9iAiIjIiGE7Cy7Y2I1ghGxG2RbFDLaZO/2qdSROjhNne5vks5IAoCVSPstqTLBVVfvaKfKsw5Gmqt1tk+8TAIgLk8+xuzpcsXAAERMSxVnLN05V2x0rn6f3z23zVbVjMhNU+Yvt8u3c8e1qVe354WPEWV/ITaraRzNOirMuK0lVe3yKfF6bHbraKdE+Vd6y5Pf9vARLVdtmybczza2rDcjnQMbYFXPmhFmeARERkRFsQEREZAQbEBERGcEGRERERrABERGREWxARERkBBsQEREZwQZERERGsAEREZERbEBERGTEsB3F44/tgj9Slr3iuHxkSiDlQ9U6jjdeIs5OSDqlqh0ZKh/FY7fHqGpXde4VZwsdutE6DbY2VT4hxCPO2oPyYwkA7shPxdmjztmq2mHWYXG2IzVVVTslfLcqP+Z4ujg7Paj7vfK3oW5x9gfRn6tq97YeFGfD4gpVtZt9wgcIALkR8nFQANDc6lXlJ8SGi7P7eyNUtfMUjxPwK88pFNPDTvYGxNl2YZZnQEREZAQbEBERGcEGRERERrABERGREWxARERkBBsQEREZwQZERERGsAEREZERbEBERGQEGxARERnBBkREREYM21lwaDgGRMjmK52IbxWXtXYkq5ZRNeOgODvJ8x1V7VMpH4uz/sAYVe2OyJnirL1HPgsMAHrCdTPvQjBOnD0UbVPVTg3OE2frQv+iqj3Jli/ObvfrZo1d1H61Kv9y9H+Js//TsUhVezaSxNnQdt1t5Z24oDg7xa6r7XTJs3Y4VLXDYqNUec1QtZgQZWlL8TAdJt/fX5Df3+rt8qxXmOUZEBERGaFqQGVlZZgxYwaio6ORnJyMa6+9FtXV1f0yc+bMgc1m63e58847B3XRREQ08qkaUHl5OUpLS1FRUYG3334bfr8f8+fPh9fbf3T57bffjqampr7LY489NqiLJiKikU/1HNCmTZv6fb127VokJyejsrISs2f/7bNWIiIikKr8fBQiIrqwnNNzQG1tX3wwWXx8fL/vP//880hMTEReXh5WrlyJzs7OM9bw+XzweDz9LkRENPoN+FVwwWAQ99xzD2bNmoW8vLy+7990003Izs5Geno6du3ahR//+Meorq7Gyy+/fNo6ZWVlePjhhwe6DCIiGqEG3IBKS0uxZ88evP/++/2+f8cdd/T9e9q0aUhLS8O8efNQW1uL8ePHf63OypUrsWLFir6vPR4PMjMzB7osIiIaIQbUgJYvX47XX38dW7duRUZGxjdmCwu/+Jz3mpqa0zYgp9MJp9M5kGUQEdEIpmpAlmXh7rvvxsaNG7Flyxbk5OSc9f9UVVUBANLS0ga0QCIiGp1UDai0tBTr1q3Dq6++iujoaDQ3NwMA3G43XC4XamtrsW7dOlxzzTVISEjArl27cO+992L27NnIz5e/q5yIiEY/VQNavXo1gC/ebPr31qxZg1tuuQUOhwPvvPMOHn/8cXi9XmRmZmLp0qX46U9/OmgLJiKi0UH9J7hvkpmZifLy8nNa0JcaDx2CK1w2v6ktcExcd1/yFNU6Urrks+NqMg+oaoc1ff05sTOxZzapateflM9t6k1qUNWO6E5R5RHuF0fdpxJVpa3YneJs1gHdPD3b5Ghxtti+R1U7GKV7u8Gynn8UZ0MV9wcA2HFCftu6OKVdVbvQmy3OWjHf/PjyVbu75e8i+ZYroKqd1KN8h4pDvvYcn24tCJcPjwsJ6vah5o04BZZ83qFHmOUsOCIiMoINiIiIjGADIiIiI9iAiIjICDYgIiIygg2IiIiMYAMiIiIj2ICIiMgINiAiIjKCDYiIiIwY8OcBDbXe9LHodYWLslN6LhbXjXMdUa3DPlY+BiP3pG7MT92YLnE2EMxS1b4m8ZQ4Gwbdx6fnunRjZKyAfB+GR3WratsxTZxNyT6hqg3LJY4mhOlK21Ggyie4vOJsmBWnqv1P6R3ibIilG5V0iVs+GsaunCJzm0v+H2zK37WdsilgA5IdLh+T9QV5Pka7ExVCwmWPxwAQ0sNRPERENIyxARERkRFsQEREZAQbEBERGcEGRERERrABERGREWxARERkBBsQEREZwQZERERGsAEREZERbEBERGTEsJ0FlxjhQ0SELNvVEyWu63AfVa3DZt0szgYyO1W1DzTL15KbrKsd1hUpD0fpZrt1dPpU+aTwFnH2A1+MqnZ2WJ0429LuVNVOcJ4UZ3d15qlqfys6qMp3B2SztQDACd1t5cWA8I4G4NZQ+fxCAAgN9MrDIfJ1AIAnKJ97lmDX/a7dFtQdn3h7QJytg3w2IgDkQr6dnqB8HQCQaJevpblCPqex3SvL8gyIiIiMYAMiIiIj2ICIiMgINiAiIjKCDYiIiIxgAyIiIiPYgIiIyAg2ICIiMoINiIiIjGADIiIiI4btKJ6k7qsRaZONkzk26zlx3fCu+1Tr+Dw2Q5wt+FQ36qXrIvnIFJs9SVX70xD5KJHkoG78jdd1UJVPxDhx9lJnh6q2vSNLnA1JOKGqDbjEya5I3bGHXz5eBQD+FJTfVf+HU3c8P4dfnLUFw3W1Q1rF2YnKETUNil+fE1SVAa/yV/N4hImzNcq15Cqyp+w2Ve1EyPO+FPlYpZ4OWZZnQEREZAQbEBERGcEGRERERrABERGREWxARERkBBsQEREZwQZERERGsAEREZERbEBERGQEGxARERnBBkREREYM21lwVdGvwxUhm691UVu+uG70mGOqddgONYuznbkXq2rP88TJw7G6GVxRXe3irBWlm7+W4klW5RHdJI6GtMpn2AGAL6FLnO1p100Es6K6xdn4v8jnqQFAzxzdvLb5p+TH3+bU7cPM3h55OEx3O8wOKLYzRDcfLzSgyIfofteO79TNVEOEfC158pvsF+QjCZGmO/SqU5Ds8fKwxyPL8gyIiIiMUDWg1atXIz8/HzExMYiJiUFRURHefPPNvuu7u7tRWlqKhIQEREVFYenSpWhpaRn0RRMR0cinakAZGRl49NFHUVlZiR07dmDu3LlYvHgx9u7dCwC499578dprr2HDhg0oLy9HY2MjlixZMiQLJyKikU31HNCiRYv6ff0f//EfWL16NSoqKpCRkYFnnnkG69atw9y5cwEAa9aswUUXXYSKigpcfvnlg7dqIiIa8Qb8HFAgEMD69evh9XpRVFSEyspK+P1+FBcX92Vyc3ORlZWFbdu2nbGOz+eDx+PpdyEiotFP3YB2796NqKgoOJ1O3Hnnndi4cSOmTJmC5uZmOBwOxMbG9sunpKSgufnMryQrKyuD2+3uu2RmZqo3goiIRh51A5o8eTKqqqqwfft23HXXXVi2bBn27ds34AWsXLkSbW1tfZeGhoYB1yIiopFD/T4gh8OBCRMmAACmT5+Ojz76CE888QSuv/569PT0oLW1td9ZUEtLC1JTU89Yz+l0wumUvd+HiIhGj3N+H1AwGITP58P06dMRFhaGzZs3911XXV2N+vp6FBUVneuPISKiUUZ1BrRy5UqUlJQgKysL7e3tWLduHbZs2YK33noLbrcbt912G1asWIH4+HjExMTg7rvvRlFREV8BR0REX6NqQEePHsU//dM/oampCW63G/n5+Xjrrbdw9dVXAwB+/etfw263Y+nSpfD5fFiwYAF+85vfDGhhkcdtcLlk4zD29ISJ647zvq1ax8T0z8XZwBsPqGp/coX8T4/T23Tjclp6HOJsV5vuRHh3iHyfAEBur3ysyRFLN+olqbpXnD2W6FXV9jZFibPBNFVpBBrlt1kAqAiVvzp03slYVe3ikFPibEurYi4MgIgUeW17T7SqdkaUfISQv15+LAFg1xj57QoAZnaEiLOBMN28nN5W+X253eVT1Y4IkddufV9eu90rOzaqBvTMM8984/Xh4eFYtWoVVq1apSlLREQXIM6CIyIiI9iAiIjICDYgIiIygg2IiIiMYAMiIiIj2ICIiMgINiAiIjKCDYiIiIxgAyIiIiPU07CHmmVZAICuLvnYh+6wLnG23asbVeFv94uzrk7duBxvu3yUiMceUNXu9MtHbHj88m0EAG+IbqSNR74UeAO6ESjtHfLfobxOS1Xb45PnO3S7BB4odgqAztB2ee0Q3e+V7XZ5batd94GRvS55bX+P7vh0BOX3n0C7bvyN16O7HXq65KN42pWjeDxdilE8ft3jm0sxiqfdKz+WHZ1fZL98PD8Tm3W2xHl2+PBhfigdEdEo0NDQgIyMjDNeP+waUDAYRGNjI6Kjo2Gz/W2IpcfjQWZmJhoaGhATE2NwhUOL2zl6XAjbCHA7R5vB2E7LstDe3o709HTY7Wc+Ix92f4Kz2+3f2DFjYmJG9cH/Erdz9LgQthHgdo4257qdbrf7rBm+CIGIiIxgAyIiIiNGTANyOp148MEH4XTKP8RtJOJ2jh4XwjYC3M7R5nxu57B7EQIREV0YRswZEBERjS5sQEREZAQbEBERGcEGRERERoyYBrRq1SqMHTsW4eHhKCwsxIcffmh6SYPqoYcegs1m63fJzc01vaxzsnXrVixatAjp6emw2Wx45ZVX+l1vWRYeeOABpKWlweVyobi4GAcOHDCz2HNwtu285ZZbvnZsFy5caGaxA1RWVoYZM2YgOjoaycnJuPbaa1FdXd0v093djdLSUiQkJCAqKgpLly5FS0uLoRUPjGQ758yZ87Xjeeeddxpa8cCsXr0a+fn5fW82LSoqwptvvtl3/fk6liOiAb344otYsWIFHnzwQXz88ccoKCjAggULcPToUdNLG1RTp05FU1NT3+X99983vaRz4vV6UVBQgFWrVp32+sceewxPPvkknn76aWzfvh2RkZFYsGABuru7z/NKz83ZthMAFi5c2O/YvvDCC+dxheeuvLwcpaWlqKiowNtvvw2/34/58+fD6/3bFNZ7770Xr732GjZs2IDy8nI0NjZiyZIlBletJ9lOALj99tv7Hc/HHnvM0IoHJiMjA48++igqKyuxY8cOzJ07F4sXL8bevXsBnMdjaY0AM2fOtEpLS/u+DgQCVnp6ulVWVmZwVYPrwQcftAoKCkwvY8gAsDZu3Nj3dTAYtFJTU61f/vKXfd9rbW21nE6n9cILLxhY4eD46nZalmUtW7bMWrx4sZH1DJWjR49aAKzy8nLLsr44dmFhYdaGDRv6Mvv377cAWNu2bTO1zHP21e20LMv69re/bf3oRz8yt6ghEhcXZ/32t789r8dy2J8B9fT0oLKyEsXFxX3fs9vtKC4uxrZt2wyubPAdOHAA6enpGDduHG6++WbU19ebXtKQqaurQ3Nzc7/j6na7UVhYOOqOKwBs2bIFycnJmDx5Mu666y6cOHHC9JLOSVtbGwAgPj4eAFBZWQm/39/veObm5iIrK2tEH8+vbueXnn/+eSQmJiIvLw8rV65EZ2enieUNikAggPXr18Pr9aKoqOi8HsthN4z0q44fP45AIICUlJR+309JScGnn35qaFWDr7CwEGvXrsXkyZPR1NSEhx9+GFdeeSX27NmD6Oho08sbdM3NzQBw2uP65XWjxcKFC7FkyRLk5OSgtrYW//Zv/4aSkhJs27YNISHyz5EZLoLBIO655x7MmjULeXl5AL44ng6HA7Gxsf2yI/l4nm47AeCmm25CdnY20tPTsWvXLvz4xz9GdXU1Xn75ZYOr1du9ezeKiorQ3d2NqKgobNy4EVOmTEFVVdV5O5bDvgFdKEpKSvr+nZ+fj8LCQmRnZ+Oll17CbbfdZnBldK5uuOGGvn9PmzYN+fn5GD9+PLZs2YJ58+YZXNnAlJaWYs+ePSP+OcqzOdN23nHHHX3/njZtGtLS0jBv3jzU1tZi/Pjx53uZAzZ58mRUVVWhra0Nv//977Fs2TKUl5ef1zUM+z/BJSYmIiQk5GuvwGhpaUFqaqqhVQ292NhYTJo0CTU1NaaXMiS+PHYX2nEFgHHjxiExMXFEHtvly5fj9ddfx3vvvdfvY1NSU1PR09OD1tbWfvmRejzPtJ2nU1hYCAAj7ng6HA5MmDAB06dPR1lZGQoKCvDEE0+c12M57BuQw+HA9OnTsXnz5r7vBYNBbN68GUVFRQZXNrQ6OjpQW1uLtLQ000sZEjk5OUhNTe13XD0eD7Zv3z6qjyvwxaf+njhxYkQdW8uysHz5cmzcuBHvvvsucnJy+l0/ffp0hIWF9Tue1dXVqK+vH1HH82zbeTpVVVUAMKKO5+kEg0H4fL7zeywH9SUNQ2T9+vWW0+m01q5da+3bt8+64447rNjYWKu5udn00gbNv/zLv1hbtmyx6urqrL/+9a9WcXGxlZiYaB09etT00gasvb3d2rlzp7Vz504LgPWrX/3K2rlzp3Xo0CHLsizr0UcftWJjY61XX33V2rVrl7V48WIrJyfH6urqMrxynW/azvb2duu+++6ztm3bZtXV1VnvvPOOdemll1oTJ060uru7TS9d7K677rLcbre1ZcsWq6mpqe/S2dnZl7nzzjutrKws691337V27NhhFRUVWUVFRQZXrXe27aypqbEeeeQRa8eOHVZdXZ316quvWuPGjbNmz55teOU6P/nJT6zy8nKrrq7O2rVrl/WTn/zEstls1p///GfLss7fsRwRDciyLOupp56ysrKyLIfDYc2cOdOqqKgwvaRBdf3111tpaWmWw+GwxowZY11//fVWTU2N6WWdk/fee88C8LXLsmXLLMv64qXYP/vZz6yUlBTL6XRa8+bNs6qrq80uegC+aTs7Ozut+fPnW0lJSVZYWJiVnZ1t3X777SPul6fTbR8Aa82aNX2Zrq4u64c//KEVFxdnRUREWNddd53V1NRkbtEDcLbtrK+vt2bPnm3Fx8dbTqfTmjBhgvWv//qvVltbm9mFK/3gBz+wsrOzLYfDYSUlJVnz5s3raz6Wdf6OJT+OgYiIjBj2zwEREdHoxAZERERGsAEREZERbEBERGQEGxARERnBBkREREawARERkRFsQEREZAQbEBERGcEGRERERrABERGREWxARERkxP8D7zv6AM6RrXMAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "noise = tf.random.normal(shape=(1,100))\n",
        "random_number = tf.random.uniform(shape=[1,], minval=0, maxval=10, dtype=tf.int32)\n",
        "test = generator.predict((noise,random_number))\n",
        "print(random_number)\n",
        "plt.imshow(test.squeeze())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_r4IEg2iBLvP"
      },
      "outputs": [],
      "source": [
        "NOISE_DIM = 100\n",
        "GP_WEIGHT = 10\n",
        "\n",
        "\n",
        "#@tf.function\n",
        "def train_step(images,digits):\n",
        "\n",
        "\n",
        "    for i in range(3):\n",
        "      with tf.GradientTape() as disc_tapeU:\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        real_outputU = discriminatorU((images,digits), training=True)\n",
        "        fake_outputU = discriminatorU((generated_images,digits), training=True)\n",
        "        disc_lossU = cross_entropy(tf.ones_like(real_outputU), real_outputU)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      gradients_of_discriminatorU = disc_tapeU.gradient(disc_lossU, discriminatorU.trainable_variables)\n",
        "      discriminatorU_optimizer.apply_gradients(zip(gradients_of_discriminatorU, discriminatorU.trainable_variables))\n",
        "      if i == 0:\n",
        "        weights = discriminatorU.get_weights()\n",
        "\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tapeW:\n",
        "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "        generated_images = generator((noise,digits), training=True)\n",
        "\n",
        "        real_outputW = discriminatorW((images,digits), training=True)\n",
        "        fake_outputW = discriminatorW((generated_images,digits), training=True)\n",
        "        real_outputU = discriminatorU((images,digits), training=True)\n",
        "        fake_outputU = discriminatorU((generated_images,digits), training=True)\n",
        "        disc_lossW = discriminator_lossW(real_outputW, fake_outputW)\n",
        "\n",
        "\n",
        "        gen_lossU = cross_entropy(tf.ones_like(fake_outputU), fake_outputU)\n",
        "        gen_lossW = generator_lossW(fake_outputW)\n",
        "        gen_loss = gen_lossU#+gen_lossW\n",
        "\n",
        "        gp = gradient_penalty(images, generated_images, digits)\n",
        "        disc_lossW += gp * GP_WEIGHT\n",
        "\n",
        "\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    gradients_of_discriminatorW = disc_tapeW.gradient(disc_lossW, discriminatorW.trainable_variables)\n",
        "    discriminatorW_optimizer.apply_gradients(zip(gradients_of_discriminatorW, discriminatorW.trainable_variables))\n",
        "\n",
        "    discriminatorU.set_weights(weights)\n",
        "\n",
        "    tf.print(\"disc_lossW\",disc_lossW,'disc_lossU',disc_lossU,'gen_lossU',gen_lossU,'gen_lossW',gen_lossW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhuRFc0ro5T_"
      },
      "outputs": [],
      "source": [
        "print(np.min(x_train2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojIuJFIAybro"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}