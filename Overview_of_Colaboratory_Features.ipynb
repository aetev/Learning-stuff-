{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aetev/Learning-stuff-/blob/main/Overview_of_Colaboratory_Features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tf-agents[reverb]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avnZVDph6XDI",
        "outputId": "0b44e415-9e3d-4a15-e12e-9f4439077963"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tf-agents[reverb] in /usr/local/lib/python3.10/dist-packages (0.16.0)\n",
            "Requirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (1.4.0)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (2.2.1)\n",
            "Requirement already satisfied: gin-config>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (0.5.0)\n",
            "Requirement already satisfied: gym<=0.23.0,>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (0.23.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (1.22.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (8.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (1.16.0)\n",
            "Requirement already satisfied: protobuf>=3.11.3 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (3.20.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (1.14.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (4.5.0)\n",
            "Requirement already satisfied: pygame==2.1.3 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (2.1.3)\n",
            "Requirement already satisfied: tensorflow-probability~=0.19.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (0.19.0)\n",
            "Requirement already satisfied: rlds in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (0.1.8)\n",
            "Requirement already satisfied: dm-reverb~=0.11.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (0.11.0)\n",
            "Requirement already satisfied: tensorflow~=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (2.12.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from dm-reverb~=0.11.0->tf-agents[reverb]) (0.1.8)\n",
            "Requirement already satisfied: portpicker in /usr/local/lib/python3.10/dist-packages (from dm-reverb~=0.11.0->tf-agents[reverb]) (1.3.9)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym<=0.23.0,>=0.17.0->tf-agents[reverb]) (0.0.8)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (0.4.10)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (16.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (23.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (67.7.2)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (2.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-agents[reverb]) (0.32.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability~=0.19.0->tf-agents[reverb]) (4.4.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.12.0->tf-agents[reverb]) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow~=2.12.0->tf-agents[reverb]) (0.1.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow~=2.12.0->tf-agents[reverb]) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-agents[reverb]) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzGKkz097Pha",
        "outputId": "ec072b08-5e49-423d-a278-a524d1f4a01b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import abc\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import reverb\n",
        "\n",
        "import tf_agents as ta\n",
        "from tf_agents.networks import network\n",
        "import tensorflow_probability as tfp\n",
        "from tf_agents.policies import py_tf_eager_policy\n",
        "from tf_agents.replay_buffers import reverb_replay_buffer\n",
        "from tf_agents.replay_buffers import reverb_utils\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tf_agents.drivers import py_driver\n",
        "from tf_agents.utils import common\n",
        "import tensorflow as tf\n",
        "from tf_agents.agents.dqn import dqn_agent\n",
        "from tf_agents.networks import sequential\n",
        "from tf_agents.specs import tensor_spec\n",
        "from tf_agents.environments import py_environment\n",
        "from tf_agents.environments import tf_environment\n",
        "from tf_agents.environments import tf_py_environment\n",
        "from tf_agents.environments import utils\n",
        "from tf_agents.specs import array_spec\n",
        "from tf_agents.environments import wrappers\n",
        "from tf_agents.environments import suite_gym\n",
        "from tf_agents.trajectories import time_step as ts\n",
        "from tf_agents.policies import random_tf_policy\n",
        "from tf_agents.drivers import dynamic_step_driver"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "Qq7mHcz_6Znf",
        "outputId": "c781aaa1-1a37-4927-aec9-db5e5237e03a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0x10 but this version of numpy is 0xf"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_iterations = 20000 # @param {type:\"integer\"}\n",
        "\n",
        "initial_collect_steps = 100  # @param {type:\"integer\"}\n",
        "collect_steps_per_iteration =   1# @param {type:\"integer\"}\n",
        "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
        "\n",
        "batch_size = 64  # @param {type:\"integer\"}\n",
        "learning_rate = 1e-3  # @param {type:\"number\"}\n",
        "log_interval = 200  # @param {type:\"integer\"}\n",
        "\n",
        "num_eval_episodes = 2  # @param {type:\"integer\"}\n",
        "eval_interval = 1000  # @param {type:\"integer\"}"
      ],
      "metadata": {
        "id": "PDBocCSIMGmO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data.csv')\n",
        "df.pop(\"index\")\n",
        "del df[df. columns[0]]\n",
        "df = df.astype('float64')\n",
        "min = df.min()\n",
        "obsShape = len(df. columns)\n",
        "\n",
        "dfarray = df.to_numpy()\n",
        "dflist = dfarray.tolist()\n",
        "\n",
        "length = len(dflist)\n",
        "\n",
        "print(dflist[1][3])\n",
        "print(df)\n",
        "print(np.asarray(dflist).shape)\n",
        "#print(df.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMUkx9L17ZOZ",
        "outputId": "e2e839c3-e92d-4bbb-aa4d-14477ae4af9d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.0001999999999999\n",
            "       Direction  Bottom_Point  Top_Point  Relative_Change     Size   day  \\\n",
            "0            0.0      0.000000   0.666667         -0.00080  0.00120   2.0   \n",
            "1            0.0      0.444444   0.666667         -0.00020  0.00090   2.0   \n",
            "2            1.0      0.230769   0.846154          0.00080  0.00130   2.0   \n",
            "3            0.0      0.888889   0.888889          0.00000  0.00090   2.0   \n",
            "4            1.0      0.400000   0.700000          0.00030  0.00100   2.0   \n",
            "...          ...           ...        ...              ...      ...   ...   \n",
            "93075        1.0      0.575000   0.962500          0.00093  0.00240  29.0   \n",
            "93076        1.0      0.457317   0.682927          0.00037  0.00164  29.0   \n",
            "93077        0.0      0.422680   0.824742         -0.00039  0.00097  29.0   \n",
            "93078        1.0      0.634146   0.780488          0.00006  0.00041  29.0   \n",
            "93079        1.0      0.515152   0.969697          0.00015  0.00033  29.0   \n",
            "\n",
            "       month  weekday  hour_of_day  \n",
            "0        5.0      0.0          0.0  \n",
            "1        5.0      0.0          1.0  \n",
            "2        5.0      0.0          2.0  \n",
            "3        5.0      0.0          3.0  \n",
            "4        5.0      0.0          4.0  \n",
            "...      ...      ...          ...  \n",
            "93075    4.0      2.0         18.0  \n",
            "93076    4.0      2.0         19.0  \n",
            "93077    4.0      2.0         20.0  \n",
            "93078    4.0      2.0         21.0  \n",
            "93079    4.0      2.0         22.0  \n",
            "\n",
            "[93080 rows x 9 columns]\n",
            "(93080, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TradingEnv(py_environment.PyEnvironment):\n",
        "\n",
        "  \n",
        "  def __init__(self):\n",
        "    self._action_spec = array_spec.BoundedArraySpec(\n",
        "        shape=(), dtype=np.int32, minimum=0, maximum=1, name='action')\n",
        "    self._observation_spec = array_spec.BoundedArraySpec(\n",
        "        shape=(9,), dtype=np.float32, name='observation')\n",
        "    self.counter = 0\n",
        "    self.reward = 0\n",
        "    self._state = dflist[0]\n",
        "    self._episode_ended = False\n",
        "    self._reward_spec = array_spec.BoundedArraySpec(\n",
        "    shape=(1,), dtype=np.float32, minimum=-100.0, maximum=100.0, name='reward')\n",
        "\n",
        "  def action_spec(self):\n",
        "    return self._action_spec\n",
        "\n",
        "  def observation_spec(self):\n",
        "    return self._observation_spec\n",
        "\n",
        "  def _reset(self):\n",
        "    self._state = dflist[0]\n",
        "    self._episode_ended = False\n",
        "    self.reward = 0\n",
        "    self.counter = 0\n",
        "    return ts.restart(np.array([self._state], dtype=np.float32))\n",
        "\n",
        "  def _step(self, action):\n",
        "\n",
        "    self.counter += 1\n",
        "\n",
        "    self._state = dflist[self.counter]\n",
        "\n",
        "    if self._episode_ended:\n",
        "      # The last action ended the episode. Ignore the current action and start\n",
        "      # a new episode.\n",
        "      return self.reset()\n",
        "\n",
        "    # Buy Sell reward.\n",
        "    if action == 1:\n",
        "      self.reward += dflist[self.counter][3] \n",
        "    elif action == 0:\n",
        "      self.reward -= dflist[self.counter][3]\n",
        "    else:\n",
        "      raise ValueError('`action` should be 0 or 1.')\n",
        "\n",
        "\n",
        "    if self.counter == 1000:\n",
        "      self._episode_ended = True\n",
        "\n",
        "\n",
        "    if self._episode_ended:\n",
        "      return ts.termination(np.array([self._state], dtype=np.float32), reward=self.reward)\n",
        "    else:\n",
        "      return ts.transition(\n",
        "          np.array([self._state], dtype=np.float32), reward=self.reward, discount=1)"
      ],
      "metadata": {
        "id": "yE8avAL96b4a"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_py_env = CustomEnvironment()\n",
        "custom_tf_env = tf_py_environment.TFPyEnvironment(custom_py_env)"
      ],
      "metadata": {
        "id": "YptrkBKuyM2w"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fc_layer_params = (100, 50)\n",
        "action_tensor_spec = tensor_spec.from_spec(env.action_spec())\n",
        "num_actions = action_tensor_spec.maximum - action_tensor_spec.minimum + 1\n",
        "\n",
        "def dense_layer(num_units):\n",
        "    return tf.keras.layers.Dense(\n",
        "        num_units,\n",
        "        activation=tf.keras.activations.relu,\n",
        "        kernel_initializer=tf.keras.initializers.VarianceScaling(\n",
        "            scale=2.0, mode='fan_in', distribution='truncated_normal'))\n",
        "\n",
        "dense_layers = [dense_layer(num_units) for num_units in fc_layer_params]\n",
        "q_values_layer = tf.keras.layers.Dense(\n",
        "    num_actions,\n",
        "    activation=None,\n",
        "    kernel_initializer=tf.keras.initializers.RandomUniform(\n",
        "        minval=-0.03, maxval=0.03),\n",
        "    bias_initializer=tf.keras.initializers.Constant(-0.2))\n",
        "q_net = tf.keras.Sequential(dense_layers + [Flatten(), q_values_layer])"
      ],
      "metadata": {
        "id": "pgOlS1RayGmS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QNetwork(network.Network):\n",
        "\n",
        "    def __init__(self, input_shape, num_actions, fc_layer_params=(100, 50), name='QNetwork'):\n",
        "        super(QNetwork, self).__init__(input_tensor_spec=None, state_spec=(), name=name)\n",
        "        self._num_actions = num_actions\n",
        "        self._fc_layers = [dense_layer(num_units) for num_units in fc_layer_params]\n",
        "        self._q_values_layer = tf.keras.layers.Dense(\n",
        "            num_actions,\n",
        "            activation=None,\n",
        "            kernel_initializer=tf.keras.initializers.RandomUniform(minval=-0.03, maxval=0.03),\n",
        "            bias_initializer=tf.keras.initializers.Constant(-0.2))\n",
        "\n",
        "    def call(self, inputs, step_type=None, network_state=()):\n",
        "        x = tf.cast(inputs, tf.float32)\n",
        "        for layer in self._fc_layers:\n",
        "            x = layer(x)\n",
        "        q_values = self._q_values_layer(x)\n",
        "        q_values = tf.reshape(q_values, [-1, self._num_actions])  # Add this line to reshape the output tensor\n",
        "        return q_values, network_state\n"
      ],
      "metadata": {
        "id": "35ZVyuBvyhVP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q_net = QNetwork(env.observation_spec().shape, num_actions)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "train_step_counter = tf.Variable(0)\n",
        "agent = dqn_agent.DqnAgent(\n",
        "    env.time_step_spec(),\n",
        "    env.action_spec(),\n",
        "    q_network=q_net,\n",
        "    optimizer=optimizer,\n",
        "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
        "    train_step_counter=train_step_counter)\n",
        "agent.initialize()"
      ],
      "metadata": {
        "id": "A_GdQ8y5zRFT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replay_buffer = ta.replay_buffers.TFUniformReplayBuffer(\n",
        "    data_spec=agent.collect_data_spec,\n",
        "    batch_size=1000,\n",
        "    max_length=100000)\n"
      ],
      "metadata": {
        "id": "Fa2KDUqwz3Tb"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random policy for initial data collection\n",
        "random_policy = random_tf_policy.RandomTFPolicy(\n",
        "    env.time_step_spec(),\n",
        "    env.action_spec())\n",
        "\n",
        "# Create a driver to collect experience from the environment\n",
        "collect_driver = dynamic_step_driver.DynamicStepDriver(\n",
        "    env,\n",
        "    random_policy,\n",
        "    observers=[replay_buffer.add_batch],\n",
        "    num_steps=1000)  # Collect 1000 steps\n",
        "\n",
        "# Collect initial experience\n",
        "collect_driver.run()\n"
      ],
      "metadata": {
        "id": "W079tEj20BEK",
        "outputId": "d3a40683-de6a-48dd-f8cd-64b643174494",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-89325288f996>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Collect initial experience\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mcollect_driver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_agents/drivers/dynamic_step_driver.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, time_step, policy_state, maximum_iterations)\u001b[0m\n\u001b[1;32m    180\u001b[0m       \u001b[0mpolicy_state\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mfinal\u001b[0m \u001b[0mstep\u001b[0m \u001b[0mpolicy\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \"\"\"\n\u001b[0;32m--> 182\u001b[0;31m     return self._run_fn(\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0mtime_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mpolicy_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpolicy_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_agents/utils/common.py\u001b[0m in \u001b[0;36mwith_check_resource_vars\u001b[0;34m(*fn_args, **fn_kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;31m# We're either in eager mode or in tf.function mode (no in-between); so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;31m# autodep-like behavior is already expected of fn.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresource_variables_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMISSING_RESOURCE_VARIABLES_ERROR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_agents/drivers/dynamic_step_driver.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, time_step, policy_state, maximum_iterations)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# Batch dim should be first index of tensors during data collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m     batch_dims = nest_utils.get_outer_shape(time_step,\n\u001b[0m\u001b[1;32m    197\u001b[0m                                             self.env.time_step_spec())\n\u001b[1;32m    198\u001b[0m     \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_agents/utils/nest_utils.py\u001b[0m in \u001b[0;36mget_outer_shape\u001b[0;34m(nested_tensor, spec)\u001b[0m\n\u001b[1;32m    811\u001b[0m   \u001b[0;31m# Check tensors have same batch shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m   \u001b[0mnum_outer_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m   if not is_batched_nested_tensors(\n\u001b[0m\u001b[1;32m    814\u001b[0m       nested_tensor, spec, num_outer_dims=num_outer_dims, check_dtypes=False):\n\u001b[1;32m    815\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_agents/utils/nest_utils.py\u001b[0m in \u001b[0;36mis_batched_nested_tensors\u001b[0;34m(tensors, specs, num_outer_dims, allow_extra_fields, check_dtypes)\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m   raise ValueError(\n\u001b[0m\u001b[1;32m    529\u001b[0m       \u001b[0;34m'Received a mix of batched and unbatched Tensors, or Tensors'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m       \u001b[0;34m' are not compatible with Specs.  num_outer_dims: %d.\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Received a mix of batched and unbatched Tensors, or Tensors are not compatible with Specs.  num_outer_dims: 1.\nSaw tensor_shapes:\n   TimeStep(\n{'discount': TensorShape([1]),\n 'observation': TensorShape([1, 1, 9]),\n 'reward': TensorShape([1]),\n 'step_type': TensorShape([1])})\nAnd spec_shapes:\n   TimeStep(\n{'discount': TensorShape([]),\n 'observation': TensorShape([9]),\n 'reward': TensorShape([]),\n 'step_type': TensorShape([])})"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Overview of Colaboratory Features",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}