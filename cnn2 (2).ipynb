{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aetev/Learning-stuff-/blob/main/cnn2%20(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow_addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-g36b6KfZQeH",
        "outputId": "b1bf8e6e-046e-42e4-9d3f-c4dace11ac86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (612 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/612.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/612.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m368.6/612.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m604.2/612.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.1/612.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (23.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UiZf7YAawUu"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow_addons as tfa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yn4y2vCkggU1"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Load MNIST dataset\n",
        "(x_train, y_train), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalize the images to [-1, 1]\n",
        "#x_train = (x_train.astype(\"float32\") - 127.5) / 127.5\n",
        "#y_train = y_train.reshape(-1, 1)\n",
        "x_train = (x_train.astype(\"float32\")) / np.max(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_images = []\n",
        "new_labels = []\n",
        "\n",
        "for digit in set(y_train):\n",
        "    digit_indices = np.where(y_train == digit)[0][:10]\n",
        "    for index in digit_indices:\n",
        "        image = x_train[index]\n",
        "        label = y_train[index]\n",
        "        new_images.append(image)\n",
        "        new_labels.append(label)\n",
        "\n",
        "new_images = np.array(new_images)\n",
        "new_labels = np.array(new_labels)\n",
        "\n",
        "print(\"New dataset shape:\", new_images.shape)\n",
        "\n",
        "# Visualize the new dataset\n",
        "plt.imshow(new_images[1], cmap=\"gray\")\n",
        "plt.title(\"Label: {}\".format(new_labels[1]))\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GwT02EZkqZQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_rotate_images(images, min_angle=-90):\n",
        "    size = tf.shape(images)[0]\n",
        "    random_angles = tf.random.uniform(shape=(size,), minval=min_angle, maxval=-min_angle, dtype=tf.float32)\n",
        "    rotated_images = tfa.image.rotate(images, random_angles / 90)\n",
        "    return rotated_images\n",
        "\n",
        "# Select a batch of images\n",
        "batch_size = 10\n",
        "batch_images = x_train[:batch_size]\n",
        "batch_images = np.expand_dims(batch_images, axis=-1)\n",
        "rotated_images = random_rotate_images(batch_images)\n",
        "\n",
        "fig, axes = plt.subplots(nrows=2, ncols=batch_size, figsize=(10, 4))\n",
        "for i in range(batch_size):\n",
        "    axes[0][i].imshow(batch_images[i], cmap='gray')\n",
        "    axes[0][i].axis('off')\n",
        "    axes[1][i].imshow(rotated_images[i], cmap='gray')\n",
        "    axes[1][i].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "e5q1TuKbSRIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyOx5JqbrffI"
      },
      "outputs": [],
      "source": [
        "def build_generator():\n",
        "    noise_shape = (100,)\n",
        "    noise = layers.Input(shape=noise_shape)\n",
        "    input_digit = layers.Input(shape=(1,), dtype=\"int32\")\n",
        "    digit_embedding = layers.Embedding(10, 10)(input_digit)\n",
        "    digit_embedding = layers.Flatten()(digit_embedding)\n",
        "\n",
        "    x = layers.Concatenate()([noise, digit_embedding])\n",
        "\n",
        "    # Transform the concatenated vector into a 7x7x256 tensor\n",
        "    x = layers.Dense(7 * 7, use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "    x = layers.Reshape((7, 7, 1))(x)\n",
        "\n",
        "    # Upsample to 14x14\n",
        "    x = layers.Conv2DTranspose(64, (5, 5), strides=(1, 1), padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    # Conv 14x14\n",
        "    x = layers.Conv2D(64, (5, 5), strides=(1, 1), padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    # Upsample to 28x28\n",
        "    x = layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    # Final output layer\n",
        "    output = layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='hard_sigmoid')(x)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=[noise, input_digit], outputs=output)\n",
        "    return model\n",
        "\n",
        "generator = build_generator()\n",
        "generator.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gh2ORgUybdzt"
      },
      "outputs": [],
      "source": [
        "def build_discriminator():\n",
        "    input_image = layers.Input(shape=(28, 28, 1))\n",
        "    digit_input = layers.Input(shape=(1,), dtype=\"int32\")\n",
        "    digit_embedding_2d = layers.Embedding(10, 10)(digit_input)\n",
        "    digit_embedding_2d = layers.Flatten()(digit_embedding_2d)\n",
        "    #digit_embedding_2d = layers.Reshape((28, 28, 1))(digit_embedding_2d)\n",
        "\n",
        "    #merged_input = layers.Concatenate()([input_image, digit_embedding_2d])\n",
        "\n",
        "    # Convolutional layers\n",
        "    x = layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.01))(input_image)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = layers.Conv2D(248, (5, 5), strides=(2, 2), padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = layers.Conv2D(248, (5, 5), strides=(2, 2), padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Concatenate()([x,digit_embedding_2d])\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    x = layers.Dense(300, kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    x = layers.Dense(1, activation=\"sigmoid\", kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=[input_image, digit_input], outputs=x)\n",
        "    return model\n",
        "\n",
        "discriminator = build_discriminator()\n",
        "discriminator_copy = build_discriminator()\n",
        "#discriminator.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFFOfuDfbpD9"
      },
      "outputs": [],
      "source": [
        "# Compile models\n",
        "generator_optimizer = tf.keras.optimizers.Adam(0.0004)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(0.0004)\n",
        "copy_optimizer = tf.keras.optimizers.Adam(0.0004)\n",
        "\n",
        "#generator_optimizer = tf.keras.optimizers.experimental.SGD(1e-4)\n",
        "#discriminator_optimizer = tf.keras.optimizers.experimental.SGD(1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3PtShxlbn9c"
      },
      "outputs": [],
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = tf.keras.losses.BinaryCrossentropy()(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = tf.keras.losses.BinaryCrossentropy()(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return tf.keras.losses.BinaryCrossentropy()(tf.ones_like(fake_output), fake_output)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_img(generator_model):\n",
        "    # Generate and save sample images\n",
        "    noise = tf.random.normal([10, 100])\n",
        "    sampled_labels = tf.constant([[i % 10] for i in range(10)], dtype=tf.int32)\n",
        "    generated_images = generator_model.predict([noise, sampled_labels])\n",
        "    fig, axs = plt.subplots(1, 10, figsize=(10, 10))\n",
        "    for i in range(10):\n",
        "        axs[i].imshow(generated_images[i], cmap=\"gray\")\n",
        "        axs[i].axis(\"off\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "vAoSvqXLsQHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@tf.function\n",
        "\n",
        "\n",
        "def train_step(images, labels):\n",
        "\n",
        "    batch_size = images.shape[0]\n",
        "    noise = tf.random.normal([batch_size, 100])\n",
        "    generated_images = generator([noise, labels], training=True)\n",
        "\n",
        "\n",
        "\n",
        "    with tf.GradientTape() as disc_tape:\n",
        "\n",
        "      real_output = discriminator([images, labels], training=True)\n",
        "      fake_output = discriminator([generated_images, labels], training=True)\n",
        "\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "\n",
        "    # Get the weights of model1\n",
        "    weights = discriminator.get_weights()\n",
        "\n",
        "    # Set the weights of model2 to be the same as model1\n",
        "    discriminator_copy.set_weights(weights)\n",
        "\n",
        "    for i in range(5):\n",
        "      with tf.GradientTape() as disc_copy_tape:\n",
        "\n",
        "        real_output = discriminator_copy([images, labels], training=True)\n",
        "        fake_output = discriminator_copy([generated_images, labels], training=True)\n",
        "\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "      gradients_of_discriminator = disc_copy_tape.gradient(disc_loss, discriminator_copy.trainable_variables)\n",
        "      copy_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator_copy.trainable_variables))\n",
        "\n",
        "\n",
        "\n",
        "    with tf.GradientTape() as gen_tape:\n",
        "      generated_images = generator([noise, labels], training=True)\n",
        "      fake_output = discriminator_copy([generated_images, labels], training=True)\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "\n",
        "    tf.print(\"disc_loss\",disc_loss,'gen_loss',gen_loss)\n",
        "\n",
        "\n",
        "def train(generator, discriminator\n",
        "          , epochs, batch_size):\n",
        "    for epoch in range(epochs):\n",
        "        for batch in range(len(new_images) // batch_size):\n",
        "            images = new_images[batch * batch_size: (batch+1) * batch_size]\n",
        "            labels = new_labels[batch * batch_size: (batch+1) * batch_size]\n",
        "\n",
        "            train_step(images, labels)\n",
        "\n",
        "        # Output training progress\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "            print_img(generator)\n",
        "\n",
        "# Train the GAN\n",
        "EPOCHS = 2000000\n",
        "BATCH_SIZE = 50\n",
        "num_unrolling_steps = 5  # Set the desired number of unrolling steps\n",
        "train(generator, discriminator, EPOCHS, BATCH_SIZE)"
      ],
      "metadata": {
        "id": "CK4j3K7qtz47"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Overview of Colaboratory Features",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}