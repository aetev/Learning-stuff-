{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aetev/Learning-stuff-/blob/main/agcnn%203.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-g36b6KfZQeH",
        "outputId": "f607d315-7c64-4db0-c2f2-012103697ab9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (612 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.1/612.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (23.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow_addons\n",
            "Successfully installed tensorflow_addons-0.21.0 typeguard-2.13.3\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.0.post2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.0)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.3.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.56.4)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch<1.7,>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.5)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.7.1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.5)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa) (23.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa) (2.27.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_addons\n",
        "#!pip install pydub\n",
        "!pip install librosa"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "kq4KEMDwylHv",
        "outputId": "8dbadcec-d2da-41ca-8fa1-0ccc1b60e916",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UiZf7YAawUu",
        "outputId": "b33a6392-44b7-4e44-d37d-3ad34b94da93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow_addons as tfa\n",
        "import os\n",
        "from IPython.display import Audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KZA4iSHlpHeW"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "def downsample_array(arr, factor, axis):\n",
        "    return arr.take(np.arange(0, arr.shape[axis], factor), axis)\n",
        "\n",
        "def create_sliding_window(array, window_size, stride):\n",
        "    num_windows = (len(array) - window_size) // stride + 1\n",
        "    sliding_windows = np.lib.stride_tricks.sliding_window_view(array, (window_size,))\n",
        "\n",
        "    return sliding_windows[::stride]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PwZorlMxq2Rx"
      },
      "outputs": [],
      "source": [
        "reduction = 24\n",
        "wav_file = '/content/drive/MyDrive/bass samples/NBKoanbandstuff.wav'\n",
        "audio, sr = librosa.load(wav_file, sr=None)\n",
        "audio_dev = np.std(audio)\n",
        "audio = audio/audio_dev\n",
        "result_array = create_sliding_window(audio,44100,100)\n",
        "result_array = np.expand_dims(result_array, axis=2)\n",
        "result_array = downsample_array(result_array,reduction,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "ZIzKgHj1sIvX",
        "outputId": "196a4428-2250-4cc0-93cc-8ba3a35716d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ],
            "text/html": [
              "\n",
              "                <audio  controls=\"controls\" >\n",
              "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "\n",
        "\n",
        "audio_data = result_array[100].ravel()\n",
        "# Play the audio within the Jupyter Notebook\n",
        "Audio(data=audio_data, rate=sr/reduction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XZfCdyC7S_D",
        "outputId": "c298640d-1acb-4c32-c41c-7b14ab1141eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1838, 1)\n"
          ]
        }
      ],
      "source": [
        "#x_train = noise\n",
        "y_train = result_array\n",
        "print(y_train[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MUFnmA-82FDv"
      },
      "outputs": [],
      "source": [
        "class ResNetBlock(layers.Layer):\n",
        "    def __init__(self, filters,kernel_size=3, strides=1,dilation_rate=1):\n",
        "        super(ResNetBlock, self).__init__()\n",
        "        self.conv1 = layers.Conv1D(filters, kernel_size, strides=strides,dilation_rate=dilation_rate, padding='same')\n",
        "        self.bn1 = layers.BatchNormalization()\n",
        "        self.conv2 = layers.Conv1D(filters, kernel_size, padding='same')\n",
        "        self.bn2 = layers.BatchNormalization()\n",
        "\n",
        "        if strides != 1:\n",
        "            self.residual = layers.Conv1D(filters, 1, strides=strides)\n",
        "        else:\n",
        "            self.residual = lambda x: x\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.bn1(x, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x, training=training)\n",
        "\n",
        "        r = self.residual(inputs)\n",
        "\n",
        "        x += r\n",
        "        return tf.nn.relu(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNetBlockup(layers.Layer):\n",
        "    def __init__(self, filters, kernel_size=3, strides=1, dilation_rate=1):\n",
        "        super(ResNetBlockup, self).__init__()\n",
        "        self.conv1 = layers.Conv1DTranspose(filters, kernel_size, strides=strides, dilation_rate=dilation_rate, padding='same')\n",
        "        self.bn1 = layers.BatchNormalization()\n",
        "        self.conv2 = layers.Conv1DTranspose(filters, kernel_size, padding='same')\n",
        "        self.bn2 = layers.BatchNormalization()\n",
        "\n",
        "        if strides != 1:\n",
        "            self.residual = layers.Conv1DTranspose(filters, 1, strides=strides)\n",
        "        else:\n",
        "            self.residual = lambda x: x\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.bn1(x, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x, training=training)\n",
        "\n",
        "        r = self.residual(inputs)\n",
        "\n",
        "        x += r\n",
        "        return tf.nn.relu(x)"
      ],
      "metadata": {
        "id": "qBopciVs0FBC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gh2ORgUybdzt",
        "outputId": "625604a5-1577-4810-ea6a-9b5453b91a37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, None, 1)]         0         \n",
            "                                                                 \n",
            " batch_normalization_22 (Bat  (None, None, 1)          4         \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " res_net_block_9 (ResNetBloc  (None, None, 64)         17280     \n",
            " k)                                                              \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, None, 64)          0         \n",
            "                                                                 \n",
            " res_net_block_10 (ResNetBlo  (None, None, 64)         33408     \n",
            " ck)                                                             \n",
            "                                                                 \n",
            " res_net_block_11 (ResNetBlo  (None, None, 64)         33408     \n",
            " ck)                                                             \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, None, 64)          0         \n",
            "                                                                 \n",
            " res_net_block_12 (ResNetBlo  (None, None, 64)         33408     \n",
            " ck)                                                             \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, None, 64)          0         \n",
            "                                                                 \n",
            " res_net_block_13 (ResNetBlo  (None, None, 64)         33408     \n",
            " ck)                                                             \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, None, 64)          0         \n",
            "                                                                 \n",
            " res_net_block_14 (ResNetBlo  (None, None, 64)         33408     \n",
            " ck)                                                             \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, None, 64)          0         \n",
            "                                                                 \n",
            " global_average_pooling1d_1   (None, 64)               0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 184,389\n",
            "Trainable params: 182,851\n",
            "Non-trainable params: 1,538\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def build_discriminator():\n",
        "    input_series = layers.Input(shape=(None,1))\n",
        "\n",
        "    x = layers.BatchNormalization()(input_series)\n",
        "\n",
        "    # Convolutional layers\n",
        "    x = ResNetBlock(64,4,1,1)(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = ResNetBlock(64,4,1,2)(x)\n",
        "\n",
        "\n",
        "    x = ResNetBlock(64,4,1,4)(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = ResNetBlock(64,4,1,8)(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = ResNetBlock(64,4,1,12)(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = ResNetBlock(64,4,1,24)(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "\n",
        "\n",
        "    # Global pooling\n",
        "    pooled_output = layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "    # Dense layer\n",
        "    dense_output = layers.Dense(64, activation='relu')(pooled_output)\n",
        "\n",
        "    # Dense layer\n",
        "    dense_output = layers.Dense(1, activation='linear')(pooled_output)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=input_series, outputs=dense_output)\n",
        "    return model\n",
        "\n",
        "discriminator = build_discriminator()\n",
        "discriminator.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q_-l7f8eC-i",
        "outputId": "93b95c72-fec3-4cea-e44f-f1de46800efd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, None, 1)]         0         \n",
            "                                                                 \n",
            " batch_normalization_44 (Bat  (None, None, 1)          4         \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " res_net_block_18 (ResNetBlo  (None, None, 64)         17408     \n",
            " ck)                                                             \n",
            "                                                                 \n",
            " res_net_block_19 (ResNetBlo  (None, None, 64)         37568     \n",
            " ck)                                                             \n",
            "                                                                 \n",
            " res_net_block_20 (ResNetBlo  (None, None, 64)         37568     \n",
            " ck)                                                             \n",
            "                                                                 \n",
            " res_net_blockup_2 (ResNetBl  (None, None, 64)         37568     \n",
            " ockup)                                                          \n",
            "                                                                 \n",
            " conv1d_53 (Conv1D)          (None, None, 1)           65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 130,181\n",
            "Trainable params: 129,155\n",
            "Non-trainable params: 1,026\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def build_generator():\n",
        "    input_series = layers.Input(shape=(None,1))\n",
        "\n",
        "    x = layers.BatchNormalization()(input_series)\n",
        "\n",
        "    x = ResNetBlock(64,4,strides=2)(x)\n",
        "\n",
        "    x = ResNetBlock(64,4,strides=2)(x)\n",
        "\n",
        "    x = ResNetBlock(64,4,strides=2)(x)\n",
        "\n",
        "    x = ResNetBlockup(64,4,strides=2)(x)\n",
        "\n",
        "    x = layers.Conv1D(1,1)(x)\n",
        "\n",
        "\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=input_series, outputs=x)\n",
        "    return model\n",
        "\n",
        "generator = build_generator()\n",
        "generator.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "aFFOfuDfbpD9"
      },
      "outputs": [],
      "source": [
        "# Compile models\n",
        "generator_optimizer = tf.keras.optimizers.Adam(0.0004)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(0.0004)\n",
        "\n",
        "#generator_optimizer = tf.keras.optimizers.experimental.SGD(1e-4)\n",
        "#discriminator_optimizer = tf.keras.optimizers.experimental.SGD(1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "T3PtShxlbn9c"
      },
      "outputs": [],
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "    return tf.reduce_mean(fake_output) - tf.reduce_mean(real_output)\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return -tf.reduce_mean(fake_output)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clip_discriminator_weights(discriminator):\n",
        "    for l in discriminator.layers:\n",
        "        weights = l.get_weights()\n",
        "        weights = [tf.clip_by_value(w, -0.01, 0.01) for w in weights]\n",
        "        l.set_weights(weights)"
      ],
      "metadata": {
        "id": "a8RtXmHLZHWu"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "vAoSvqXLsQHq"
      },
      "outputs": [],
      "source": [
        "def print_img(generator_model):\n",
        "    # Generate and save sample images\n",
        "    noise = tf.random.normal([10, 100])\n",
        "    sampled_labels = tf.constant([[i % 10] for i in range(10)], dtype=tf.int32)\n",
        "    generated_images = generator_model.predict([noise, sampled_labels])\n",
        "    fig, axs = plt.subplots(1, 10, figsize=(10, 10))\n",
        "    for i in range(10):\n",
        "        axs[i].imshow(generated_images[i], cmap=\"gray\")\n",
        "        axs[i].axis(\"off\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAqGbZU0Z5yl",
        "outputId": "39e4c2dc-ceb9-4c61-e7b7-cc69d2076cbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "(1, 2500, 1)\n"
          ]
        }
      ],
      "source": [
        "noise = tf.random.normal(shape=(1,10000,1))\n",
        "\n",
        "test = generator.predict(noise)\n",
        "print(test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wp5mnkMVVgPV",
        "outputId": "408d88ee-d27a-4b1b-ce17-f847344f08ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "disc_loss 5.63106732e-06 gen_loss 0.000201476345\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#@tf.function\n",
        "def train_step(target_audios):\n",
        "\n",
        "\n",
        "  for i in range(5):\n",
        "\n",
        "      # Get the shape of the target_audios tensor\n",
        "      shape = tf.shape(target_audios)\n",
        "\n",
        "      # Divide the number in the second index by 4\n",
        "      divided_value = shape[1] // 4\n",
        "\n",
        "      # Generate noise using tf.random.normal()\n",
        "      noise = tf.random.normal((shape[0], divided_value, shape[2]))\n",
        "      generated_audio = generator(noise, training=True)\n",
        "      with tf.GradientTape() as disc_tape:\n",
        "\n",
        "          real_output = discriminator(target_audios, training=True)\n",
        "          fake_output = discriminator(generated_audio, training=True)\n",
        "\n",
        "          disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "      gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "      discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "      clip_discriminator_weights(discriminator)\n",
        "\n",
        "      if i ==0:\n",
        "          weights = discriminator.get_weights()\n",
        "\n",
        "\n",
        "  with tf.GradientTape() as gen_tape:\n",
        "    noise = tf.random.normal(shape=(target_audios.shape))\n",
        "    generated_audio = generator(noise, training=True)\n",
        "    fake_output = discriminator(generated_audio, training=True)\n",
        "    gen_loss = generator_loss(fake_output)\n",
        "\n",
        "  gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "  generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "  discriminator.set_weights(weights)\n",
        "\n",
        "\n",
        "  tf.print(\"disc_loss\",disc_loss,'gen_loss',gen_loss)\n",
        "\n",
        "\n",
        "def train(generator, discriminator\n",
        "          , epochs, batch_size):\n",
        "    for epoch in range(epochs):\n",
        "        for batch in range(len(y_train) // batch_size):\n",
        "            #images = x_train[batch * batch_size: (batch+1) * batch_size]\n",
        "            target_audios = y_train[batch * batch_size: (batch+1) * batch_size]\n",
        "\n",
        "            train_step(target_audios)\n",
        "\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "            test = generator.predict(noise)\n",
        "            audio_data = test.ravel()\n",
        "            # Play the audio within the Jupyter Notebook\n",
        "            Audio(data=audio_data, rate=sr/reduction)\n",
        "\n",
        "\n",
        "# Train the GAN\n",
        "EPOCHS = 2000000\n",
        "BATCH_SIZE = 20\n",
        "num_unrolling_steps = 20  # Set the desired number of unrolling steps\n",
        "train(generator, discriminator, EPOCHS, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrmv1Zri-jjc"
      },
      "outputs": [],
      "source": [
        "            test = generator.predict(noise)\n",
        "            audio_data = test.ravel()\n",
        "            # Play the audio within the Jupyter Notebook\n",
        "            Audio(data=audio_data, rate=sr/reduction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjhAydgsdXVx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Overview of Colaboratory Features",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}