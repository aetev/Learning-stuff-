{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aetev/Learning-stuff-/blob/main/agcnn%203.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-g36b6KfZQeH",
        "outputId": "cebaefe4-fa2f-4815-d8a0-b9a5689aeac7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (612 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.1/612.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (23.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow_addons\n",
            "Successfully installed tensorflow_addons-0.21.0 typeguard-2.13.3\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.0.post2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.0)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.3.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.56.4)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch<1.7,>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.5)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.7.1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.5)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa) (23.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa) (2.27.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_addons\n",
        "#!pip install pydub\n",
        "!pip install librosa"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "kq4KEMDwylHv",
        "outputId": "a97615d6-4184-4f76-ed0e-fa065df29bf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UiZf7YAawUu",
        "outputId": "4c64107e-a12b-4604-d6c8-55540efb7452"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow_addons as tfa\n",
        "import os\n",
        "from IPython.display import Audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KZA4iSHlpHeW"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "def downsample_array(arr, factor, axis):\n",
        "    return arr.take(np.arange(0, arr.shape[axis], factor), axis)\n",
        "\n",
        "def create_sliding_window(array, window_size, stride):\n",
        "    num_windows = (len(array) - window_size) // stride + 1\n",
        "    sliding_windows = np.lib.stride_tricks.sliding_window_view(array, (window_size,))\n",
        "\n",
        "    return sliding_windows[::stride]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "PwZorlMxq2Rx"
      },
      "outputs": [],
      "source": [
        "reduction = 24\n",
        "wav_file = '/content/drive/MyDrive/bass samples/NBKoanbandstuff.wav'\n",
        "audio, sr = librosa.load(wav_file, sr=None)\n",
        "audio_dev = np.std(audio)\n",
        "audio = audio/audio_dev\n",
        "result_array = create_sliding_window(audio,44100,100)\n",
        "result_array = np.expand_dims(result_array, axis=2)\n",
        "result_array = downsample_array(result_array,reduction,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "ZIzKgHj1sIvX",
        "outputId": "5cb93fe4-7400-4a85-b376-2c217b8afa41"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ],
            "text/html": [
              "\n",
              "                <audio  controls=\"controls\" >\n",
              "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "\n",
        "\n",
        "audio_data = result_array[100].ravel()\n",
        "# Play the audio within the Jupyter Notebook\n",
        "Audio(data=audio_data, rate=sr/reduction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XZfCdyC7S_D",
        "outputId": "70e59ffc-bc90-46df-990f-fe677c44605d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1838, 1)\n"
          ]
        }
      ],
      "source": [
        "#x_train = noise\n",
        "y_train = result_array\n",
        "print(y_train[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "MUFnmA-82FDv"
      },
      "outputs": [],
      "source": [
        "class ResNetBlock(layers.Layer):\n",
        "    def __init__(self, filters,kernel_size=3, strides=1,dilation_rate=1):\n",
        "        super(ResNetBlock, self).__init__()\n",
        "        self.conv1 = layers.Conv1D(filters, kernel_size, strides=strides,dilation_rate=dilation_rate, padding='same')\n",
        "        self.bn1 = layers.BatchNormalization()\n",
        "        self.conv2 = layers.Conv1D(filters, kernel_size, padding='same')\n",
        "        self.bn2 = layers.BatchNormalization()\n",
        "\n",
        "        if strides != 1:\n",
        "            self.residual = layers.Conv1D(filters, 1, strides=strides)\n",
        "        else:\n",
        "            self.residual = lambda x: x\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.bn1(x, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x, training=training)\n",
        "\n",
        "        r = self.residual(inputs)\n",
        "\n",
        "        x += r\n",
        "        return tf.nn.relu(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNetBlockup(layers.Layer):\n",
        "    def __init__(self, filters, kernel_size=3, strides=1, dilation_rate=1):\n",
        "        super(ResNetBlockup, self).__init__()\n",
        "        self.conv1 = layers.Conv1DTranspose(filters, kernel_size, strides=strides, dilation_rate=dilation_rate, padding='same')\n",
        "        self.bn1 = layers.BatchNormalization()\n",
        "        self.conv2 = layers.Conv1DTranspose(filters, kernel_size, padding='same')\n",
        "        self.bn2 = layers.BatchNormalization()\n",
        "\n",
        "        if strides != 1:\n",
        "            self.residual = layers.Conv1DTranspose(filters, 1, strides=strides)\n",
        "        else:\n",
        "            self.residual = lambda x: x\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.bn1(x, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x, training=training)\n",
        "\n",
        "        r = self.residual(inputs)\n",
        "\n",
        "        x += r\n",
        "        return tf.nn.relu(x)"
      ],
      "metadata": {
        "id": "qBopciVs0FBC"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gh2ORgUybdzt",
        "outputId": "b832a1d2-644f-4893-a921-2c2c04bd1df9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, None, 1)]         0         \n",
            "                                                                 \n",
            " batch_normalization_22 (Bat  (None, None, 1)          4         \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " res_net_block_9 (ResNetBloc  (None, None, 64)         17280     \n",
            " k)                                                              \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, None, 64)          0         \n",
            "                                                                 \n",
            " res_net_block_10 (ResNetBlo  (None, None, 64)         33408     \n",
            " ck)                                                             \n",
            "                                                                 \n",
            " res_net_block_11 (ResNetBlo  (None, None, 64)         33408     \n",
            " ck)                                                             \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, None, 64)          0         \n",
            "                                                                 \n",
            " res_net_block_12 (ResNetBlo  (None, None, 64)         33408     \n",
            " ck)                                                             \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, None, 64)          0         \n",
            "                                                                 \n",
            " res_net_block_13 (ResNetBlo  (None, None, 64)         33408     \n",
            " ck)                                                             \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, None, 64)          0         \n",
            "                                                                 \n",
            " res_net_block_14 (ResNetBlo  (None, None, 64)         33408     \n",
            " ck)                                                             \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, None, 64)          0         \n",
            "                                                                 \n",
            " global_average_pooling1d_1   (None, 64)               0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 184,389\n",
            "Trainable params: 182,851\n",
            "Non-trainable params: 1,538\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def build_discriminator():\n",
        "    input_series = layers.Input(shape=(None,1))\n",
        "\n",
        "    x = layers.BatchNormalization()(input_series)\n",
        "\n",
        "    # Convolutional layers\n",
        "    x = ResNetBlock(64,4,1,1)(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = ResNetBlock(64,4,1,2)(x)\n",
        "\n",
        "\n",
        "    x = ResNetBlock(64,4,1,4)(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = ResNetBlock(64,4,1,8)(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = ResNetBlock(64,4,1,12)(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = ResNetBlock(64,4,1,24)(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "\n",
        "\n",
        "    # Global pooling\n",
        "    pooled_output = layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "    # Dense layer\n",
        "    dense_output = layers.Dense(64, activation='relu')(pooled_output)\n",
        "\n",
        "    # Dense layer\n",
        "    dense_output = layers.Dense(1, activation='sigmoid')(pooled_output)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=input_series, outputs=dense_output)\n",
        "    return model\n",
        "\n",
        "discriminator = build_discriminator()\n",
        "discriminator.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q_-l7f8eC-i",
        "outputId": "55d00ff4-f68d-4187-eac4-8609211fc211"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, None, 1)]         0         \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, None, 1)          4         \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " res_net_block_6 (ResNetBloc  (None, None, 64)         17408     \n",
            " k)                                                              \n",
            "                                                                 \n",
            " res_net_block_7 (ResNetBloc  (None, None, 64)         37568     \n",
            " k)                                                              \n",
            "                                                                 \n",
            " res_net_block_8 (ResNetBloc  (None, None, 64)         37568     \n",
            " k)                                                              \n",
            "                                                                 \n",
            " res_net_blockup (ResNetBloc  (None, None, 64)         37568     \n",
            " kup)                                                            \n",
            "                                                                 \n",
            " conv1d_21 (Conv1D)          (None, None, 1)           65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 130,181\n",
            "Trainable params: 129,155\n",
            "Non-trainable params: 1,026\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def build_generator():\n",
        "    input_series = layers.Input(shape=(None,1))\n",
        "\n",
        "    x = layers.BatchNormalization()(input_series)\n",
        "\n",
        "    x = ResNetBlock(64,4,strides=2)(x)\n",
        "\n",
        "    x = ResNetBlock(64,4,strides=2)(x)\n",
        "\n",
        "    x = ResNetBlock(64,4,strides=2)(x)\n",
        "\n",
        "    x = ResNetBlockup(64,4,strides=2)(x)\n",
        "\n",
        "    x = layers.Conv1D(1,1)(x)\n",
        "\n",
        "\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=input_series, outputs=x)\n",
        "    return model\n",
        "\n",
        "generator = build_generator()\n",
        "generator.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "aFFOfuDfbpD9"
      },
      "outputs": [],
      "source": [
        "# Compile models\n",
        "generator_optimizer = tf.keras.optimizers.Adam(0.0004)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(0.0004)\n",
        "\n",
        "#generator_optimizer = tf.keras.optimizers.experimental.SGD(1e-4)\n",
        "#discriminator_optimizer = tf.keras.optimizers.experimental.SGD(1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "T3PtShxlbn9c"
      },
      "outputs": [],
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = tf.keras.losses.BinaryCrossentropy()(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = tf.keras.losses.BinaryCrossentropy()(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return tf.keras.losses.BinaryCrossentropy()(tf.ones_like(fake_output), fake_output)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "vAoSvqXLsQHq"
      },
      "outputs": [],
      "source": [
        "def print_img(generator_model):\n",
        "    # Generate and save sample images\n",
        "    noise = tf.random.normal([10, 100])\n",
        "    sampled_labels = tf.constant([[i % 10] for i in range(10)], dtype=tf.int32)\n",
        "    generated_images = generator_model.predict([noise, sampled_labels])\n",
        "    fig, axs = plt.subplots(1, 10, figsize=(10, 10))\n",
        "    for i in range(10):\n",
        "        axs[i].imshow(generated_images[i], cmap=\"gray\")\n",
        "        axs[i].axis(\"off\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAqGbZU0Z5yl",
        "outputId": "da0ae456-02a5-4e0f-ad96-dd05266b7dd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 82ms/step\n",
            "(1, 2500, 1)\n"
          ]
        }
      ],
      "source": [
        "noise = tf.random.normal(shape=(1,10000,1))\n",
        "\n",
        "test = generator.predict(noise)\n",
        "print(test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wp5mnkMVVgPV"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@tf.function\n",
        "def train_step(target_audios):\n",
        "\n",
        "\n",
        "  for i in range(5):\n",
        "\n",
        "      # Get the shape of the target_audios tensor\n",
        "      shape = tf.shape(target_audios)\n",
        "\n",
        "      # Divide the number in the second index by 4\n",
        "      divided_value = shape[1] // 4\n",
        "\n",
        "      # Generate noise using tf.random.normal()\n",
        "      noise = tf.random.normal((shape[0], divided_value, shape[2]))\n",
        "      generated_audio = generator(noise, training=True)\n",
        "      with tf.GradientTape() as disc_tape:\n",
        "\n",
        "          real_output = discriminator(target_audios, training=True)\n",
        "          fake_output = discriminator(generated_audio, training=True)\n",
        "\n",
        "          disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "      gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "      discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "      if i ==0:\n",
        "          weights = discriminator.get_weights()\n",
        "\n",
        "\n",
        "  with tf.GradientTape() as gen_tape:\n",
        "    noise = tf.random.normal(shape=(target_audios.shape))\n",
        "    generated_audio = generator(noise, training=True)\n",
        "    fake_output = discriminator(generated_audio, training=True)\n",
        "    gen_loss = generator_loss(fake_output)\n",
        "\n",
        "  gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "  generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "  discriminator.set_weights(weights)\n",
        "\n",
        "\n",
        "  tf.print(\"disc_loss\",disc_loss,'gen_loss',gen_loss)\n",
        "\n",
        "\n",
        "def train(generator, discriminator\n",
        "          , epochs, batch_size):\n",
        "    for epoch in range(epochs):\n",
        "        for batch in range(len(y_train) // batch_size):\n",
        "            #images = x_train[batch * batch_size: (batch+1) * batch_size]\n",
        "            target_audios = y_train[batch * batch_size: (batch+1) * batch_size]\n",
        "\n",
        "            train_step(target_audios)\n",
        "\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "            test = generator.predict(noise)\n",
        "            audio_data = test.ravel()\n",
        "            # Play the audio within the Jupyter Notebook\n",
        "            Audio(data=audio_data, rate=sr/reduction)\n",
        "\n",
        "\n",
        "# Train the GAN\n",
        "EPOCHS = 2000000\n",
        "BATCH_SIZE = 20\n",
        "num_unrolling_steps = 20  # Set the desired number of unrolling steps\n",
        "train(generator, discriminator, EPOCHS, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "id": "mrmv1Zri-jjc",
        "outputId": "1a7bf260-96b5-42fd-ccbe-643a66fd69e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 50ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ],
            "text/html": [
              "\n",
              "                <audio  controls=\"controls\" >\n",
              "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "            test = generator.predict(noise)\n",
        "            audio_data = test.ravel()\n",
        "            # Play the audio within the Jupyter Notebook\n",
        "            Audio(data=audio_data, rate=sr/reduction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjhAydgsdXVx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Overview of Colaboratory Features",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}