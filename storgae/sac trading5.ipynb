{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/aetev/Learning-stuff-/blob/main/sac%20trading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z1IPtawZ_QU6",
    "outputId": "898eeb56-d8f7-43cc-bef8-9326395d3974"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gkseWxmn_R_h",
    "outputId": "ef92564c-a3fa-4a24-f87c-2c4d81b1b167"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf_agents[reverb] in /usr/local/lib/python3.8/dist-packages (0.16.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.8/dist-packages (from tf_agents[reverb]) (1.23.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from tf_agents[reverb]) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.8/dist-packages (from tf_agents[reverb]) (1.14.1)\n",
      "Requirement already satisfied: gin-config>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from tf_agents[reverb]) (0.5.0)\n",
      "Requirement already satisfied: pygame==2.1.3 in /usr/local/lib/python3.8/dist-packages (from tf_agents[reverb]) (2.1.3)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from tf_agents[reverb]) (9.4.0)\n",
      "Requirement already satisfied: protobuf>=3.11.3 in /usr/local/lib/python3.8/dist-packages (from tf_agents[reverb]) (4.22.1)\n",
      "Requirement already satisfied: gym<=0.23.0,>=0.17.0 in /usr/local/lib/python3.8/dist-packages (from tf_agents[reverb]) (0.23.0)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.8/dist-packages (from tf_agents[reverb]) (2.2.1)\n",
      "Requirement already satisfied: tensorflow-probability~=0.19.0 in /usr/local/lib/python3.8/dist-packages (from tf_agents[reverb]) (0.19.0)\n",
      "Requirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.8/dist-packages (from tf_agents[reverb]) (1.4.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/lib/python3/dist-packages (from tf_agents[reverb]) (1.14.0)\n",
      "Requirement already satisfied: dm-reverb~=0.11.0 in /usr/local/lib/python3.8/dist-packages (from tf_agents[reverb]) (0.11.0)\n",
      "Requirement already satisfied: rlds in /usr/local/lib/python3.8/dist-packages (from tf_agents[reverb]) (0.1.8)\n",
      "Requirement already satisfied: tensorflow~=2.12.0 in /usr/local/lib/python3.8/dist-packages (from tf_agents[reverb]) (2.12.0)\n",
      "Requirement already satisfied: dm-tree in /usr/local/lib/python3.8/dist-packages (from dm-reverb~=0.11.0->tf_agents[reverb]) (0.1.8)\n",
      "Requirement already satisfied: portpicker in /usr/local/lib/python3.8/dist-packages (from dm-reverb~=0.11.0->tf_agents[reverb]) (1.5.2)\n",
      "Requirement already satisfied: importlib-metadata>=4.10.0 in /usr/local/lib/python3.8/dist-packages (from gym<=0.23.0,>=0.17.0->tf_agents[reverb]) (6.1.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from gym<=0.23.0,>=0.17.0->tf_agents[reverb]) (0.0.8)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.12.0->tf_agents[reverb]) (2.12.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.12.0->tf_agents[reverb]) (2.12.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.12.0->tf_agents[reverb]) (16.0.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.12.0->tf_agents[reverb]) (2.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.12.0->tf_agents[reverb]) (3.8.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.12.0->tf_agents[reverb]) (1.6.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.12.0->tf_agents[reverb]) (1.51.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.12.0->tf_agents[reverb]) (23.3.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.12.0->tf_agents[reverb]) (23.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.12.0->tf_agents[reverb]) (0.31.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.12.0->tf_agents[reverb]) (67.6.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.12.0->tf_agents[reverb]) (3.3.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.12.0->tf_agents[reverb]) (0.4.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.12.0->tf_agents[reverb]) (2.12.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.12.0->tf_agents[reverb]) (0.4.6)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.12.0->tf_agents[reverb]) (0.2.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability~=0.19.0->tf_agents[reverb]) (5.1.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow~=2.12.0->tf_agents[reverb]) (0.40.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.10.0->gym<=0.23.0,>=0.17.0->tf_agents[reverb]) (3.15.0)\n",
      "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.8/dist-packages (from jax>=0.3.15->tensorflow~=2.12.0->tf_agents[reverb]) (1.10.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf_agents[reverb]) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf_agents[reverb]) (0.7.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf_agents[reverb]) (2.16.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf_agents[reverb]) (2.22.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf_agents[reverb]) (2.2.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf_agents[reverb]) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf_agents[reverb]) (3.4.3)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from portpicker->dm-reverb~=0.11.0->tf_agents[reverb]) (5.9.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf_agents[reverb]) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf_agents[reverb]) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf_agents[reverb]) (5.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf_agents[reverb]) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf_agents[reverb]) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf_agents[reverb]) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf_agents[reverb]) (3.2.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pandas_ta in /usr/local/lib/python3.8/dist-packages (0.3.14b0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from pandas_ta) (2.0.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.8/dist-packages (from pandas->pandas_ta) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.8/dist-packages (from pandas->pandas_ta) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->pandas_ta) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.8/dist-packages (from pandas->pandas_ta) (1.23.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->pandas_ta) (1.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Collecting imageio\n",
      "  Downloading imageio-2.31.1-py3-none-any.whl (313 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from imageio) (1.23.5)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.8/dist-packages (from imageio) (9.4.0)\n",
      "Installing collected packages: imageio\n",
      "Successfully installed imageio-2.31.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tf_agents[reverb]\n",
    "!pip install pandas_ta\n",
    "!pip install imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "BDqp9KQn_yrH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-22 01:59:45.753814: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import imageio\n",
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import reverb\n",
    "import tempfile\n",
    "import PIL.Image\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pandas_ta as ta\n",
    "\n",
    "from tf_agents.environments import suite_gym\n",
    "import tensorflow as tf\n",
    "\n",
    "from tf_agents.environments import py_environment\n",
    "from tf_agents.environments import tf_environment\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.specs import array_spec\n",
    "from tf_agents.environments import utils\n",
    "\n",
    "from tf_agents.agents.ddpg import critic_network\n",
    "from tf_agents.agents.sac import sac_agent\n",
    "from tf_agents.agents.sac import tanh_normal_projection_network\n",
    "from tf_agents.metrics import py_metrics\n",
    "from tf_agents.networks import actor_distribution_network\n",
    "from tf_agents.policies import greedy_policy\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.policies import random_py_policy\n",
    "from tf_agents.replay_buffers import reverb_replay_buffer\n",
    "from tf_agents.replay_buffers import reverb_utils\n",
    "from tf_agents.train import actor\n",
    "from tf_agents.train import learner\n",
    "from tf_agents.train import triggers\n",
    "from tf_agents.train.utils import spec_utils\n",
    "from tf_agents.train.utils import strategy_utils\n",
    "from tf_agents.train.utils import train_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "cellView": "form",
    "id": "8Xo8gJchAtla"
   },
   "outputs": [],
   "source": [
    "# Use \"num_iterations = 1e6\" for better results (2 hrs)\n",
    "# 1e5 is just so this doesn't take too long (1 hr)\n",
    "num_iterations = 100000 # @param {type:\"integer\"}\n",
    "\n",
    "initial_collect_steps = 10000 # @param {type:\"integer\"}\n",
    "collect_steps_per_iteration = 1 # @param {type:\"integer\"}\n",
    "replay_buffer_capacity = 10000 # @param {type:\"integer\"}\n",
    "\n",
    "batch_size = 256 # @param {type:\"integer\"}\n",
    "\n",
    "critic_learning_rate = 3e-4 # @param {type:\"number\"}\n",
    "actor_learning_rate = 3e-4 # @param {type:\"number\"}\n",
    "alpha_learning_rate = 3e-4 # @param {type:\"number\"}\n",
    "target_update_tau = 0.005 # @param {type:\"number\"}\n",
    "target_update_period = 1 # @param {type:\"number\"}\n",
    "gamma = 0.99 # @param {type:\"number\"}\n",
    "reward_scale_factor = 1.0 # @param {type:\"number\"}\n",
    "\n",
    "actor_fc_layer_params = (256, 256)\n",
    "critic_joint_fc_layer_params = (256, 256)\n",
    "\n",
    "log_interval = 1000 # @param {type:\"integer\"}\n",
    "\n",
    "num_eval_episodes = 5 # @param {type:\"integer\"}\n",
    "eval_interval = 10000 # @param {type:\"integer\"}\n",
    "\n",
    "policy_save_interval = 5000 # @param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T3hj-E1MVcS1",
    "outputId": "b19cdffa-9ab8-4efd-d292-d3aba0b2d95f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.2937088e+01 8.4042799e-04 6.5000000e-05]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/tmp/eurusd_hour.csv')\n",
    "bid_open = df['BO'].to_numpy()\n",
    "bid_close = df['BC'].to_numpy()\n",
    "rel_change = (bid_open - bid_close) * 1000\n",
    "input_df = pd.DataFrame()\n",
    "\n",
    "cumulative_arr = np.cumsum(rel_change)\n",
    "rsi = ta.rsi(df['BC'], 14)\n",
    "stdev = ta.stdev(df['BC'], 14)\n",
    "mad = ta.sma(df['BC'], 14) - df['BC']\n",
    "mad = pd.DataFrame(mad,columns=[\"mad\"])\n",
    "relc_df = pd.DataFrame(rel_change,columns=[\"rel_change\"])\n",
    "\n",
    "concatenated_df = pd.concat([rsi, stdev, mad,relc_df], axis=1)\n",
    "concatenated_df = concatenated_df.dropna(axis=0)\n",
    "\n",
    "changenp = concatenated_df.pop(\"rel_change\")\n",
    "changenp = changenp.to_numpy()\n",
    "changenp = changenp.astype('float32')\n",
    "\n",
    "concatenated_df = concatenated_df.to_numpy()\n",
    "concatenated_df = concatenated_df.astype('float32')\n",
    "\n",
    "print(concatenated_df[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "47pOqHSLizij",
    "outputId": "ef2e257a-561d-4d88-f7e6-49cc50470cf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.60771217e+01 9.35611664e-04 1.96000002e-03 2.00000000e+01]\n"
     ]
    }
   ],
   "source": [
    "new_array = np.append(concatenated_df[0], 20.)\n",
    "print(new_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "48DkwFLnVg9O"
   },
   "outputs": [],
   "source": [
    "class CardGameEnv(py_environment.PyEnvironment):\n",
    "    def __init__(self):\n",
    "        self._action_spec = array_spec.BoundedArraySpec(\n",
    "            shape=(1,), dtype=np.float32, minimum=-1, maximum=1, name='action')\n",
    "        self._observation_spec = array_spec.BoundedArraySpec(\n",
    "            shape=(4,), dtype=np.float32, minimum=-100, maximum=100, name='observation')\n",
    "        self._array = concatenated_df\n",
    "        self._state = np.append(self._array[0],0)\n",
    "        self._episode_ended = False\n",
    "        self._count = 0\n",
    "        self._Net_Profit = 0\n",
    "    def action_spec(self):\n",
    "        return self._action_spec\n",
    "\n",
    "    def observation_spec(self):\n",
    "        return self._observation_spec\n",
    "\n",
    "    def _reset(self):\n",
    "        self._Net_Profit = 0\n",
    "        self._count = 0\n",
    "        self._state = np.append(self._array[0],0)\n",
    "        self._episode_ended = False\n",
    "        return ts.restart(np.array(self._state, dtype=np.float32))\n",
    "\n",
    "    def _step(self, action):\n",
    "        if self._episode_ended:\n",
    "            # The last action ended the episode. Ignore the current action and start\n",
    "            # a new episode.\n",
    "            return self.reset()\n",
    "\n",
    "        value = changenp[self._count]\n",
    "\n",
    "        # Make sure episodes don't go on forever.\n",
    "\n",
    "        self._Net_Profit += value*action[0]\n",
    "        self.state = np.append(self._array[self._count],self._Net_Profit)\n",
    "\n",
    "        if self._count > 5000:\n",
    "            self._episode_ended = True\n",
    "        self._count += 1\n",
    "\n",
    "        if self._episode_ended:\n",
    "            reward = self._Net_Profit\n",
    "            return ts.termination(np.array(self._state, dtype=np.float32), reward)\n",
    "        else:\n",
    "            reward = value*action[0]\n",
    "            return ts.transition(np.array(self._state, dtype=np.float32), reward=reward,discount=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "0YMxohCHWezc"
   },
   "outputs": [],
   "source": [
    "\n",
    "environment = CardGameEnv()\n",
    "utils.validate_py_environment(environment, episodes=2)\n",
    "#env = environment#tf_py_environment.TFPyEnvironment(environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "2lIl-hO-_0Mm"
   },
   "outputs": [],
   "source": [
    "env = environment #tf_py_environment.TFPyEnvironment(environment)\n",
    "env_name = 'MountainCarContinuous-v0'\n",
    "collect_env  = env #suite_gym.load(env_name)\n",
    "eval_env   = env #suite_gym.load(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "CkDfs-xfBJUU",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-22 02:00:25.850895: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-22 02:00:25.862624: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-22 02:00:25.862820: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-22 02:00:25.864983: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-22 02:00:25.865251: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-22 02:00:25.865467: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-22 02:00:26.576570: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-22 02:00:26.576758: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-22 02:00:26.576895: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-22 02:00:26.577018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6019 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 SUPER, pci bus id: 0000:0b:00.0, compute capability: 7.5\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    }
   ],
   "source": [
    "use_gpu = True\n",
    "\n",
    "strategy = strategy_utils.get_strategy(tpu=False, use_gpu=use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "RbBZPAOXAf78"
   },
   "outputs": [],
   "source": [
    "observation_spec, action_spec, time_step_spec = (\n",
    "      spec_utils.get_tensor_specs(collect_env))\n",
    "\n",
    "with strategy.scope():\n",
    "  critic_net = critic_network.CriticNetwork(\n",
    "        (observation_spec, action_spec),\n",
    "        observation_fc_layer_params=None,\n",
    "        action_fc_layer_params=None,\n",
    "        joint_fc_layer_params=(20,20),\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        last_kernel_initializer='glorot_uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-t4j7m6SVQqr",
    "outputId": "6e523cf9-1bbf-4e74-b076-a03885f2da33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Spec: BoundedTensorSpec(shape=(4,), dtype=tf.float32, name='observation', minimum=array(-100., dtype=float32), maximum=array(100., dtype=float32))\n",
      "Action Spec: BoundedTensorSpec(shape=(1,), dtype=tf.float32, name='action', minimum=array(-1., dtype=float32), maximum=array(1., dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "print(\"Observation Spec:\", observation_spec)\n",
    "print(\"Action Spec:\", action_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "jI0afo1FBPga"
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "  actor_net = actor_distribution_network.ActorDistributionNetwork(\n",
    "      observation_spec,\n",
    "      action_spec,\n",
    "      fc_layer_params=(20,20),\n",
    "      continuous_projection_net=(\n",
    "          tanh_normal_projection_network.TanhNormalProjectionNetwork))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "6V3WUw25B1k7"
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "  train_step = train_utils.create_train_step()\n",
    "\n",
    "  tf_agent = sac_agent.SacAgent(\n",
    "        time_step_spec,\n",
    "        action_spec,\n",
    "        actor_network=actor_net,\n",
    "        critic_network=critic_net,\n",
    "        actor_optimizer=tf.keras.optimizers.Adam(\n",
    "            learning_rate=actor_learning_rate),\n",
    "        critic_optimizer=tf.keras.optimizers.Adam(\n",
    "            learning_rate=critic_learning_rate),\n",
    "        alpha_optimizer=tf.keras.optimizers.Adam(\n",
    "            learning_rate=alpha_learning_rate),\n",
    "        target_update_tau=target_update_tau,\n",
    "        target_update_period=target_update_period,\n",
    "        td_errors_loss_fn=tf.math.squared_difference,\n",
    "        gamma=gamma,\n",
    "        reward_scale_factor=reward_scale_factor,\n",
    "        train_step_counter=train_step)\n",
    "\n",
    "  tf_agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "8OtP7sjGBf6R"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[reverb/cc/platform/tfrecord_checkpointer.cc:162]  Initializing TFRecordCheckpointer in /tmp/tmp_p94wfxm.\n",
      "[reverb/cc/platform/tfrecord_checkpointer.cc:567] Loading latest checkpoint from /tmp/tmp_p94wfxm\n",
      "[reverb/cc/platform/default/server.cc:71] Started replay server on port 37421\n"
     ]
    }
   ],
   "source": [
    "rate_limiter=reverb.rate_limiters.SampleToInsertRatio(samples_per_insert=3.0, min_size_to_sample=3, error_buffer=3.0)\n",
    "\n",
    "table_name = 'uniform_table'\n",
    "table = reverb.Table(\n",
    "    table_name,\n",
    "    max_size=replay_buffer_capacity,\n",
    "    sampler=reverb.selectors.Uniform(),\n",
    "    remover=reverb.selectors.Fifo(),\n",
    "    rate_limiter=reverb.rate_limiters.MinSize(1))\n",
    "\n",
    "reverb_server = reverb.Server([table])\n",
    "\n",
    "reverb_replay = reverb_replay_buffer.ReverbReplayBuffer(\n",
    "    tf_agent.collect_data_spec,\n",
    "    sequence_length=2,\n",
    "    table_name=table_name,\n",
    "    local_server=reverb_server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "S2GPKTjeD8zP"
   },
   "outputs": [],
   "source": [
    "dataset = reverb_replay.as_dataset(\n",
    "      sample_batch_size=batch_size, num_steps=2).prefetch(50)\n",
    "experience_dataset_fn = lambda: dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Q8FrWue9EAej"
   },
   "outputs": [],
   "source": [
    "tf_eval_policy = tf_agent.policy\n",
    "eval_policy = py_tf_eager_policy.PyTFEagerPolicy(\n",
    "  tf_eval_policy, use_tf_function=True)\n",
    "\n",
    "tf_collect_policy = tf_agent.collect_policy\n",
    "collect_policy = py_tf_eager_policy.PyTFEagerPolicy(\n",
    "  tf_collect_policy, use_tf_function=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "9_GBDROTEQXK"
   },
   "outputs": [],
   "source": [
    "random_policy = random_py_policy.RandomPyPolicy(\n",
    "  collect_env.time_step_spec(), collect_env.action_spec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "eJP741I1ESXV"
   },
   "outputs": [],
   "source": [
    "rb_observer = reverb_utils.ReverbAddTrajectoryObserver(\n",
    "  reverb_replay.py_client,\n",
    "  table_name,\n",
    "  sequence_length=2,\n",
    "  stride_length=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "g8sD1uCkExqN"
   },
   "outputs": [],
   "source": [
    "initial_collect_actor = actor.Actor(\n",
    "  collect_env,\n",
    "  random_policy,\n",
    "  train_step,\n",
    "  steps_per_run=initial_collect_steps,\n",
    "  observers=[rb_observer])\n",
    "initial_collect_actor.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "tAEqMRo2Jmxc"
   },
   "outputs": [],
   "source": [
    "location = \"/tmp/lerning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "gdA_u_j_Ey6p"
   },
   "outputs": [],
   "source": [
    "\n",
    "env_step_metric = py_metrics.EnvironmentSteps()\n",
    "collect_actor = actor.Actor(\n",
    "  collect_env,\n",
    "  collect_policy,\n",
    "  train_step,\n",
    "  steps_per_run=1,\n",
    "  metrics=actor.collect_metrics(10),\n",
    "  summary_dir=os.path.join(location, learner.TRAIN_DIR),\n",
    "  observers=[rb_observer, env_step_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "IHYlGKpsE0Hs"
   },
   "outputs": [],
   "source": [
    "eval_actor = actor.Actor(\n",
    "  eval_env,\n",
    "  eval_policy,\n",
    "  train_step,\n",
    "  episodes_per_run=num_eval_episodes,\n",
    "  metrics=actor.eval_metrics(num_eval_episodes),\n",
    "  summary_dir=os.path.join(location, 'eval'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ybubwekdFFNs",
    "outputId": "6a6af5b6-868d-4d7f-b3d7-2a52d3255570"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/distributions/distribution.py:342: calling MultivariateNormalDiag.__init__ (from tensorflow_probability.python.distributions.mvn_diag) with scale_identity_multiplier is deprecated and will be removed after 2020-01-01.\n",
      "Instructions for updating:\n",
      "`scale_identity_multiplier` is deprecated; please combine it into `scale_diag` directly instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow_probability/python/distributions/distribution.py:342: calling MultivariateNormalDiag.__init__ (from tensorflow_probability.python.distributions.mvn_diag) with scale_identity_multiplier is deprecated and will be removed after 2020-01-01.\n",
      "Instructions for updating:\n",
      "`scale_identity_multiplier` is deprecated; please combine it into `scale_diag` directly instead.\n",
      "WARNING:absl:WARNING: Could not serialize policy.distribution() for policy \"<tf_agents.policies.actor_policy.ActorPolicy object at 0x7f4adc2e25b0>\". Calling saved_model.distribution() will raise the following assertion error: missing a required argument: 'distribution'\n",
      "WARNING:absl:WARNING: Could not serialize policy.distribution() for policy \"<tf_agents.policies.actor_policy.ActorPolicy object at 0x7f4adc2e25b0>\". Calling saved_model.distribution() will raise the following assertion error: missing a required argument: 'distribution'\n"
     ]
    }
   ],
   "source": [
    "saved_model_dir = os.path.join(location, learner.POLICY_SAVED_MODEL_DIR)\n",
    "\n",
    "# Triggers to save the agent's policy checkpoints.\n",
    "learning_triggers = [\n",
    "    triggers.PolicySavedModelTrigger(\n",
    "        saved_model_dir,\n",
    "        tf_agent,\n",
    "        train_step,\n",
    "        interval=policy_save_interval),\n",
    "    triggers.StepPerSecondLogTrigger(train_step, interval=1000),\n",
    "]\n",
    "\n",
    "agent_learner = learner.Learner(\n",
    "  location,\n",
    "  train_step,\n",
    "  tf_agent,\n",
    "  experience_dataset_fn,\n",
    "  triggers=learning_triggers,\n",
    "  strategy=strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "NyOHolq_FUhG"
   },
   "outputs": [],
   "source": [
    "def get_eval_metrics():\n",
    "  eval_actor.run()\n",
    "  results = {}\n",
    "  for metric in eval_actor.metrics:\n",
    "    results[metric.name] = metric.result()\n",
    "  return results\n",
    "\n",
    "metrics = get_eval_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yjlwf8G-FV0m",
    "outputId": "94eafbf3-447f-4722-dc86-7ae28f9c5170"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 0: AverageReturn = 26.625431, AverageEpisodeLength = 5002.000000\n"
     ]
    }
   ],
   "source": [
    "def log_eval_metrics(step, metrics):\n",
    "  eval_results = (', ').join(\n",
    "      '{} = {:.6f}'.format(name, result) for name, result in metrics.items())\n",
    "  print('step = {0}: {1}'.format(step, eval_results))\n",
    "\n",
    "log_eval_metrics(0, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aspLZmK1Fjjh",
    "outputId": "d1af79df-4631-4cc6-cb3a-65497b9f7341"
   },
   "outputs": [],
   "source": [
    "# Reset the train step\n",
    "tf_agent.train_step_counter.assign(0)\n",
    "\n",
    "# Evaluate the agent's policy once before training.\n",
    "avg_return = get_eval_metrics()[\"AverageReturn\"]\n",
    "returns = [avg_return]\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "  # Training.\n",
    "  collect_actor.run()\n",
    "  loss_info = agent_learner.run(iterations=1)\n",
    "\n",
    "  # Evaluating.\n",
    "  step = agent_learner.train_step_numpy\n",
    "\n",
    "  if eval_interval and step % eval_interval == 0:\n",
    "    metrics = get_eval_metrics()\n",
    "    log_eval_metrics(step, metrics)\n",
    "    returns.append(metrics[\"AverageReturn\"])\n",
    "\n",
    "  if log_interval and step % log_interval == 0:\n",
    "    print('step = {0}: loss = {1}'.format(step, loss_info.loss.numpy()))\n",
    "\n",
    "rb_observer.close()\n",
    "reverb_server.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Welcome To Colaboratory",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
